{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قولهأوقطعالأوليدهإلخقالالزركشيابنعرفةقولهبلفظيقتضيهكإنكارغيرحديثبالإسلاموجوبماعلموجوبهمنالدينضرورةكإ\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('dataset/cleaned_train_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_train_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_lines = file.readlines()\n",
    "\n",
    "training_data = \"\"\n",
    "for line in training_data_lines:\n",
    "    training_data += ''.join(line.split()).strip()\n",
    "training_data_diacritized = \"\"\n",
    "for line in training_data_diacritized_lines:\n",
    "    training_data_diacritized += ''.join(line.split()).strip()\n",
    "validation_data = \"\"\n",
    "for line in validation_data_lines:\n",
    "    validation_data += ''.join(line.split()).strip()\n",
    "validation_data_diacritized = \"\"\n",
    "for line in validation_data_diacritized_lines:\n",
    "    validation_data_diacritized += ''.join(line.split()).strip()\n",
    "    \n",
    "print(training_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the labels and their corresponding indices\n",
    "labels = {\n",
    "    # fatha\n",
    "    '\\u064E':0,\n",
    "    # damma\n",
    "    '\\u064F':1,\n",
    "    # kasra\n",
    "    '\\u0650':2,\n",
    "    # shadda\n",
    "    '\\u0651':3,\n",
    "    # sukun\n",
    "    '\\u0652':4,\n",
    "    # tanween_fatha\n",
    "    '\\u064B':5,\n",
    "    # tanween_damma\n",
    "    '\\u064C':6,\n",
    "    # tanween_kasra\n",
    "    '\\u064D':7\n",
    "}\n",
    "\n",
    "sequence_to_labels = {\n",
    "    # fatha\n",
    "    0:'\\u064E',\n",
    "    # damma\n",
    "    1:'\\u064F',\n",
    "    # kasra\n",
    "    2:'\\u0650',\n",
    "    # shadda\n",
    "    3:'\\u0651',\n",
    "    # sukun\n",
    "    4:'\\u0652',\n",
    "    # tanween_fatha\n",
    "    5:'\\u064B',\n",
    "    # tanween_damma\n",
    "    6:'\\u064C',\n",
    "    # tanween_kasra\n",
    "    7:'\\u064D'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ى': 0, 'ل': 1, 'ط': 2, 'ه': 3, 'ث': 4, 'س': 5, 'ف': 6, 'ظ': 7, 'غ': 8, 'ح': 9, 'ي': 10, 'ص': 11, 'إ': 12, 'ت': 13, 'ج': 14, 'ب': 15, 'ئ': 16, 'ا': 17, 'د': 18, 'و': 19, 'ء': 20, 'أ': 21, 'ز': 22, 'ؤ': 23, 'ذ': 24, 'ك': 25, 'ة': 26, 'ن': 27, 'ق': 28, 'ر': 29, 'آ': 30, 'خ': 31, 'ع': 32, 'ش': 33, 'م': 34, 'ض': 35}\n",
      "Number of unique characters:  36\n",
      "{'ى', 'ل', 'ط', 'ه', 'ث', 'س', 'ف', 'ظ', 'غ', 'ح', 'ي', 'ص', 'إ', 'ت', 'ج', 'ب', 'ئ', 'ا', 'د', 'و', 'ء', 'أ', 'ز', 'ؤ', 'ذ', 'ك', 'ة', 'ن', 'ق', 'ر', 'آ', 'خ', 'ع', 'ش', 'م', 'ض'}\n",
      "[28, 19, 1, 3, 21, 19, 28, 2, 32, 17]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into sequences at the character level\n",
    "unique_chars = set(''.join(training_data + validation_data))\n",
    "diacritization = list(labels.keys())\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "index_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "print(char_to_index)\n",
    "\n",
    "def text_to_sequence(text):\n",
    "    return [char_to_index[char] for char in text]\n",
    "\n",
    "train_sequence = text_to_sequence(training_data)\n",
    "validation_sequences = text_to_sequence(validation_data)\n",
    "\n",
    "print(\"Number of unique characters: \", len(unique_chars))\n",
    "print(unique_chars)\n",
    "print(train_sequence[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW(\n",
      "  (embeddings): Embedding(36, 50)\n",
      "  (linear): Linear(in_features=50, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Implementing word embedding using CBOW\n",
    "# CBOW context window size\n",
    "context_window = 1\n",
    "\n",
    "# Define CBOW model\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        # embedding layer \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # linear layer\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # The forward method specifies how data flows through the model.\n",
    "        embedded = self.embeddings(context).sum(dim=1)\n",
    "        output = self.linear(embedded)\n",
    "        # now, output is of size [batch_size, vocab_size], we want it to be of size [1, vocab_size]\n",
    "        # no problem, as it contains arrays, each array of size [1, vocab_size], and all elements of the arrays are the same\n",
    "        output = output.squeeze(0)[:1, :]\n",
    "        return output\n",
    "    \n",
    "# Instantiate CBOW model\n",
    "embedding_dim = 20\n",
    "vocab_size = len(unique_chars)\n",
    "cbow_model = CBOW(vocab_size, embedding_dim)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "cbow_model = cbow_model.to(device)\n",
    "\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m output \u001b[38;5;241m=\u001b[39m cbow_model(context)\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     31\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the CBOW model\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# The Adam optimizer is an extension to stochastic gradient descent\n",
    "optimizer = optim.SGD(cbow_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "# TODO: make it 50\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(context_window, len(train_sequence) - context_window):\n",
    "        # get context window, and get 1-hot encoding for each character in the window\n",
    "        context = torch.tensor(train_sequence[i-context_window:i] + train_sequence[i+1:i+1+context_window])\n",
    "        # create 1-hot encoding for each position in the context array\n",
    "        context = torch.nn.functional.one_hot(context, num_classes=vocab_size)\n",
    "        # get target character\n",
    "        target = torch.tensor([train_sequence[i]])\n",
    "        # create 1-hot encoding for target character\n",
    "        target = torch.nn.functional.one_hot(target, num_classes=vocab_size).float()\n",
    "        \n",
    "        # Move tensors to GPU if available\n",
    "        context, target = context.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = cbow_model(context)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 50)\n",
      "ى: [ 0.00693972 -0.02702003  0.04268251 -0.02664188 -0.0603625   0.03998989\n",
      "  0.02844273 -0.0110855   0.02957191 -0.06428575  0.01258888 -0.09369535\n",
      " -0.03476622  0.01324764  0.02049855 -0.05624948 -0.02535872  0.01915876\n",
      " -0.01098966  0.04600329 -0.01591044  0.0281318   0.03814961 -0.02958758\n",
      "  0.00338939  0.01921298  0.0182109   0.01304104  0.01887392  0.02705112\n",
      " -0.0191082  -0.05718313 -0.02194045 -0.0413122   0.03207927  0.02224422\n",
      " -0.01703501  0.05798257 -0.06179385 -0.04293663  0.02309863 -0.05869397\n",
      "  0.04289445  0.02252923  0.01320013  0.01109794 -0.04698668  0.09566227\n",
      " -0.00432673 -0.05210153]\n",
      "ل: [-0.4372555  -0.49678177 -0.9207096   0.8717278   2.2575328  -0.2881389\n",
      "  0.22909097 -0.15122634 -1.1989657   1.2530845  -0.13212207  2.94664\n",
      "  1.1043385   0.17992999 -2.0714617   0.6319345   0.50512385 -0.0947079\n",
      "  0.930131   -1.3984638   1.3758057  -0.11205965 -1.1877218  -0.37510827\n",
      "  0.09779697 -0.04472011 -0.69965106 -0.50004363 -0.3746642  -0.9417012\n",
      " -0.06043649  1.3242837   0.21377388  0.25190368 -1.7048504  -1.2758867\n",
      "  0.2612761  -1.6476243   0.77411574  0.8350136  -0.8803409   2.2374048\n",
      " -0.46036282 -0.8345793   0.2191624  -0.07904611 -0.00396989 -2.121102\n",
      "  0.47536337  1.4837662 ]\n",
      "ط: [-0.62392426 -0.2511344  -0.4521069  -1.8010256  -0.78517765 -0.20737597\n",
      "  0.2601746   0.41437405  0.16319303  0.2894087  -0.05291495  2.057214\n",
      " -1.2308105   1.8824873  -0.09571419 -1.0340198   0.94018257  0.42231175\n",
      "  1.2286133  -0.7963733  -0.9888992  -1.6654842  -2.4162056  -1.0449617\n",
      "  2.7355099   0.3679977   1.2588217  -0.57106453 -0.09803546 -0.86324936\n",
      "  0.2369527  -1.7266207   0.46499833  0.2748219   0.07781302  0.75275546\n",
      " -0.99996275 -0.46193153  0.5309748   0.02399738 -0.22314961 -0.45003816\n",
      "  1.0684056  -0.18323977  1.2963376  -0.87946385 -0.40846935 -0.22587183\n",
      "  1.6300856   0.31043285]\n",
      "ه: [ 1.13375795e+00  2.76819205e+00  4.64696437e-01  1.17027628e+00\n",
      " -8.53782713e-01 -7.71240413e-01 -6.13566160e-01 -5.14911592e-01\n",
      " -3.49189591e+00 -2.15154195e+00  1.12760300e-02 -6.63502395e-01\n",
      "  2.11798232e-02  1.24970543e+00 -1.14896727e+00 -8.14837217e-02\n",
      "  1.17339730e+00 -3.81002523e-04  1.53685904e+00  6.64250180e-02\n",
      "  3.62785496e-02  1.71277821e-01  4.95421380e-01 -9.37967241e-01\n",
      "  7.17085898e-01  1.29744411e+00  1.03361440e+00  9.51633930e-01\n",
      " -7.45882869e-01  9.60108042e-01 -1.07266605e-01  2.42963004e+00\n",
      " -1.28082204e+00 -2.25807548e-01  9.59468484e-02 -7.25372791e-01\n",
      " -6.65324748e-01  1.52179539e+00 -2.40394902e+00  8.79680276e-01\n",
      "  1.03735542e+00 -3.99885252e-02 -5.15774250e-01 -1.41252232e+00\n",
      " -1.62424839e+00 -6.28762901e-01 -4.67139274e-01 -6.66603625e-01\n",
      "  9.22758341e-01 -8.16002309e-01]\n",
      "ث: [ 0.44315663 -1.42879    -0.43753585  0.8966299  -0.35972124 -0.6642821\n",
      " -1.3846952   1.5258151   0.09971682  0.5256492   0.45785618 -0.47563034\n",
      "  1.0674539   2.0211442   1.0432962   0.7324615  -0.6315045   1.6318793\n",
      " -0.2367817   1.5129274  -0.13686791 -1.2611507   0.0902759   0.52323204\n",
      " -0.6179042  -0.8557674  -1.3796046  -0.93363726 -0.77153677  1.7434951\n",
      " -1.034056   -0.73106474  0.4038112  -0.24968821  1.24789     0.7481712\n",
      "  1.5158712  -0.5545627  -0.66825765  0.44270164  1.4422977   0.77205455\n",
      "  0.25945014 -1.1428037   0.42220414 -1.7201543  -0.25398725 -1.0777268\n",
      " -0.2946653   0.0050551 ]\n",
      "س: [ 6.4803654e-01 -1.7978954e+00  2.2439094e+00 -7.9363620e-01\n",
      " -2.1349710e-01  4.0680778e-01 -5.8157575e-01  4.5607191e-01\n",
      " -2.5135467e-03 -7.3706156e-01  4.4051722e-01 -3.2951880e-01\n",
      "  3.9523032e-02 -5.0895095e-02 -2.8875613e-01  1.9050239e-01\n",
      " -2.1204634e-01 -5.1352841e-01  7.1838498e-01 -6.1610967e-01\n",
      "  1.3785896e+00  8.2893676e-01 -1.7457321e+00 -3.4607953e-01\n",
      "  6.2826633e-01 -2.8547338e-01  1.1159809e-01 -1.3545569e+00\n",
      "  1.3058673e-01  6.1353636e-01 -6.3579714e-01 -1.6542330e+00\n",
      "  3.3376014e-01  8.2401661e-03 -1.0587822e-01  9.0332073e-01\n",
      "  1.0396061e+00  4.0521866e-01 -7.3076737e-01  1.0391176e+00\n",
      " -2.1937811e-01 -2.6846197e-01 -7.6180470e-01 -5.2881187e-01\n",
      "  1.0337421e+00  1.3414441e-01  1.2860458e-01 -1.8034033e-03\n",
      "  1.5249863e+00 -4.3435258e-01]\n",
      "ف: [ 0.37309244 -0.9700528   0.18025157 -1.1468378   2.0649965  -0.2955353\n",
      "  1.8499185  -2.4765344  -0.735841    2.04649    -1.5290692  -0.36456838\n",
      " -0.7638697  -0.62743366 -1.2125006   0.63987035 -0.5486586   0.44487396\n",
      " -0.07642227  1.4148978  -1.1262628  -0.4528084   2.0067766   0.6428861\n",
      " -1.0958368  -1.9754496   1.3680483   1.3068249   0.04017009 -0.19120815\n",
      " -2.2258055  -0.7015339  -0.31847876  1.2273381  -0.38813254 -0.9854003\n",
      "  0.44407067  2.9146028   0.34821975  1.2458429  -0.7944371   0.4005788\n",
      " -2.428303   -1.0893016  -1.1324008  -0.9672661  -0.10651358  0.51393306\n",
      "  0.2727087   1.4299697 ]\n",
      "ظ: [-1.5186524  -0.09282697 -1.5569426   1.0903226   0.08280589  0.6775164\n",
      " -0.5117717   0.3545136  -0.56916887 -0.3111047  -0.7188044   0.63132745\n",
      " -0.09519222 -0.1954865   1.1625168   0.6172566  -0.5911576  -2.0678399\n",
      "  0.1567015  -0.7487894   0.51400834 -0.09880655  0.512134   -1.7373316\n",
      " -0.34486327 -0.3993229  -2.1928437  -0.19014919  0.95659244 -1.7094233\n",
      "  0.31591797  0.32760364 -1.5766433   0.9138029   0.95965105 -0.35419634\n",
      "  1.6020905  -1.2963647  -1.056957    1.5094053  -0.84617394  0.81641066\n",
      "  0.25981572 -0.31770304  0.3227706  -0.6669957  -0.5420276   1.8031125\n",
      "  1.2956611  -0.9621099 ]\n",
      "غ: [ 0.7562833  -0.12852266  0.1398615  -1.2684661  -0.2051549   0.73588914\n",
      "  2.1528666   0.8150783  -1.0037161  -0.5397952   0.35048345 -1.4099777\n",
      "  0.36528856 -0.12104487 -0.6016447  -0.03046746 -0.4633388   1.3562385\n",
      " -1.082475    1.0607268  -0.99202216 -1.3966523   0.07707186 -1.112245\n",
      "  1.2545531  -0.20489591  0.28173795  0.51753306 -0.3541682   0.42133975\n",
      " -0.25348097  0.61724967 -0.2745703   1.7632581  -0.22376387  1.4420223\n",
      "  1.9607086  -0.66227144 -0.16203049  2.5873792   0.4833327   0.6370621\n",
      "  0.36931112 -0.8796304  -1.2286578   2.441586    0.43699467 -0.08822771\n",
      "  2.5135434   0.7663425 ]\n",
      "ح: [ 0.21646291 -0.51032025 -0.4244691  -0.4623403  -0.9884107  -2.1148937\n",
      " -0.34514105 -0.01387201  3.027955    2.339738    0.10547832 -1.1809886\n",
      " -0.22344223 -1.0094743   0.3488264  -0.61891043 -0.5320808  -0.4374939\n",
      " -0.3914387   0.18428275 -0.15679096  0.9215862  -0.7185158  -0.42871022\n",
      " -0.5239161  -0.9248792   0.6051308  -0.6087476  -1.125671   -0.15838604\n",
      " -1.7749301   1.0944995  -0.24591216  0.9878178   0.8366317  -0.17947206\n",
      "  1.2018727   0.02670086 -0.5350807   0.24124905  0.31447014  0.59301746\n",
      " -0.444543   -1.7865835  -1.5084952  -2.5263314  -0.6682068  -0.5750606\n",
      " -1.0666715  -1.5633984 ]\n",
      "ي: [ 0.06358966  0.2659752  -1.0532587   1.5096917   0.22303835  1.4407678\n",
      " -1.0029142  -0.6410923  -1.1575773   0.31360608 -0.94261587  0.48802274\n",
      "  0.7935867  -0.82515347 -0.8333733  -0.2409636   0.33393654 -0.7139206\n",
      " -0.9791133   0.4517262  -0.815721   -0.207473    0.56163526  0.83464223\n",
      "  0.613118    0.21499784  0.45773327  0.45481816 -1.1341251   1.5887432\n",
      "  0.89432305  2.25708    -1.422498    0.11940715 -0.68131316  1.8412882\n",
      " -0.60179424 -0.2328437   0.5578534   2.6163814   0.3646755   0.44025466\n",
      "  1.0313655   1.1855797  -1.7731221  -0.3999784   0.17892957  1.150707\n",
      " -0.04578105 -2.029006  ]\n",
      "ص: [ 1.1734337e+00  1.2208886e-03 -1.3427213e+00  2.8604561e-01\n",
      " -1.2186178e+00  3.8367826e-01  3.7606940e-01  1.5168542e-01\n",
      "  2.5658542e-01  3.5492256e-01  6.2458944e-02 -7.0702660e-01\n",
      " -1.6201518e-01 -1.2668055e+00 -1.6018102e+00 -1.9573650e-01\n",
      " -1.8594097e+00  6.5996724e-01 -3.0647215e-01  2.8979218e-02\n",
      " -1.0150620e+00  4.6982244e-02 -6.2250090e-01  5.8743519e-01\n",
      "  1.4363845e-01 -8.3854479e-01 -9.3757677e-01  5.7979649e-01\n",
      " -2.2707608e-01 -4.0320027e-01  4.5658037e-01 -1.8443251e-01\n",
      "  1.3057944e+00 -1.5116605e-01 -1.4793135e+00 -6.3818461e-01\n",
      " -4.3394062e-01  1.0670080e+00 -5.1909578e-01  2.0322007e-01\n",
      " -1.7203904e+00 -1.0474775e+00 -2.6219192e-01  1.8056525e+00\n",
      "  6.2907892e-01 -6.0433549e-01 -1.9352870e+00 -2.0915093e+00\n",
      " -1.1181080e-01 -7.2162461e-01]\n",
      "إ: [-0.46204814 -0.39225438  1.8706625   1.0969328  -0.41974184 -1.9482186\n",
      " -0.40863782  0.31717375  3.3595345  -0.71946216 -0.5474473   0.2853821\n",
      " -0.8021296   0.6129379  -0.8663162   1.3724915   0.9949168  -1.2634863\n",
      " -0.12666659 -1.841855   -0.5862507   1.6649607  -0.35940656 -2.5167453\n",
      " -0.273788   -0.5331385   0.6055368  -0.4395008  -1.0325387   0.2700493\n",
      "  0.25278342  1.5958419   1.3038969   0.2578341  -0.7065994   0.5729668\n",
      " -0.11804759  0.17638946 -0.6118923   0.0432688   1.2127311  -1.102522\n",
      "  0.25899845  0.25082576 -1.0186963   0.45569545 -0.29124585 -0.6290103\n",
      " -2.0540855  -1.1638588 ]\n",
      "ت: [ 2.5075347   0.6236334   0.90568435  0.16848586 -0.27629375  0.41672587\n",
      "  1.0219034  -0.590595    0.57740515  0.69893247  0.10958314 -1.0673519\n",
      " -0.7916776  -1.0920037   0.2812008   0.5563709  -1.2597675  -0.4825673\n",
      "  0.04966333 -0.20487364  0.28473413  1.665928   -1.0185452  -0.46482784\n",
      "  0.25505912  1.5911195   0.32517758  2.0425127  -0.8818711  -0.35614198\n",
      "  0.11625297 -1.7201792  -0.38389614 -0.3185428   0.63706005 -0.56066126\n",
      "  1.6776625   0.5226293   1.3739736  -1.4034916   0.6967108  -0.31931978\n",
      "  1.9906173   0.72381514  0.16965483  0.41524577  1.6640579   0.25650185\n",
      " -0.48739737  0.02425874]\n",
      "ج: [-0.8773683  -0.648244    0.54669464  0.9451454  -1.1985304  -0.18406774\n",
      "  0.3009232  -1.3286102   0.33251482  0.15935369 -0.01834067  1.115293\n",
      " -0.13416709 -1.6863263  -1.2473098  -3.1272428   1.1990714  -0.21663055\n",
      "  0.41404766 -0.82042134  2.3156056  -0.79155314 -1.3909243  -0.16088097\n",
      " -0.12147421  0.61451685  0.00871574 -2.2106128   0.09846514 -0.31508285\n",
      " -0.2481339  -0.84763765  0.60508215 -0.71254754  0.42786297  0.9847301\n",
      "  0.92902833  0.28347507  0.44646475 -0.98401874 -1.9905034   0.5756825\n",
      "  1.2086841   2.1721702   1.246702   -0.44577014 -1.567083    1.8729064\n",
      "  0.74008304  0.3417343 ]\n",
      "ب: [-1.1624554  -0.44510326  3.4905355   1.0335563   0.67144316 -1.5160702\n",
      "  1.2577918   0.3747216  -0.58377314 -0.14966981  2.2508907   1.3324237\n",
      " -0.23685265 -0.10727869  0.48911235  1.0529896  -0.62612593 -0.40719357\n",
      "  2.0459733   0.38367543 -0.6492787   1.0933174  -1.1858498   2.1773279\n",
      "  0.6513321   0.6619895   0.077767   -0.04419552 -0.03011802 -0.8450129\n",
      "  1.0248823  -0.3258049  -1.7457968   0.6963107   0.790183    1.1768571\n",
      " -2.21815     0.50298464  0.46136454  0.48440397  0.2710512  -0.01055677\n",
      " -1.4784185   0.3243084  -0.17474432  0.18511704  1.1208714   0.4671421\n",
      " -0.1965545  -1.586106  ]\n",
      "ئ: [-0.18787163  0.3126625   0.6395906  -0.35787797  0.4301567   0.06457996\n",
      "  0.46796656 -0.45184952  0.5098812   1.382942    1.0831586  -1.7845552\n",
      "  1.2745141  -0.63837487  0.88488555  0.64450896 -1.1551166   1.9357036\n",
      "  0.04962921  1.4180571   0.69137186 -0.83366734 -0.75055254 -1.9406962\n",
      "  0.7160735  -1.6145177  -1.745867   -0.9611902   1.0912874  -0.15329167\n",
      " -0.5589477  -0.43191764  0.9487532  -1.1320008  -0.633118   -1.6333283\n",
      "  0.94617325  1.7353423  -0.03794978  0.83340895 -0.61486167  0.69060373\n",
      " -0.38560906  0.18017483 -0.05424971 -0.2299684  -1.252987    0.40697002\n",
      " -0.4310642   1.6361352 ]\n",
      "ا: [-2.6579458e-01 -5.9265047e-01 -4.9865910e-01 -7.5879037e-01\n",
      " -3.9856839e-01 -4.8338780e-01 -4.5817748e-02 -6.0931057e-02\n",
      " -5.2051228e-01 -1.1292818e+00  1.2088283e-03  9.3582964e-01\n",
      " -9.2170101e-01  1.4051608e+00  7.6829875e-01 -2.8003395e-01\n",
      " -6.2297243e-01  2.9656389e-01  2.1970735e+00  2.4622028e-01\n",
      " -1.7432411e+00  7.7486241e-01 -6.2109375e-01 -1.0389359e+00\n",
      " -1.2547584e+00  1.8520203e+00 -2.0029812e-01  3.5720187e-01\n",
      " -3.7303039e-01  4.6113503e-01  1.0269846e+00 -1.7230691e+00\n",
      "  1.4755839e+00  1.0806389e-01 -1.6949354e-01  7.9807055e-01\n",
      "  6.7597628e-01  8.4274691e-01  2.1550985e-01  3.6164525e-01\n",
      "  5.3289783e-01 -1.2121980e+00  9.3391228e-01  8.9907601e-02\n",
      "  1.6932298e-01 -1.5995675e-01 -2.0130940e-01  5.5501983e-02\n",
      "  5.7924896e-01  1.5378568e+00]\n",
      "د: [ 0.22151823 -0.64030385  0.7841503   0.84045154  1.6175357  -0.5153733\n",
      "  0.14176974  2.736002    0.70402133  0.21835405 -0.12275711  0.0820794\n",
      "  0.67234707 -0.7171144   0.01338166 -0.80561256  0.76041263  0.37695795\n",
      " -2.5636873   0.8312255  -1.295399    0.0123374  -1.3072929   0.6858836\n",
      " -0.6100996   0.30195445  0.47013342 -0.08185505  0.20064582 -0.22763853\n",
      " -1.725619    1.4962035   0.4616345  -0.6347236  -0.43486795 -1.000564\n",
      "  0.80040866 -2.0070136   0.86381185 -0.9547671  -0.27315104  0.6400845\n",
      " -0.76170534 -0.7150379   0.9609229  -0.41000083  0.02195401 -2.0504496\n",
      " -0.89407545  1.5697368 ]\n",
      "و: [-0.9761022   2.6029782   0.67294735  0.87039244 -1.8981936   0.72372127\n",
      " -0.83093816  0.32305142  2.7218986   0.9593488  -0.83612543  2.6150067\n",
      "  0.9644161   1.4184573  -1.5845536   1.3488005  -2.2972825  -0.684865\n",
      " -0.66999453  0.27810112 -0.07661461 -0.33381128 -0.03510003  0.95273507\n",
      " -1.138489   -0.6069011  -1.1586261  -0.5055454  -0.7445807  -1.0631361\n",
      "  1.0661657  -0.00723796  0.64804476 -0.01610766 -0.91687     1.1337659\n",
      " -0.7213653   0.16499999 -0.3378657   0.71032965  0.4612547  -0.35420662\n",
      "  1.4530768  -2.2506716   0.6916518   0.50100017  0.02136597  0.9920235\n",
      "  2.1007729   0.41312227]\n",
      "ء: [ 1.7903852   0.39387894 -0.30692446 -0.11942223  1.9501888  -0.08073168\n",
      "  0.42256477 -0.6492115  -0.78469044 -0.7353215  -0.40317014 -0.8564721\n",
      "  0.7495883   1.347764   -0.01654789  0.12623097  0.02933969 -0.9973253\n",
      "  0.5429645   0.77331865  0.16892146 -0.56770843  0.42168507 -0.10071008\n",
      " -0.14494158 -1.1867335  -1.1861097  -0.7606554   0.48997366 -0.5821116\n",
      "  0.51023436  0.04464062  0.26705366  0.95212716  1.0868556   0.297855\n",
      " -0.90821064 -1.4452204  -2.0315826   0.54382765  0.18353294  0.2677306\n",
      " -2.4074943   0.9205082  -0.24906592  1.0082605  -0.13689399 -1.5194424\n",
      "  2.2346408  -0.37512356]\n",
      "أ: [-1.3834193   0.4827291   0.64155036 -0.45969197 -0.555249    0.9876937\n",
      " -1.1342809   0.3202429   0.7376889   0.3982922  -0.72015446  0.44855905\n",
      "  0.990926    0.5827921   0.16528837  0.3353988  -0.39824292  0.64617825\n",
      "  2.2400236  -0.51332843 -1.3163762  -0.53456753 -0.35978192  1.1134154\n",
      " -0.8090594   0.46196303 -0.7540338   0.20279159 -1.8690186   1.8210253\n",
      "  0.03256652 -0.8378622   2.000081    0.38694242 -0.36084577 -0.36767483\n",
      "  0.28955236  1.3124385  -0.6506192   0.92464775 -0.18015078 -0.6274431\n",
      " -0.32731754  0.47783774  0.70610285  1.282441   -0.03798806  0.72297895\n",
      " -1.1743851   0.15116382]\n",
      "ز: [ 0.04452366  2.2037346   1.4737978  -0.36670208  1.636455    0.79114974\n",
      " -0.09373344 -1.0955049   0.5487637   0.02402351 -0.6366817  -1.2993553\n",
      "  0.36234057  0.3452315   0.42140895 -1.4981632   0.255708   -0.8204223\n",
      " -1.6367203   0.52755    -1.0050793   0.16118704 -1.8696742   1.1988647\n",
      "  1.1021668   0.42391366  0.6445365   0.14864245 -1.6862738   0.39770573\n",
      " -0.85925657 -0.6755525   1.0958743   0.7002887   0.41718507  1.3765589\n",
      " -1.1985835   0.22070496  1.7355745  -0.58259666  0.03057371  1.3614446\n",
      " -0.19928679 -1.7056484   0.5717676   0.6586195   0.40912515  0.8667381\n",
      " -1.2842437  -0.947363  ]\n",
      "ؤ: [-0.515335   -0.15588938 -0.22128941 -0.6325361   0.7395409  -1.3016819\n",
      " -2.1405966   1.6042993   0.29319152  1.4686943   0.41972828 -1.4332749\n",
      " -2.1693501  -1.2931652  -0.4721886  -1.1575347   0.35112315  0.5476619\n",
      " -0.20289622  0.71231824 -1.9104296   0.02035753  1.3470539  -0.03922762\n",
      " -0.08484918 -0.51597995 -1.7233139   1.6528746   1.5287749   0.11975038\n",
      "  1.0657929   0.80563635  0.85338116  0.0382457  -2.1322992   0.69329584\n",
      "  1.0081279  -1.2668114  -0.4395836  -0.55480146 -1.4407282  -1.0889072\n",
      "  0.58933026  0.26497853  0.15615664 -0.6810322  -1.0985514   0.29266542\n",
      "  2.1829307  -0.9487847 ]\n",
      "ذ: [-1.7439042   0.6683703  -0.04067383  1.053405    0.33909592  1.3164198\n",
      " -1.6666976  -1.2105522   0.5242098  -0.29151723 -0.49206015  2.3227973\n",
      " -0.1290995   0.3026169   0.50960606  0.1665958   0.17558905 -0.43035138\n",
      "  0.16893716  0.71465003 -0.71982956  1.6316605   0.5581523  -1.4558194\n",
      "  1.8290237  -0.42286637  0.8834074  -0.0310883  -0.04179884  1.0843637\n",
      " -0.034157   -0.1548143  -1.2665684  -1.2799962   1.06078     0.20639211\n",
      " -0.19124736  1.5615665   0.83987707 -1.4527957   0.8686002  -0.78455657\n",
      " -1.0092208  -0.5915087   1.3712761  -2.4615185   1.9753032   0.10542787\n",
      " -0.616484   -3.0612206 ]\n",
      "ك: [ 0.5120226  -0.00423171  0.2818158  -1.0503356  -0.9206461  -0.9832792\n",
      " -0.5166505   0.46787253 -1.2633556   1.5936741   0.42736298  1.3735867\n",
      "  0.24773626 -0.5068416   0.85073465  0.02386005  0.23269476  0.36013627\n",
      "  0.09574956  0.48989174 -0.0130436   0.43152815 -0.9681979  -0.49983695\n",
      "  0.49253145 -0.13646656 -1.1430262   0.82906836 -1.283118   -0.5074914\n",
      "  0.96128726 -0.3754229   1.4516431  -1.1937941  -1.0891029  -0.39022392\n",
      "  0.1558569   1.1825161  -0.5197305   0.80955875  1.2322928   0.4764701\n",
      " -0.49259657 -0.21587873  0.03419346  0.20823519 -1.4163209  -0.09618503\n",
      " -0.7045882   0.5282435 ]\n",
      "ة: [ 0.22159418 -0.46003    -0.26411504  0.9984159  -0.6424402  -0.73072594\n",
      " -0.05077218 -2.2269247  -1.4037423  -0.74611753  0.5835504   0.63381994\n",
      " -0.30417356 -0.53415424 -0.15556176  1.2270925   1.2822043   0.10461488\n",
      " -0.275905    0.37303582  1.0231775   0.37900397 -0.5779676  -1.7419252\n",
      " -0.69087875 -0.78458786 -0.14484137 -0.2552996  -0.9876531  -0.39622176\n",
      " -0.63341695 -1.0206653  -0.9741619  -0.15169258  1.2368872   0.6658681\n",
      " -1.1909167   0.16826811 -1.0855691   1.7316854  -0.2542294   0.7544581\n",
      "  0.20130283  1.9585383  -0.21432547 -1.6123842   0.9472348   0.79347557\n",
      "  0.4792252   0.4869404 ]\n",
      "ن: [ 0.9769488  -0.30184487 -1.4761559   0.46747395 -0.62882215  2.0490787\n",
      " -0.06848965  0.18035974  0.84919375 -0.9857541  -0.6973958   0.8698433\n",
      "  0.28173178 -0.07450381  0.35618094  1.2067496   0.3813253  -1.012178\n",
      " -0.36710322 -0.74435884  1.2009912   0.12825528 -0.35126832 -1.2291377\n",
      " -0.5166461   0.17902933  1.0468961  -0.10628203 -0.28827703 -0.8319875\n",
      "  0.8394789  -0.8405985   0.97682685  1.1482846  -0.8458649  -1.0462568\n",
      " -0.24665157 -1.6310359  -0.1169297  -1.7819246  -1.1214952  -1.8562164\n",
      "  0.66981894 -0.28616813  0.63987964  0.9021522  -2.1479619   0.20210737\n",
      "  0.8880768   0.8154967 ]\n",
      "ق: [-0.7181782  -0.64010876  1.0257989  -0.343692    1.2932506  -0.18344556\n",
      " -0.7592338   0.16875812  0.7376043  -0.05184226 -2.0313516   0.3222594\n",
      "  0.62620735 -0.75988233 -0.13360602  0.48912355 -0.31063876 -0.34824288\n",
      "  0.613674    1.7330275   0.04821638 -0.61234516 -0.5248448  -1.7470071\n",
      "  1.4479952   0.71629554 -0.57462835  0.7899659  -1.0227991   0.3282285\n",
      "  1.0710037   0.25602853 -1.1651403   0.6422637   0.7749197  -0.14679046\n",
      "  0.9326362  -1.6071991  -0.72074723 -0.37030068  0.47200525 -0.83358383\n",
      " -1.095208   -0.6132503  -1.0280081  -0.01290933 -0.14809023 -0.48210585\n",
      "  0.25121808 -0.6078326 ]\n",
      "ر: [ 0.08146859 -0.27601916 -0.52870435  0.11598615 -0.7015038   0.9522872\n",
      " -0.609695   -1.1057379   1.8220904   3.6290367  -0.04246606  1.1113967\n",
      "  1.5126946  -0.06889521  0.21418512  1.0102725   1.0842887   0.62939525\n",
      " -2.074103    1.2120695   0.8082018   0.28304482 -1.3338764   0.80987036\n",
      " -0.8468384   1.6240053  -0.34627053  0.62968767  1.9321445  -0.4829782\n",
      " -1.6441858   0.51662606 -0.37317672  0.16528882  0.17867057  0.32136664\n",
      " -1.2620878   1.0772148  -0.8837395   1.2547375   2.1088045  -0.6404078\n",
      "  0.6432106  -0.73220277  0.98878145 -0.2526262   0.6640424   0.4607701\n",
      " -0.36575863  0.2564905 ]\n",
      "آ: [-1.8507009  -0.2410301   0.06517349 -0.7620793  -0.08694467 -0.674815\n",
      " -1.1999474  -0.46655908 -0.6211649   1.8742735  -0.85812026 -0.5488169\n",
      "  1.4655807   0.21635772 -0.39158383 -1.3204089   1.9398348   0.24834447\n",
      " -0.4626738   0.4677321  -0.30112946  0.13807674 -1.1727797  -0.87969947\n",
      " -0.7104238   0.20913753 -1.4207163  -1.4586248   1.6352642  -2.2986286\n",
      " -2.5528562  -0.46311828 -0.34779516 -0.6441301   0.22292292  1.2390672\n",
      "  1.3422115   0.2523566   0.24609394  0.42265183  2.6755755   0.73587984\n",
      "  1.2280009   0.5631517  -0.91692317  0.18774791  1.1128827  -0.41542295\n",
      "  0.6538846   0.7573007 ]\n",
      "خ: [ 0.50415987  0.2032254   0.05743228  0.6903611  -1.1595488  -0.73711413\n",
      " -0.20177042 -0.6642377   0.14247127 -0.9533776  -0.9316655   1.1441324\n",
      "  0.75550425  0.05954493  0.46277383 -0.38401398 -1.4671402   0.13585244\n",
      "  0.88066876  2.2860975   1.3428032  -1.9168681   1.4190385  -1.4287465\n",
      " -1.2476295  -0.80389386  0.13691339 -0.1445029   0.1005393  -0.29243577\n",
      " -0.18184252 -0.61259776  0.26810777  1.6404433  -1.4882606   0.15104462\n",
      " -0.44746158 -0.46108618  2.410901    0.35537907  1.121873    0.720278\n",
      "  0.13718759  0.08423171  1.0601264  -1.9311216   0.6486991  -2.383726\n",
      "  0.7357326  -0.6465433 ]\n",
      "ع: [-0.6026139   0.15847811 -0.70784295  0.07577194  0.9160683   0.17177919\n",
      "  0.802621    0.11798994 -1.4442014   0.04259193 -0.77852046 -0.25934613\n",
      " -0.7290479   1.8286085   0.6231481   0.13876103  0.6995714   1.751304\n",
      "  0.22834511  1.3393239  -0.10638131 -2.095108   -0.6419957   0.11514172\n",
      "  1.3810871   0.25548157 -0.96101373 -1.0761333  -0.56873363 -0.5615898\n",
      "  1.1592853  -0.12590343 -0.8716978   0.1941735   1.6932817  -1.9310242\n",
      "  0.48008206  3.0179474   0.7662776  -0.24416131 -0.47507396  1.1570584\n",
      " -0.1954105  -0.81690633  0.31255236  0.3391504  -0.7834245   1.9593514\n",
      "  1.0213499  -0.37730294]\n",
      "ش: [-1.0179645  -0.69890124 -1.2597076   0.17338714  1.5099405   1.4242321\n",
      " -0.00506826 -1.6921358   0.49339372  0.37341183 -0.28351194 -0.72169363\n",
      " -0.07334426  1.6063367   0.4037074  -0.7309983   0.9801167   0.2705072\n",
      "  0.5928528   0.82898104  0.17347597 -2.2295072  -1.3524749   2.9704697\n",
      "  0.99821454 -0.4884725   0.55401754  0.79424644  0.76840216  0.41296032\n",
      " -0.14713044 -0.9006638  -0.78357637 -1.1120079   0.71511835  1.0516437\n",
      " -0.63020456 -2.2208154  -0.40350354  1.188581   -0.9993772   1.5201027\n",
      " -0.6588799   0.7915113  -0.64444804  1.1097953   0.08919785  1.34927\n",
      " -1.4677962  -2.013512  ]\n",
      "م: [-0.04761007  0.69141126 -1.2741398   1.0516089  -0.26807573  1.2389123\n",
      " -1.1053134   0.09779543 -0.7784955  -0.29915926 -0.6186234   0.6511039\n",
      "  0.60376364  0.82698447 -0.6041997   1.0612435   0.37895852  0.05467995\n",
      "  0.7054339   1.360727    0.54999566  0.7980474  -0.10441402 -0.38001055\n",
      "  0.3304857  -0.21447591 -1.1012816   0.0755398   0.8334647  -0.8207868\n",
      " -1.3127122   0.48948538  1.9037489  -1.3483764   0.56097597 -1.5049652\n",
      " -1.2859182   1.1394624   0.82098514  0.06753243  0.5063069   1.668987\n",
      "  2.0810494  -1.0535579  -0.837382   -0.67911315  0.6055706  -0.02073667\n",
      " -0.7456784  -1.4968146 ]\n",
      "ض: [ 0.59021735 -0.84953344 -0.45510694  0.3389657   0.12317691 -1.2062051\n",
      "  1.0714662  -0.3974392  -0.82832897  0.5334636   1.5752543   0.10961723\n",
      " -1.0462871   0.18169786  0.03170996  0.10795072  0.27621627 -0.7446281\n",
      " -0.8457781  -0.21266213  0.84963816  0.1749052   0.1775332  -0.22550327\n",
      " -0.56140965  2.1546352   0.5536228   1.4786223  -1.336609   -0.47867975\n",
      "  0.3258635  -1.0523512  -0.6934633  -0.19787836 -0.5641125  -1.5067657\n",
      "  0.3072661   1.6320072   0.83238786  1.6731765   1.8404545  -0.24625899\n",
      " -0.20956734  1.0924432   0.28497955 -0.82899445  0.776758   -1.4209521\n",
      "  0.28553522  0.12249792]\n"
     ]
    }
   ],
   "source": [
    "# Get character embeddings\n",
    "char_embeddings = cbow_model.embeddings.weight.detach().numpy()\n",
    "\n",
    "print(char_embeddings.shape)\n",
    "\n",
    "# Print character embeddings\n",
    "for idx, char in index_to_char.items():\n",
    "    print(f'{char}: {char_embeddings[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
