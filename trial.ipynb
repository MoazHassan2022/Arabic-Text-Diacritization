{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قولهأوقطعالأوليدهإلخقالالزركشيابنعرفةقولهبلفظيقتضيهكإنكارغيرحديثبالإسلاموجوبماعلموجوبهمنالدينضرورةكإ\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('dataset/cleaned_train_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_train_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_lines = file.readlines()\n",
    "\n",
    "training_data = \"\"\n",
    "for line in training_data_lines:\n",
    "    training_data += ''.join(line.split()).strip()\n",
    "training_data_diacritized = \"\"\n",
    "for line in training_data_diacritized_lines:\n",
    "    training_data_diacritized += ''.join(line.split()).strip()\n",
    "validation_data = \"\"\n",
    "for line in validation_data_lines:\n",
    "    validation_data += ''.join(line.split()).strip()\n",
    "validation_data_diacritized = \"\"\n",
    "for line in validation_data_diacritized_lines:\n",
    "    validation_data_diacritized += ''.join(line.split()).strip()\n",
    "    \n",
    "print(training_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the labels and their corresponding indices\n",
    "labels = {\n",
    "    # fatha\n",
    "    '\\u064E':0,\n",
    "    # damma\n",
    "    '\\u064F':1,\n",
    "    # kasra\n",
    "    '\\u0650':2,\n",
    "    # shadda\n",
    "    '\\u0651':3,\n",
    "    # sukun\n",
    "    '\\u0652':4,\n",
    "    # tanween_fatha\n",
    "    '\\u064B':5,\n",
    "    # tanween_damma\n",
    "    '\\u064C':6,\n",
    "    # tanween_kasra\n",
    "    '\\u064D':7\n",
    "}\n",
    "\n",
    "sequence_to_labels = {\n",
    "    # fatha\n",
    "    0:'\\u064E',\n",
    "    # damma\n",
    "    1:'\\u064F',\n",
    "    # kasra\n",
    "    2:'\\u0650',\n",
    "    # shadda\n",
    "    3:'\\u0651',\n",
    "    # sukun\n",
    "    4:'\\u0652',\n",
    "    # tanween_fatha\n",
    "    5:'\\u064B',\n",
    "    # tanween_damma\n",
    "    6:'\\u064C',\n",
    "    # tanween_kasra\n",
    "    7:'\\u064D'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ى': 0, 'ل': 1, 'ط': 2, 'ه': 3, 'ث': 4, 'س': 5, 'ف': 6, 'ظ': 7, 'غ': 8, 'ح': 9, 'ي': 10, 'ص': 11, 'إ': 12, 'ت': 13, 'ج': 14, 'ب': 15, 'ئ': 16, 'ا': 17, 'د': 18, 'و': 19, 'ء': 20, 'أ': 21, 'ز': 22, 'ؤ': 23, 'ذ': 24, 'ك': 25, 'ة': 26, 'ن': 27, 'ق': 28, 'ر': 29, 'آ': 30, 'خ': 31, 'ع': 32, 'ش': 33, 'م': 34, 'ض': 35}\n",
      "Number of unique characters:  36\n",
      "{'ى', 'ل', 'ط', 'ه', 'ث', 'س', 'ف', 'ظ', 'غ', 'ح', 'ي', 'ص', 'إ', 'ت', 'ج', 'ب', 'ئ', 'ا', 'د', 'و', 'ء', 'أ', 'ز', 'ؤ', 'ذ', 'ك', 'ة', 'ن', 'ق', 'ر', 'آ', 'خ', 'ع', 'ش', 'م', 'ض'}\n",
      "[28, 19, 1, 3, 21, 19, 28, 2, 32, 17]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into sequences at the character level\n",
    "unique_chars = set(''.join(training_data + validation_data))\n",
    "diacritization = list(labels.keys())\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "index_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "print(char_to_index)\n",
    "\n",
    "def text_to_sequence(text):\n",
    "    return [char_to_index[char] for char in text]\n",
    "\n",
    "train_sequence = text_to_sequence(training_data)\n",
    "validation_sequences = text_to_sequence(validation_data)\n",
    "\n",
    "print(\"Number of unique characters: \", len(unique_chars))\n",
    "print(unique_chars)\n",
    "print(train_sequence[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW(\n",
      "  (embeddings): Embedding(36, 20)\n",
      "  (linear): Linear(in_features=20, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Implementing word embedding using CBOW\n",
    "# CBOW context window size\n",
    "context_window = 1\n",
    "\n",
    "# Define CBOW model\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        # embedding layer \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # linear layer\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # The forward method specifies how data flows through the model.\n",
    "        embedded = self.embeddings(context).sum(dim=1)\n",
    "        output = self.linear(embedded)\n",
    "        # now, output is of size [batch_size, vocab_size], we want it to be of size [1, vocab_size]\n",
    "        # no problem, as it contains arrays, each array of size [1, vocab_size], and all elements of the arrays are the same\n",
    "        output = output.squeeze(0)[:1, :]\n",
    "        return output\n",
    "    \n",
    "# Instantiate CBOW model\n",
    "embedding_dim = 20\n",
    "vocab_size = len(unique_chars)\n",
    "cbow_model = CBOW(vocab_size, embedding_dim)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "cbow_model = cbow_model.to(device)\n",
    "\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 578282.0670684576\n",
      "Epoch 2/3, Loss: 575837.2111845016\n",
      "Epoch 3/3, Loss: 575845.1363406181\n"
     ]
    }
   ],
   "source": [
    "# Training the CBOW model\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# The Adam optimizer is an extension to stochastic gradient descent\n",
    "optimizer = optim.SGD(cbow_model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "# TODO: make it 50\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(context_window, len(train_sequence) - context_window):\n",
    "        # get context window, and get 1-hot encoding for each character in the window\n",
    "        context = torch.tensor(train_sequence[i-context_window:i] + train_sequence[i+1:i+1+context_window])\n",
    "        # create 1-hot encoding for each position in the context array\n",
    "        context = torch.nn.functional.one_hot(context, num_classes=vocab_size)\n",
    "        # get target character\n",
    "        target = torch.tensor([train_sequence[i]])\n",
    "        # create 1-hot encoding for target character\n",
    "        target = torch.nn.functional.one_hot(target, num_classes=vocab_size).float()\n",
    "        \n",
    "        # Move tensors to GPU if available\n",
    "        context, target = context.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = cbow_model(context)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 20)\n",
      "ى: [-0.02491802  0.03899876 -0.0858681  -0.05633762 -0.01706139 -0.00362067\n",
      " -0.00908654 -0.04218103  0.01387355 -0.01394024  0.0263774   0.00491693\n",
      " -0.0042674   0.01571666  0.07048664  0.02466692  0.01340346  0.01285902\n",
      "  0.06158666  0.0092001 ]\n",
      "ل: [-0.530507    0.4280205   0.62792784  2.230431    0.39901805  0.90821904\n",
      "  0.5206144   1.1459837   0.42858866  1.4255207  -0.7981823  -0.65918475\n",
      "  0.56598693 -0.12815654  0.12077828 -0.69428    -1.1426365  -1.6433033\n",
      " -0.21235164 -0.4322641 ]\n",
      "ط: [-1.3274553   0.9719781  -1.3855953  -0.02773895 -0.27838656 -1.1500709\n",
      "  1.051754    0.53278327 -1.4847202   0.6330003  -0.37871987  0.32195097\n",
      "  0.20924708 -0.49564987 -2.1044495  -1.3350732  -0.37433508  1.0329229\n",
      " -0.67105204 -0.25660402]\n",
      "ه: [ 1.5211954  -1.4997439   0.64794385  0.2514645  -0.7202958   0.8731724\n",
      "  0.47653553  1.475459    0.42314875  0.90437627  0.57568526 -0.2645905\n",
      "  0.2805538  -0.14809914 -0.38314816 -1.5234482  -0.8347636  -0.10202003\n",
      "  0.7203185   0.04670541]\n",
      "ث: [-0.5884517   0.9144036  -0.9941744  -0.75279397  0.17645212  0.32793924\n",
      "  0.5845402   0.66803855  0.53756326  0.60653937  2.004862    1.4527321\n",
      "  0.576557    0.06514768 -0.8980901   0.02319272  1.9647824  -1.5026889\n",
      " -0.5355513   0.18188101]\n",
      "س: [-0.18285103 -0.08582148 -0.29478166  1.4660999   2.1223516   0.08269177\n",
      "  0.08721611  0.08790605  2.6113706   0.52153057 -1.5812328  -0.46107\n",
      "  0.28744447 -1.6532035  -1.8420388  -0.12302239  2.127262   -0.8213263\n",
      "  0.31381634 -1.7244538 ]\n",
      "ف: [ 1.4311182  -0.9786896   1.460334    0.4295704  -0.73810244  0.8357171\n",
      "  0.40148386 -1.9004631  -0.03731754 -0.5378758   0.5088984   0.2796663\n",
      "  0.23467076 -0.6022391   0.02053991 -0.7449528  -0.8031995   0.28811\n",
      "  1.8604679  -0.1820042 ]\n",
      "ظ: [ 1.0615455  -0.848957   -0.80964917  1.0029274   1.1422989   0.17594868\n",
      "  0.7310592  -1.1675165  -0.6750878  -0.7409957   1.121703    0.8655165\n",
      "  1.1264247  -0.6533809  -2.1736598  -0.7341088  -0.6379571  -0.4106153\n",
      "  0.6132259   0.33260635]\n",
      "غ: [-1.1265279   0.8884243   1.7222013   0.16379912 -0.11834965  0.37726766\n",
      "  2.0414736   0.91966987 -0.25808945 -2.269263   -2.9202754   0.27777258\n",
      " -0.46223396  0.44489667 -0.44589487 -0.60612804  0.19586316 -0.99770606\n",
      " -0.71333027  0.30701223]\n",
      "ح: [ 0.09958977  1.3125302   0.16474484 -0.74022    -0.15051672 -0.7838214\n",
      "  0.5384362  -1.5014347   0.7977347  -0.21532716 -0.6727707   2.454144\n",
      " -0.4276143   0.05977108 -0.6299645   0.8060288   0.5937304   0.60431504\n",
      " -0.2022441   1.0274734 ]\n",
      "ي: [-0.66496694  1.0230402  -0.51440537 -1.1531123   0.02581535  1.3134739\n",
      " -1.4467378   0.7985477  -0.06962252  0.5312092   1.0418189  -0.53711295\n",
      " -0.57190984  0.6513591  -2.053138   -0.28183246 -0.2399646   0.2628529\n",
      "  0.3142394   0.21815848]\n",
      "ص: [-2.9224870e-01 -9.4630986e-01  2.3077287e-01  1.1750538e+00\n",
      " -2.5421554e-01 -1.2990806e+00 -2.8883478e-01 -2.1060027e-01\n",
      " -1.3666067e+00 -6.7464125e-01 -4.2317227e-01 -2.0278364e-03\n",
      "  8.9787459e-01 -8.5152298e-01 -1.0859125e+00 -6.7268538e-01\n",
      "  6.1584103e-01  1.8120942e+00 -1.4138147e+00 -2.1147354e+00]\n",
      "إ: [-1.3156347  -0.5532026  -0.4171754   1.4158592   2.1743574   0.7112373\n",
      " -0.17256156  0.8696095   0.09460492  3.2816432  -0.04084814 -1.1238118\n",
      " -1.5001774  -0.88064563 -0.28227952 -0.7572609  -0.42546546 -0.423296\n",
      "  0.13845101  1.1622804 ]\n",
      "ت: [ 0.3994302  -1.4393858  -0.32676873  0.9564201  -1.9134573  -1.0779209\n",
      "  0.9953936  -1.4582272  -0.4574555  -1.0146587  -1.2756792   2.104737\n",
      "  0.04768682  0.44391355 -2.4018834   0.29809552  0.7272299   0.4939671\n",
      "  0.4959876   0.7670768 ]\n",
      "ج: [-0.38038376 -0.86378163 -1.3243799  -0.38814938  0.6921884   0.1538235\n",
      " -0.08685709 -0.3367451  -0.5607375   0.12912053  0.7537703  -0.5799976\n",
      "  0.61983824  0.90819234 -0.47257504 -0.9175141  -0.48511183  1.257933\n",
      " -0.8362495   2.0941484 ]\n",
      "ب: [-0.82578844  0.0445065  -1.0837362   1.5298442   1.5000616  -0.53982645\n",
      "  0.17328154  1.4560934  -0.9266572  -0.8175301  -0.5843818  -0.44704893\n",
      " -1.5405171   0.00537883 -0.09986006  0.10406119 -0.1876078   0.80892485\n",
      " -0.35464823 -1.9953597 ]\n",
      "ئ: [-0.28476346  1.2277232   0.28425506  1.5276155   2.431151   -1.1679051\n",
      " -0.6874137   1.0955521   1.6083012   0.47213262 -0.02184482  1.3048418\n",
      "  0.1427015  -0.48278895  0.15932652  1.213028    0.7313864   1.2185476\n",
      " -0.36031008 -0.62747854]\n",
      "ا: [-0.501994   -0.5400418   0.42129233 -1.5220126  -0.7129474  -1.5015049\n",
      " -2.1801715   0.2951713  -0.54549193  1.6487129   1.2780659  -0.22531798\n",
      " -0.7302016   2.006325   -0.6687967  -1.0127196  -1.4114321  -0.17635727\n",
      " -1.5017723   0.09518766]\n",
      "د: [ 0.9744637  -2.260021   -0.13982563  1.4998494  -0.54645205 -1.3534662\n",
      "  1.3567578  -1.2394592  -0.28594136  1.4837394  -0.34074876 -1.7501355\n",
      " -2.5039628  -0.74660754  0.46483564 -0.521262    3.26614    -1.8671923\n",
      "  0.36427015 -0.5883449 ]\n",
      "و: [-0.9852135  -0.59582067 -2.073349    0.12068009  0.0097671   0.06030437\n",
      "  0.5706057  -0.8407909  -0.5693434  -0.4013235   0.46145365  0.40579012\n",
      " -0.8583963   0.83421844  0.8777865   0.80994475 -0.7829282   0.40594798\n",
      " -0.70453936  1.6917189 ]\n",
      "ء: [-0.97593015 -1.3530436  -1.0265561   0.4704537  -1.4356767   2.2194178\n",
      "  0.8085142  -0.2899938  -1.764196   -0.7116725  -0.42857137  0.29972675\n",
      "  0.77774656 -0.6859968   0.2100819  -0.6516252  -0.8499133   0.5438745\n",
      "  2.035436    0.6537657 ]\n",
      "أ: [ 1.1459705  -1.3113843  -2.1304874   0.8058519   2.3519678   0.9061781\n",
      "  0.4538042   1.681012    0.14083181 -1.0339086   0.47953343  0.52946\n",
      "  0.08327677 -0.75658554  0.8768628  -0.488514   -0.20124052 -0.99661946\n",
      "  1.334096   -0.04991787]\n",
      "ز: [ 1.3598586  -0.45653194 -0.41330078 -1.1681544  -0.48114485  0.4226967\n",
      "  0.54863495 -1.6750605  -0.05018903  0.72993946  0.03541064  0.9007834\n",
      "  0.04078123 -0.02933133 -0.71146965 -0.08598683 -0.17774753 -0.2550305\n",
      " -0.6446048   1.4764241 ]\n",
      "ؤ: [-1.939835    1.4975197   0.24277253  0.5043818  -0.58133596 -0.4852781\n",
      "  0.58074087  1.2900844   1.0421749   0.6801562   0.11947732  0.42493454\n",
      " -0.04179359  2.5315294   1.0209434  -0.65950114 -1.3603656   0.717332\n",
      " -0.8177514   1.198185  ]\n",
      "ذ: [ 0.5792007   1.3600742  -0.48827693 -0.45353264  1.2222542  -1.1796553\n",
      " -1.4730638  -0.8323476  -0.58504     0.38434216  0.16336325 -0.4008281\n",
      "  1.210406    2.1568425   0.27094007  1.1005771  -1.0569385  -0.3094458\n",
      "  1.436538    0.07361337]\n",
      "ك: [-0.4877926  -0.27631634  0.25907162 -0.14624852 -1.4167986  -0.9295455\n",
      "  0.07622926 -0.8830794  -0.1336896   0.3532669   0.5653217   0.4125884\n",
      " -0.5589232  -0.68656206  0.4083765   1.1597091  -0.28859118 -0.60998905\n",
      " -1.2465338   0.79637724]\n",
      "ة: [ 0.9264135   2.0777643  -0.9299633   3.0240862   1.09259     2.2539818\n",
      " -0.583986   -1.7292465  -1.0796525  -0.50966185 -0.80513227 -1.9030209\n",
      " -0.47626793  0.54687905  0.20822407  0.41804817  0.02806692  0.36448774\n",
      "  0.46969107 -0.58340794]\n",
      "ن: [-0.94338125 -0.1127754  -0.00449528  1.2639779   1.2718642   1.1055831\n",
      "  0.997217    0.81731856 -1.4001906   0.7897858   1.0931407   0.5984391\n",
      "  0.3280607  -0.30630922  0.58551186 -0.50669664  0.38601747 -0.5787797\n",
      "  0.13576128  1.8804224 ]\n",
      "ق: [ 0.5678023  -0.09995629 -0.13170268 -0.21648733  0.1366303   0.8983836\n",
      " -0.27757403 -0.09396125 -0.95944285 -1.4655592  -0.32415774  0.03706026\n",
      "  0.66456866 -0.53545976  0.26240662 -0.5814559   1.0043406  -0.2787616\n",
      " -1.0675654  -0.14444743]\n",
      "ر: [ 0.24160938  2.1387873   0.05336482 -0.0671714  -0.03222551  1.4329519\n",
      " -0.32816938 -1.5886159  -0.83728886 -0.70432484  0.2592438  -1.2703096\n",
      " -1.1856219  -1.1632588  -0.8009939  -0.08350214 -0.9591349  -0.6072733\n",
      " -0.5552153  -1.8651255 ]\n",
      "آ: [-0.7310049   1.7578431  -0.79592085 -0.6742526  -0.5099132   0.2609314\n",
      "  1.2060614  -0.7720326   0.76558745  2.5788271  -0.31503654  0.18293028\n",
      "  1.5875274   1.2764888  -1.5632311   1.0265051  -0.19878311  0.10054414\n",
      "  0.6232345   1.0372422 ]\n",
      "خ: [-0.5356095   1.287146   -0.78147364  1.2684156  -0.59524375 -1.9861598\n",
      " -0.7845337   0.00585918 -0.9012099  -0.9079951  -0.16233069 -1.5356752\n",
      " -0.1143513   1.1888905   0.46719813  0.14733918  2.078655    0.44791403\n",
      " -1.6630013   0.5504395 ]\n",
      "ع: [ 8.69869411e-01  7.13039100e-01 -4.14076418e-01  7.29632616e-01\n",
      "  1.68712914e+00  1.90526628e+00  1.05164659e+00  5.04680991e-01\n",
      "  7.53068924e-01 -6.74782612e-04 -4.82181042e-01 -1.18047798e+00\n",
      "  1.01560795e+00  3.14031810e-01  6.78516999e-02 -7.02427551e-02\n",
      "  9.80446339e-01  1.11879736e-01  2.92835653e-01 -1.94821608e+00]\n",
      "ش: [ 0.67714584 -1.1263671   0.4535201   0.8026707   0.11013842 -0.8075421\n",
      "  0.4907048   0.6383291   0.12930535 -0.25872144  0.9767754   1.7422438\n",
      "  0.75682753  2.259246   -0.57142234  0.41838357 -0.63299775 -1.2736408\n",
      "  1.2800246   0.3523401 ]\n",
      "م: [-2.3865802   1.3654909  -0.2086912  -0.41265982 -1.2857214  -1.203329\n",
      " -0.7336501   0.48817897 -0.3391885   0.21115695  0.339717    0.30019736\n",
      " -0.4633064  -0.2714937   0.41051966  0.25363725 -0.13432425  0.7033017\n",
      " -0.4762524   0.8115516 ]\n",
      "ض: [ 0.7747471   0.52797437 -0.33064258  1.1941265  -0.64378613 -0.5199803\n",
      "  0.21608834 -1.7735046  -1.4557463  -0.01495739 -1.0254965  -0.89123154\n",
      "  0.02689638 -1.0148044  -0.09700958  1.0177908   0.1641328  -0.04313956\n",
      " -0.5405619   1.8502918 ]\n"
     ]
    }
   ],
   "source": [
    "# Get character embeddings\n",
    "char_embeddings = cbow_model.embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "print(char_embeddings.shape)\n",
    "\n",
    "# Print character embeddings\n",
    "for idx, char in index_to_char.items():\n",
    "    print(f'{char}: {char_embeddings[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
