{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قولهأوقطعالأوليدهإلخقالالزركشيابنعرفةقولهبلفظيقتضيهكإنكارغيرحديثبالإسلاموجوبماعلموجوبهمنالدينضرورةكإ\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "with open('dataset/cleaned_train_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_train_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_diacritized_lines = file.readlines()\n",
    "with open('dataset/cleaned_val_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    validation_data_lines = file.readlines()\n",
    "\n",
    "training_data = \"\"\n",
    "for line in training_data_lines:\n",
    "    training_data += ''.join(line.split()).strip()\n",
    "training_data_diacritized = \"\"\n",
    "for line in training_data_diacritized_lines:\n",
    "    training_data_diacritized += ''.join(line.split()).strip()\n",
    "validation_data = \"\"\n",
    "for line in validation_data_lines:\n",
    "    validation_data += ''.join(line.split()).strip()\n",
    "validation_data_diacritized = \"\"\n",
    "for line in validation_data_diacritized_lines:\n",
    "    validation_data_diacritized += ''.join(line.split()).strip()\n",
    "    \n",
    "print(training_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the labels and their corresponding indices\n",
    "labels = {\n",
    "    # fatha\n",
    "    '\\u064E':0,\n",
    "    # damma\n",
    "    '\\u064F':1,\n",
    "    # kasra\n",
    "    '\\u0650':2,\n",
    "    # shadda\n",
    "    '\\u0651':3,\n",
    "    # sukun\n",
    "    '\\u0652':4,\n",
    "    # tanween_fatha\n",
    "    '\\u064B':5,\n",
    "    # tanween_damma\n",
    "    '\\u064C':6,\n",
    "    # tanween_kasra\n",
    "    '\\u064D':7\n",
    "}\n",
    "\n",
    "sequence_to_labels = {\n",
    "    # fatha\n",
    "    0:'\\u064E',\n",
    "    # damma\n",
    "    1:'\\u064F',\n",
    "    # kasra\n",
    "    2:'\\u0650',\n",
    "    # shadda\n",
    "    3:'\\u0651',\n",
    "    # sukun\n",
    "    4:'\\u0652',\n",
    "    # tanween_fatha\n",
    "    5:'\\u064B',\n",
    "    # tanween_damma\n",
    "    6:'\\u064C',\n",
    "    # tanween_kasra\n",
    "    7:'\\u064D'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ح': 0, 'ى': 1, 'إ': 2, 'ز': 3, 'ذ': 4, 'آ': 5, 'ف': 6, 'ن': 7, 'س': 8, 'د': 9, 'ع': 10, 'ظ': 11, 'ا': 12, 'ؤ': 13, 'ط': 14, 'غ': 15, 'ة': 16, 'ئ': 17, 'ش': 18, 'م': 19, 'ك': 20, 'ق': 21, 'خ': 22, 'أ': 23, 'ث': 24, 'ء': 25, 'ه': 26, 'ص': 27, 'و': 28, 'ي': 29, 'ب': 30, 'ج': 31, 'ل': 32, 'ض': 33, 'ر': 34, 'ت': 35}\n",
      "Number of unique characters:  36\n",
      "{'ح', 'ى', 'إ', 'ز', 'ذ', 'آ', 'ف', 'ن', 'س', 'د', 'ع', 'ظ', 'ا', 'ؤ', 'ط', 'غ', 'ة', 'ئ', 'ش', 'م', 'ك', 'ق', 'خ', 'أ', 'ث', 'ء', 'ه', 'ص', 'و', 'ي', 'ب', 'ج', 'ل', 'ض', 'ر', 'ت'}\n",
      "[21, 28, 32, 26, 23, 28, 21, 14, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into sequences at the character level\n",
    "unique_chars = set(''.join(training_data + validation_data))\n",
    "diacritization = list(labels.keys())\n",
    "\n",
    "char_to_index = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "index_to_char = {idx: char for idx, char in enumerate(unique_chars)}\n",
    "\n",
    "print(char_to_index)\n",
    "\n",
    "def text_to_sequence(text):\n",
    "    return [char_to_index[char] for char in text]\n",
    "\n",
    "train_sequence = text_to_sequence(training_data)\n",
    "validation_sequences = text_to_sequence(validation_data)\n",
    "\n",
    "print(\"Number of unique characters: \", len(unique_chars))\n",
    "print(unique_chars)\n",
    "print(train_sequence[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "# CBOW context window size\n",
    "context_window = 5\n",
    "learning_rate = 0.01\n",
    "embedding_dim = 100\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW(\n",
      "  (embeddings): Embedding(36, 100)\n",
      "  (linear): Linear(in_features=100, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Implementing word embedding using CBOW\n",
    "\n",
    "# Define CBOW model\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        # embedding layer \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # linear layer\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # The forward method specifies how data flows through the model.\n",
    "        # now, embedded is of size [batch_size, embedded_dim], we want it to be of size [1, embedded_dim]\n",
    "        # no problem, as it contains arrays, each array of size [1, embedded_dim], and all elements of the arrays are the same\n",
    "        embedded = self.embeddings(context).mean(dim=1).squeeze(0)[:1, :]\n",
    "        output = self.linear(embedded)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        return probabilities\n",
    "    \n",
    "# Instantiate CBOW model\n",
    "vocab_size = len(unique_chars)\n",
    "cbow_model = CBOW(vocab_size, embedding_dim)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to GPU if available\n",
    "cbow_model = cbow_model.to(device)\n",
    "\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0315, 0.0129, 0.0162, 0.0326, 0.0226, 0.0202, 0.0319, 0.0206, 0.0324,\n",
      "         0.0175, 0.0184, 0.0305, 0.0154, 0.0649, 0.0062, 0.0389, 0.0529, 0.0199,\n",
      "         0.0198, 0.0100, 0.0206, 0.0330, 0.0202, 0.0313, 0.0137, 0.0452, 0.0055,\n",
      "         0.0581, 0.0176, 0.0304, 0.0166, 0.0232, 0.0244, 0.0482, 0.0400, 0.0566]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0315, 0.0129, 0.0162, 0.0326, 0.0226, 0.0202, 0.0319, 0.0206, 0.0324,\n",
      "         0.0175, 0.0184, 0.0305, 0.0154, 0.0649, 0.0062, 0.0389, 0.0529, 0.0199,\n",
      "         0.0198, 0.0100, 0.0206, 0.0330, 0.0202, 0.0313, 0.0137, 0.0452, 0.0055,\n",
      "         0.0580, 0.0179, 0.0304, 0.0166, 0.0232, 0.0244, 0.0482, 0.0400, 0.0566]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0326, 0.0225, 0.0202, 0.0319, 0.0206, 0.0324,\n",
      "         0.0175, 0.0184, 0.0305, 0.0154, 0.0648, 0.0062, 0.0388, 0.0528, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0202, 0.0312, 0.0137, 0.0451, 0.0055,\n",
      "         0.0580, 0.0179, 0.0304, 0.0166, 0.0232, 0.0244, 0.0481, 0.0400, 0.0565]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0326, 0.0226, 0.0202, 0.0319, 0.0206, 0.0324,\n",
      "         0.0175, 0.0184, 0.0305, 0.0154, 0.0648, 0.0063, 0.0388, 0.0528, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0202, 0.0312, 0.0137, 0.0451, 0.0055,\n",
      "         0.0579, 0.0179, 0.0304, 0.0166, 0.0232, 0.0244, 0.0481, 0.0400, 0.0565]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0326, 0.0225, 0.0202, 0.0318, 0.0206, 0.0324,\n",
      "         0.0175, 0.0187, 0.0305, 0.0154, 0.0647, 0.0063, 0.0388, 0.0528, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0202, 0.0312, 0.0137, 0.0451, 0.0055,\n",
      "         0.0579, 0.0179, 0.0304, 0.0166, 0.0232, 0.0244, 0.0481, 0.0399, 0.0565]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0326, 0.0225, 0.0202, 0.0318, 0.0206, 0.0324,\n",
      "         0.0175, 0.0187, 0.0305, 0.0156, 0.0647, 0.0063, 0.0388, 0.0527, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0202, 0.0312, 0.0137, 0.0451, 0.0055,\n",
      "         0.0579, 0.0179, 0.0304, 0.0166, 0.0232, 0.0244, 0.0480, 0.0399, 0.0564]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0326, 0.0225, 0.0202, 0.0318, 0.0206, 0.0324,\n",
      "         0.0175, 0.0187, 0.0304, 0.0156, 0.0646, 0.0063, 0.0388, 0.0527, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0202, 0.0312, 0.0137, 0.0451, 0.0055,\n",
      "         0.0578, 0.0179, 0.0304, 0.0166, 0.0232, 0.0249, 0.0480, 0.0399, 0.0564]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0324,\n",
      "         0.0175, 0.0187, 0.0304, 0.0156, 0.0645, 0.0063, 0.0387, 0.0526, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0201, 0.0321, 0.0137, 0.0450, 0.0055,\n",
      "         0.0577, 0.0179, 0.0304, 0.0166, 0.0232, 0.0249, 0.0479, 0.0399, 0.0563]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0324,\n",
      "         0.0175, 0.0187, 0.0304, 0.0156, 0.0644, 0.0063, 0.0387, 0.0526, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0339, 0.0201, 0.0321, 0.0137, 0.0450, 0.0055,\n",
      "         0.0577, 0.0181, 0.0304, 0.0166, 0.0232, 0.0249, 0.0479, 0.0399, 0.0563]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0323,\n",
      "         0.0175, 0.0187, 0.0304, 0.0156, 0.0643, 0.0063, 0.0387, 0.0525, 0.0198,\n",
      "         0.0198, 0.0100, 0.0206, 0.0338, 0.0201, 0.0320, 0.0137, 0.0450, 0.0055,\n",
      "         0.0576, 0.0181, 0.0303, 0.0166, 0.0232, 0.0255, 0.0479, 0.0398, 0.0562]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0323,\n",
      "         0.0175, 0.0187, 0.0304, 0.0156, 0.0642, 0.0063, 0.0387, 0.0525, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0201, 0.0320, 0.0137, 0.0449, 0.0055,\n",
      "         0.0575, 0.0181, 0.0311, 0.0166, 0.0232, 0.0254, 0.0478, 0.0398, 0.0561]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0323,\n",
      "         0.0177, 0.0187, 0.0304, 0.0156, 0.0642, 0.0063, 0.0386, 0.0525, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0201, 0.0320, 0.0137, 0.0449, 0.0055,\n",
      "         0.0575, 0.0181, 0.0311, 0.0166, 0.0232, 0.0254, 0.0478, 0.0398, 0.0561]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0162, 0.0325, 0.0225, 0.0202, 0.0318, 0.0205, 0.0323,\n",
      "         0.0177, 0.0187, 0.0304, 0.0156, 0.0642, 0.0063, 0.0386, 0.0524, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0201, 0.0320, 0.0137, 0.0449, 0.0055,\n",
      "         0.0575, 0.0181, 0.0311, 0.0166, 0.0232, 0.0254, 0.0478, 0.0398, 0.0561]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0325, 0.0225, 0.0202, 0.0317, 0.0205, 0.0323,\n",
      "         0.0177, 0.0187, 0.0304, 0.0156, 0.0641, 0.0063, 0.0386, 0.0524, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0201, 0.0320, 0.0137, 0.0449, 0.0055,\n",
      "         0.0575, 0.0181, 0.0311, 0.0166, 0.0232, 0.0254, 0.0478, 0.0398, 0.0560]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0325, 0.0225, 0.0202, 0.0317, 0.0205, 0.0323,\n",
      "         0.0177, 0.0187, 0.0304, 0.0156, 0.0641, 0.0063, 0.0386, 0.0524, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0201, 0.0320, 0.0137, 0.0448, 0.0055,\n",
      "         0.0574, 0.0181, 0.0311, 0.0166, 0.0232, 0.0260, 0.0477, 0.0397, 0.0560]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0325, 0.0225, 0.0202, 0.0317, 0.0205, 0.0323,\n",
      "         0.0177, 0.0187, 0.0304, 0.0156, 0.0640, 0.0063, 0.0386, 0.0523, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0338, 0.0205, 0.0320, 0.0137, 0.0448, 0.0055,\n",
      "         0.0574, 0.0181, 0.0311, 0.0166, 0.0232, 0.0260, 0.0477, 0.0397, 0.0559]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0324, 0.0225, 0.0202, 0.0317, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0156, 0.0639, 0.0063, 0.0385, 0.0523, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0320, 0.0137, 0.0448, 0.0055,\n",
      "         0.0573, 0.0181, 0.0311, 0.0166, 0.0232, 0.0260, 0.0476, 0.0397, 0.0559]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0324, 0.0225, 0.0202, 0.0317, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0158, 0.0638, 0.0063, 0.0385, 0.0522, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0319, 0.0137, 0.0447, 0.0055,\n",
      "         0.0572, 0.0181, 0.0311, 0.0166, 0.0232, 0.0260, 0.0476, 0.0397, 0.0558]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0324, 0.0225, 0.0202, 0.0317, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0158, 0.0637, 0.0063, 0.0385, 0.0522, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0319, 0.0137, 0.0447, 0.0055,\n",
      "         0.0572, 0.0181, 0.0311, 0.0166, 0.0231, 0.0266, 0.0476, 0.0396, 0.0558]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0129, 0.0164, 0.0324, 0.0225, 0.0202, 0.0317, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0160, 0.0637, 0.0063, 0.0385, 0.0522, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0319, 0.0137, 0.0447, 0.0055,\n",
      "         0.0571, 0.0181, 0.0311, 0.0166, 0.0231, 0.0266, 0.0476, 0.0396, 0.0557]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0129, 0.0164, 0.0324, 0.0225, 0.0202, 0.0317, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0160, 0.0636, 0.0063, 0.0385, 0.0521, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0319, 0.0137, 0.0446, 0.0055,\n",
      "         0.0571, 0.0181, 0.0310, 0.0166, 0.0231, 0.0272, 0.0475, 0.0396, 0.0557]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0129, 0.0164, 0.0333, 0.0225, 0.0201, 0.0316, 0.0205, 0.0322,\n",
      "         0.0177, 0.0187, 0.0303, 0.0160, 0.0635, 0.0063, 0.0384, 0.0520, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0347, 0.0205, 0.0319, 0.0137, 0.0446, 0.0055,\n",
      "         0.0570, 0.0181, 0.0310, 0.0166, 0.0231, 0.0272, 0.0474, 0.0396, 0.0556]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0316, 0.0205, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0160, 0.0634, 0.0063, 0.0384, 0.0519, 0.0198,\n",
      "         0.0198, 0.0100, 0.0205, 0.0346, 0.0204, 0.0318, 0.0136, 0.0445, 0.0055,\n",
      "         0.0569, 0.0181, 0.0310, 0.0166, 0.0231, 0.0271, 0.0474, 0.0409, 0.0555]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0316, 0.0205, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0160, 0.0633, 0.0063, 0.0384, 0.0519, 0.0198,\n",
      "         0.0198, 0.0100, 0.0209, 0.0346, 0.0204, 0.0318, 0.0136, 0.0445, 0.0055,\n",
      "         0.0568, 0.0181, 0.0310, 0.0166, 0.0231, 0.0271, 0.0473, 0.0409, 0.0554]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0316, 0.0205, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0160, 0.0632, 0.0063, 0.0383, 0.0518, 0.0198,\n",
      "         0.0201, 0.0100, 0.0209, 0.0346, 0.0204, 0.0318, 0.0136, 0.0445, 0.0055,\n",
      "         0.0568, 0.0181, 0.0310, 0.0166, 0.0231, 0.0271, 0.0473, 0.0409, 0.0554]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0315, 0.0205, 0.0321,\n",
      "         0.0177, 0.0186, 0.0302, 0.0160, 0.0631, 0.0063, 0.0383, 0.0518, 0.0198,\n",
      "         0.0201, 0.0100, 0.0208, 0.0346, 0.0204, 0.0318, 0.0136, 0.0444, 0.0055,\n",
      "         0.0567, 0.0181, 0.0318, 0.0166, 0.0231, 0.0271, 0.0473, 0.0408, 0.0553]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0315, 0.0205, 0.0321,\n",
      "         0.0177, 0.0186, 0.0302, 0.0162, 0.0631, 0.0063, 0.0383, 0.0518, 0.0198,\n",
      "         0.0201, 0.0100, 0.0208, 0.0346, 0.0204, 0.0318, 0.0136, 0.0444, 0.0055,\n",
      "         0.0567, 0.0181, 0.0318, 0.0166, 0.0231, 0.0271, 0.0472, 0.0408, 0.0553]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0315, 0.0205, 0.0321,\n",
      "         0.0177, 0.0186, 0.0302, 0.0162, 0.0631, 0.0063, 0.0383, 0.0517, 0.0198,\n",
      "         0.0201, 0.0100, 0.0208, 0.0345, 0.0204, 0.0318, 0.0136, 0.0444, 0.0055,\n",
      "         0.0566, 0.0181, 0.0318, 0.0168, 0.0231, 0.0271, 0.0472, 0.0408, 0.0552]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0315, 0.0208, 0.0321,\n",
      "         0.0177, 0.0186, 0.0302, 0.0162, 0.0630, 0.0063, 0.0383, 0.0517, 0.0198,\n",
      "         0.0201, 0.0100, 0.0208, 0.0345, 0.0204, 0.0318, 0.0136, 0.0444, 0.0055,\n",
      "         0.0566, 0.0181, 0.0318, 0.0168, 0.0231, 0.0271, 0.0472, 0.0408, 0.0552]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0332, 0.0224, 0.0201, 0.0315, 0.0208, 0.0321,\n",
      "         0.0177, 0.0190, 0.0302, 0.0162, 0.0629, 0.0063, 0.0383, 0.0517, 0.0198,\n",
      "         0.0201, 0.0100, 0.0208, 0.0345, 0.0204, 0.0318, 0.0136, 0.0443, 0.0055,\n",
      "         0.0565, 0.0181, 0.0318, 0.0168, 0.0231, 0.0271, 0.0472, 0.0408, 0.0552]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0129, 0.0164, 0.0331, 0.0224, 0.0201, 0.0315, 0.0208, 0.0320,\n",
      "         0.0177, 0.0189, 0.0301, 0.0162, 0.0628, 0.0063, 0.0382, 0.0516, 0.0197,\n",
      "         0.0201, 0.0100, 0.0208, 0.0345, 0.0204, 0.0317, 0.0136, 0.0443, 0.0055,\n",
      "         0.0564, 0.0181, 0.0317, 0.0168, 0.0231, 0.0271, 0.0471, 0.0422, 0.0550]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0129, 0.0164, 0.0331, 0.0224, 0.0201, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0189, 0.0301, 0.0162, 0.0627, 0.0063, 0.0382, 0.0515, 0.0197,\n",
      "         0.0201, 0.0100, 0.0208, 0.0344, 0.0204, 0.0317, 0.0136, 0.0442, 0.0055,\n",
      "         0.0563, 0.0181, 0.0317, 0.0168, 0.0230, 0.0270, 0.0470, 0.0421, 0.0550]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0129, 0.0164, 0.0330, 0.0223, 0.0200, 0.0323, 0.0208, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0162, 0.0625, 0.0063, 0.0381, 0.0537, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0344, 0.0204, 0.0316, 0.0136, 0.0441, 0.0055,\n",
      "         0.0561, 0.0180, 0.0316, 0.0168, 0.0230, 0.0270, 0.0469, 0.0420, 0.0548]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0330, 0.0223, 0.0200, 0.0322, 0.0207, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0623, 0.0063, 0.0380, 0.0536, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0354, 0.0203, 0.0316, 0.0136, 0.0440, 0.0055,\n",
      "         0.0560, 0.0180, 0.0316, 0.0168, 0.0230, 0.0270, 0.0468, 0.0419, 0.0547]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0330, 0.0223, 0.0200, 0.0322, 0.0207, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0623, 0.0063, 0.0380, 0.0536, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0354, 0.0203, 0.0316, 0.0136, 0.0440, 0.0055,\n",
      "         0.0560, 0.0183, 0.0316, 0.0168, 0.0230, 0.0270, 0.0468, 0.0419, 0.0547]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0330, 0.0223, 0.0200, 0.0322, 0.0207, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0622, 0.0063, 0.0380, 0.0535, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0353, 0.0203, 0.0316, 0.0136, 0.0440, 0.0055,\n",
      "         0.0559, 0.0183, 0.0316, 0.0168, 0.0230, 0.0276, 0.0467, 0.0419, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0330, 0.0223, 0.0200, 0.0322, 0.0207, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0622, 0.0063, 0.0380, 0.0535, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0353, 0.0203, 0.0316, 0.0136, 0.0440, 0.0056,\n",
      "         0.0559, 0.0183, 0.0316, 0.0168, 0.0230, 0.0276, 0.0467, 0.0419, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0329, 0.0223, 0.0200, 0.0322, 0.0207, 0.0319,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0621, 0.0063, 0.0380, 0.0535, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0353, 0.0203, 0.0316, 0.0136, 0.0440, 0.0056,\n",
      "         0.0559, 0.0183, 0.0316, 0.0170, 0.0230, 0.0276, 0.0467, 0.0419, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0164, 0.0329, 0.0223, 0.0200, 0.0322, 0.0207, 0.0318,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0621, 0.0063, 0.0379, 0.0534, 0.0197,\n",
      "         0.0200, 0.0100, 0.0208, 0.0353, 0.0203, 0.0316, 0.0136, 0.0439, 0.0056,\n",
      "         0.0558, 0.0183, 0.0315, 0.0170, 0.0230, 0.0282, 0.0467, 0.0418, 0.0545]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0163, 0.0329, 0.0223, 0.0200, 0.0331, 0.0207, 0.0318,\n",
      "         0.0176, 0.0189, 0.0300, 0.0161, 0.0620, 0.0063, 0.0379, 0.0533, 0.0197,\n",
      "         0.0200, 0.0100, 0.0207, 0.0353, 0.0203, 0.0315, 0.0136, 0.0439, 0.0056,\n",
      "         0.0557, 0.0183, 0.0315, 0.0170, 0.0229, 0.0282, 0.0466, 0.0418, 0.0544]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0129, 0.0163, 0.0329, 0.0223, 0.0200, 0.0330, 0.0207, 0.0318,\n",
      "         0.0176, 0.0189, 0.0307, 0.0161, 0.0619, 0.0063, 0.0379, 0.0533, 0.0197,\n",
      "         0.0200, 0.0100, 0.0207, 0.0352, 0.0203, 0.0315, 0.0136, 0.0438, 0.0056,\n",
      "         0.0557, 0.0183, 0.0315, 0.0170, 0.0229, 0.0282, 0.0466, 0.0418, 0.0543]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0129, 0.0163, 0.0328, 0.0223, 0.0200, 0.0330, 0.0207, 0.0318,\n",
      "         0.0176, 0.0189, 0.0307, 0.0161, 0.0618, 0.0063, 0.0378, 0.0532, 0.0197,\n",
      "         0.0200, 0.0100, 0.0207, 0.0352, 0.0203, 0.0315, 0.0136, 0.0438, 0.0056,\n",
      "         0.0556, 0.0183, 0.0323, 0.0170, 0.0229, 0.0282, 0.0465, 0.0417, 0.0543]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0129, 0.0163, 0.0328, 0.0223, 0.0200, 0.0330, 0.0207, 0.0317,\n",
      "         0.0176, 0.0188, 0.0307, 0.0161, 0.0616, 0.0063, 0.0378, 0.0531, 0.0196,\n",
      "         0.0200, 0.0100, 0.0207, 0.0363, 0.0203, 0.0315, 0.0136, 0.0437, 0.0056,\n",
      "         0.0555, 0.0183, 0.0323, 0.0170, 0.0229, 0.0282, 0.0464, 0.0417, 0.0542]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0128, 0.0163, 0.0327, 0.0222, 0.0199, 0.0329, 0.0207, 0.0317,\n",
      "         0.0175, 0.0188, 0.0306, 0.0161, 0.0614, 0.0063, 0.0377, 0.0529, 0.0196,\n",
      "         0.0199, 0.0099, 0.0207, 0.0362, 0.0203, 0.0314, 0.0136, 0.0436, 0.0056,\n",
      "         0.0553, 0.0182, 0.0322, 0.0170, 0.0229, 0.0281, 0.0463, 0.0415, 0.0566]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0128, 0.0163, 0.0327, 0.0222, 0.0199, 0.0328, 0.0206, 0.0316,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0612, 0.0063, 0.0376, 0.0528, 0.0196,\n",
      "         0.0199, 0.0099, 0.0206, 0.0361, 0.0202, 0.0313, 0.0136, 0.0435, 0.0055,\n",
      "         0.0551, 0.0182, 0.0322, 0.0169, 0.0228, 0.0281, 0.0481, 0.0414, 0.0564]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0163, 0.0326, 0.0222, 0.0199, 0.0328, 0.0206, 0.0316,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0611, 0.0063, 0.0376, 0.0527, 0.0196,\n",
      "         0.0199, 0.0099, 0.0206, 0.0361, 0.0202, 0.0313, 0.0135, 0.0434, 0.0055,\n",
      "         0.0551, 0.0182, 0.0331, 0.0169, 0.0228, 0.0280, 0.0480, 0.0414, 0.0564]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0163, 0.0326, 0.0222, 0.0199, 0.0328, 0.0206, 0.0316,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0611, 0.0063, 0.0376, 0.0527, 0.0196,\n",
      "         0.0199, 0.0099, 0.0206, 0.0361, 0.0202, 0.0313, 0.0136, 0.0434, 0.0056,\n",
      "         0.0550, 0.0182, 0.0331, 0.0169, 0.0228, 0.0280, 0.0480, 0.0414, 0.0563]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0163, 0.0326, 0.0222, 0.0199, 0.0328, 0.0206, 0.0316,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0610, 0.0063, 0.0376, 0.0527, 0.0196,\n",
      "         0.0199, 0.0099, 0.0210, 0.0361, 0.0202, 0.0313, 0.0136, 0.0434, 0.0056,\n",
      "         0.0550, 0.0182, 0.0331, 0.0169, 0.0228, 0.0280, 0.0480, 0.0414, 0.0563]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0165, 0.0326, 0.0222, 0.0199, 0.0328, 0.0206, 0.0316,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0610, 0.0063, 0.0375, 0.0526, 0.0196,\n",
      "         0.0199, 0.0099, 0.0210, 0.0361, 0.0202, 0.0313, 0.0136, 0.0434, 0.0056,\n",
      "         0.0550, 0.0182, 0.0330, 0.0169, 0.0228, 0.0280, 0.0480, 0.0414, 0.0563]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0165, 0.0326, 0.0222, 0.0199, 0.0328, 0.0210, 0.0315,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0609, 0.0063, 0.0375, 0.0526, 0.0196,\n",
      "         0.0199, 0.0099, 0.0210, 0.0360, 0.0202, 0.0313, 0.0136, 0.0434, 0.0056,\n",
      "         0.0549, 0.0182, 0.0330, 0.0169, 0.0228, 0.0280, 0.0479, 0.0413, 0.0562]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0165, 0.0326, 0.0222, 0.0199, 0.0328, 0.0210, 0.0315,\n",
      "         0.0175, 0.0188, 0.0305, 0.0161, 0.0609, 0.0063, 0.0375, 0.0526, 0.0196,\n",
      "         0.0199, 0.0099, 0.0214, 0.0360, 0.0202, 0.0313, 0.0136, 0.0433, 0.0056,\n",
      "         0.0549, 0.0182, 0.0330, 0.0169, 0.0228, 0.0280, 0.0479, 0.0413, 0.0562]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0165, 0.0326, 0.0222, 0.0199, 0.0328, 0.0210, 0.0315,\n",
      "         0.0175, 0.0188, 0.0305, 0.0163, 0.0609, 0.0063, 0.0375, 0.0525, 0.0196,\n",
      "         0.0199, 0.0099, 0.0214, 0.0360, 0.0202, 0.0313, 0.0136, 0.0433, 0.0056,\n",
      "         0.0549, 0.0182, 0.0330, 0.0169, 0.0228, 0.0280, 0.0479, 0.0413, 0.0562]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0128, 0.0165, 0.0326, 0.0221, 0.0199, 0.0327, 0.0210, 0.0315,\n",
      "         0.0175, 0.0188, 0.0304, 0.0163, 0.0607, 0.0063, 0.0374, 0.0524, 0.0195,\n",
      "         0.0199, 0.0099, 0.0214, 0.0360, 0.0202, 0.0312, 0.0135, 0.0432, 0.0056,\n",
      "         0.0547, 0.0182, 0.0330, 0.0169, 0.0228, 0.0280, 0.0478, 0.0428, 0.0560]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0128, 0.0165, 0.0325, 0.0221, 0.0199, 0.0327, 0.0209, 0.0315,\n",
      "         0.0175, 0.0187, 0.0304, 0.0163, 0.0606, 0.0063, 0.0386, 0.0523, 0.0195,\n",
      "         0.0198, 0.0099, 0.0214, 0.0359, 0.0202, 0.0312, 0.0135, 0.0432, 0.0056,\n",
      "         0.0546, 0.0182, 0.0329, 0.0169, 0.0228, 0.0279, 0.0477, 0.0427, 0.0559]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0128, 0.0165, 0.0325, 0.0221, 0.0199, 0.0326, 0.0209, 0.0314,\n",
      "         0.0175, 0.0187, 0.0304, 0.0163, 0.0605, 0.0063, 0.0386, 0.0522, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0359, 0.0202, 0.0311, 0.0135, 0.0431, 0.0056,\n",
      "         0.0545, 0.0182, 0.0339, 0.0169, 0.0228, 0.0279, 0.0477, 0.0426, 0.0558]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0128, 0.0165, 0.0324, 0.0221, 0.0198, 0.0326, 0.0209, 0.0314,\n",
      "         0.0175, 0.0187, 0.0303, 0.0162, 0.0603, 0.0063, 0.0385, 0.0521, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0358, 0.0201, 0.0311, 0.0135, 0.0430, 0.0056,\n",
      "         0.0544, 0.0181, 0.0338, 0.0169, 0.0227, 0.0279, 0.0476, 0.0442, 0.0557]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0128, 0.0165, 0.0324, 0.0221, 0.0198, 0.0326, 0.0209, 0.0314,\n",
      "         0.0175, 0.0187, 0.0303, 0.0162, 0.0602, 0.0063, 0.0385, 0.0521, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0358, 0.0201, 0.0311, 0.0135, 0.0430, 0.0056,\n",
      "         0.0543, 0.0181, 0.0338, 0.0169, 0.0227, 0.0279, 0.0475, 0.0441, 0.0556]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0128, 0.0165, 0.0324, 0.0221, 0.0198, 0.0326, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0162, 0.0602, 0.0063, 0.0385, 0.0520, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0358, 0.0201, 0.0311, 0.0135, 0.0430, 0.0056,\n",
      "         0.0543, 0.0181, 0.0338, 0.0169, 0.0227, 0.0279, 0.0475, 0.0441, 0.0556]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0164, 0.0324, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0162, 0.0601, 0.0063, 0.0384, 0.0519, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0135, 0.0429, 0.0056,\n",
      "         0.0542, 0.0181, 0.0348, 0.0169, 0.0227, 0.0278, 0.0474, 0.0441, 0.0555]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0164, 0.0324, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0162, 0.0600, 0.0063, 0.0384, 0.0519, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0429, 0.0056,\n",
      "         0.0542, 0.0181, 0.0348, 0.0169, 0.0227, 0.0278, 0.0474, 0.0440, 0.0555]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0165, 0.0324, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0162, 0.0600, 0.0063, 0.0384, 0.0519, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0429, 0.0056,\n",
      "         0.0542, 0.0181, 0.0347, 0.0171, 0.0227, 0.0278, 0.0474, 0.0440, 0.0554]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0165, 0.0324, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0165, 0.0600, 0.0063, 0.0384, 0.0519, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0429, 0.0056,\n",
      "         0.0541, 0.0181, 0.0347, 0.0171, 0.0227, 0.0278, 0.0474, 0.0440, 0.0554]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0164, 0.0323, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0165, 0.0599, 0.0063, 0.0384, 0.0518, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0428, 0.0056,\n",
      "         0.0541, 0.0181, 0.0347, 0.0171, 0.0227, 0.0285, 0.0473, 0.0440, 0.0553]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0167, 0.0323, 0.0221, 0.0198, 0.0325, 0.0209, 0.0313,\n",
      "         0.0177, 0.0187, 0.0303, 0.0165, 0.0598, 0.0063, 0.0384, 0.0518, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0428, 0.0056,\n",
      "         0.0540, 0.0181, 0.0347, 0.0171, 0.0227, 0.0285, 0.0473, 0.0440, 0.0553]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0325, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0165, 0.0598, 0.0063, 0.0383, 0.0517, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0357, 0.0201, 0.0310, 0.0137, 0.0428, 0.0056,\n",
      "         0.0540, 0.0181, 0.0347, 0.0171, 0.0227, 0.0285, 0.0472, 0.0439, 0.0552]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0165, 0.0597, 0.0063, 0.0383, 0.0517, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0356, 0.0201, 0.0310, 0.0137, 0.0427, 0.0056,\n",
      "         0.0539, 0.0181, 0.0347, 0.0171, 0.0227, 0.0292, 0.0472, 0.0439, 0.0551]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0596, 0.0063, 0.0383, 0.0516, 0.0195,\n",
      "         0.0198, 0.0099, 0.0213, 0.0356, 0.0201, 0.0310, 0.0137, 0.0427, 0.0056,\n",
      "         0.0539, 0.0181, 0.0346, 0.0171, 0.0227, 0.0292, 0.0472, 0.0439, 0.0551]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0596, 0.0063, 0.0383, 0.0516, 0.0195,\n",
      "         0.0198, 0.0100, 0.0213, 0.0356, 0.0201, 0.0310, 0.0137, 0.0427, 0.0056,\n",
      "         0.0539, 0.0181, 0.0346, 0.0171, 0.0227, 0.0292, 0.0471, 0.0438, 0.0551]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0596, 0.0063, 0.0383, 0.0516, 0.0195,\n",
      "         0.0198, 0.0100, 0.0213, 0.0356, 0.0201, 0.0310, 0.0137, 0.0427, 0.0056,\n",
      "         0.0538, 0.0184, 0.0346, 0.0171, 0.0227, 0.0292, 0.0471, 0.0438, 0.0551]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0323, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0595, 0.0063, 0.0382, 0.0515, 0.0195,\n",
      "         0.0198, 0.0100, 0.0213, 0.0356, 0.0201, 0.0309, 0.0137, 0.0427, 0.0056,\n",
      "         0.0538, 0.0184, 0.0346, 0.0171, 0.0231, 0.0292, 0.0471, 0.0438, 0.0550]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0595, 0.0063, 0.0382, 0.0515, 0.0195,\n",
      "         0.0198, 0.0100, 0.0213, 0.0356, 0.0201, 0.0309, 0.0137, 0.0427, 0.0056,\n",
      "         0.0538, 0.0187, 0.0346, 0.0171, 0.0231, 0.0292, 0.0471, 0.0438, 0.0550]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0594, 0.0063, 0.0382, 0.0515, 0.0195,\n",
      "         0.0198, 0.0100, 0.0213, 0.0356, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0537, 0.0187, 0.0346, 0.0174, 0.0231, 0.0291, 0.0470, 0.0438, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0167, 0.0594, 0.0063, 0.0382, 0.0515, 0.0195,\n",
      "         0.0198, 0.0101, 0.0213, 0.0356, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0537, 0.0187, 0.0346, 0.0174, 0.0231, 0.0291, 0.0470, 0.0438, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0209, 0.0321,\n",
      "         0.0177, 0.0187, 0.0302, 0.0169, 0.0594, 0.0063, 0.0382, 0.0515, 0.0195,\n",
      "         0.0198, 0.0101, 0.0213, 0.0356, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0537, 0.0187, 0.0346, 0.0174, 0.0231, 0.0291, 0.0470, 0.0437, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0209, 0.0320,\n",
      "         0.0177, 0.0190, 0.0302, 0.0169, 0.0593, 0.0063, 0.0382, 0.0514, 0.0195,\n",
      "         0.0198, 0.0101, 0.0213, 0.0355, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0536, 0.0187, 0.0346, 0.0174, 0.0231, 0.0291, 0.0470, 0.0437, 0.0549]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0324, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0592, 0.0063, 0.0382, 0.0514, 0.0195,\n",
      "         0.0198, 0.0101, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0536, 0.0187, 0.0345, 0.0174, 0.0231, 0.0299, 0.0469, 0.0437, 0.0548]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0592, 0.0063, 0.0382, 0.0513, 0.0195,\n",
      "         0.0198, 0.0102, 0.0213, 0.0355, 0.0201, 0.0309, 0.0137, 0.0426, 0.0056,\n",
      "         0.0536, 0.0187, 0.0345, 0.0174, 0.0231, 0.0299, 0.0469, 0.0437, 0.0548]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0592, 0.0063, 0.0381, 0.0513, 0.0195,\n",
      "         0.0198, 0.0102, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0535, 0.0190, 0.0345, 0.0174, 0.0231, 0.0299, 0.0469, 0.0436, 0.0547]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0591, 0.0063, 0.0381, 0.0513, 0.0194,\n",
      "         0.0198, 0.0102, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0535, 0.0190, 0.0345, 0.0174, 0.0236, 0.0299, 0.0469, 0.0436, 0.0547]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0591, 0.0063, 0.0381, 0.0512, 0.0194,\n",
      "         0.0198, 0.0102, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0534, 0.0193, 0.0345, 0.0174, 0.0236, 0.0298, 0.0468, 0.0436, 0.0547]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0590, 0.0063, 0.0381, 0.0512, 0.0194,\n",
      "         0.0198, 0.0102, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0534, 0.0193, 0.0345, 0.0176, 0.0236, 0.0298, 0.0468, 0.0436, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0590, 0.0063, 0.0381, 0.0512, 0.0194,\n",
      "         0.0198, 0.0102, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0534, 0.0193, 0.0345, 0.0176, 0.0236, 0.0298, 0.0468, 0.0436, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0322, 0.0220, 0.0198, 0.0323, 0.0208, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0590, 0.0063, 0.0381, 0.0512, 0.0194,\n",
      "         0.0198, 0.0103, 0.0212, 0.0355, 0.0201, 0.0309, 0.0137, 0.0425, 0.0056,\n",
      "         0.0534, 0.0193, 0.0345, 0.0176, 0.0236, 0.0298, 0.0468, 0.0436, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0323, 0.0212, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0169, 0.0590, 0.0063, 0.0381, 0.0512, 0.0194,\n",
      "         0.0198, 0.0103, 0.0212, 0.0354, 0.0201, 0.0308, 0.0137, 0.0424, 0.0056,\n",
      "         0.0534, 0.0193, 0.0345, 0.0176, 0.0235, 0.0298, 0.0468, 0.0435, 0.0546]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0323, 0.0212, 0.0320,\n",
      "         0.0177, 0.0190, 0.0301, 0.0172, 0.0589, 0.0063, 0.0381, 0.0511, 0.0194,\n",
      "         0.0198, 0.0103, 0.0212, 0.0354, 0.0201, 0.0308, 0.0137, 0.0424, 0.0056,\n",
      "         0.0533, 0.0193, 0.0345, 0.0176, 0.0235, 0.0298, 0.0468, 0.0435, 0.0545]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0323, 0.0212, 0.0319,\n",
      "         0.0177, 0.0190, 0.0301, 0.0172, 0.0588, 0.0063, 0.0380, 0.0511, 0.0194,\n",
      "         0.0198, 0.0103, 0.0212, 0.0354, 0.0201, 0.0308, 0.0137, 0.0424, 0.0056,\n",
      "         0.0533, 0.0193, 0.0344, 0.0176, 0.0235, 0.0306, 0.0467, 0.0435, 0.0545]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0323, 0.0212, 0.0319,\n",
      "         0.0180, 0.0190, 0.0301, 0.0172, 0.0588, 0.0063, 0.0380, 0.0510, 0.0194,\n",
      "         0.0198, 0.0103, 0.0212, 0.0354, 0.0201, 0.0308, 0.0137, 0.0424, 0.0056,\n",
      "         0.0532, 0.0193, 0.0344, 0.0176, 0.0235, 0.0306, 0.0467, 0.0435, 0.0544]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0322, 0.0212, 0.0319,\n",
      "         0.0180, 0.0190, 0.0300, 0.0172, 0.0587, 0.0063, 0.0380, 0.0510, 0.0194,\n",
      "         0.0197, 0.0103, 0.0212, 0.0354, 0.0201, 0.0308, 0.0137, 0.0423, 0.0056,\n",
      "         0.0531, 0.0193, 0.0355, 0.0176, 0.0235, 0.0306, 0.0466, 0.0434, 0.0543]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0128, 0.0167, 0.0321, 0.0220, 0.0198, 0.0322, 0.0216, 0.0319,\n",
      "         0.0180, 0.0190, 0.0300, 0.0172, 0.0586, 0.0063, 0.0379, 0.0509, 0.0194,\n",
      "         0.0197, 0.0103, 0.0212, 0.0353, 0.0201, 0.0308, 0.0137, 0.0423, 0.0056,\n",
      "         0.0531, 0.0193, 0.0354, 0.0176, 0.0235, 0.0305, 0.0466, 0.0434, 0.0543]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0128, 0.0166, 0.0320, 0.0219, 0.0197, 0.0322, 0.0216, 0.0318,\n",
      "         0.0179, 0.0189, 0.0300, 0.0172, 0.0585, 0.0063, 0.0379, 0.0508, 0.0194,\n",
      "         0.0197, 0.0103, 0.0212, 0.0353, 0.0200, 0.0307, 0.0137, 0.0422, 0.0056,\n",
      "         0.0529, 0.0193, 0.0354, 0.0176, 0.0235, 0.0305, 0.0484, 0.0433, 0.0541]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0128, 0.0166, 0.0320, 0.0219, 0.0197, 0.0321, 0.0215, 0.0318,\n",
      "         0.0179, 0.0189, 0.0299, 0.0171, 0.0583, 0.0063, 0.0378, 0.0507, 0.0194,\n",
      "         0.0197, 0.0103, 0.0212, 0.0352, 0.0200, 0.0307, 0.0136, 0.0421, 0.0056,\n",
      "         0.0528, 0.0192, 0.0353, 0.0176, 0.0234, 0.0304, 0.0483, 0.0449, 0.0540]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0128, 0.0166, 0.0320, 0.0219, 0.0197, 0.0321, 0.0215, 0.0318,\n",
      "         0.0179, 0.0189, 0.0299, 0.0171, 0.0583, 0.0063, 0.0378, 0.0506, 0.0194,\n",
      "         0.0197, 0.0103, 0.0212, 0.0352, 0.0200, 0.0307, 0.0136, 0.0421, 0.0056,\n",
      "         0.0528, 0.0196, 0.0353, 0.0176, 0.0234, 0.0304, 0.0483, 0.0448, 0.0540]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0128, 0.0166, 0.0319, 0.0219, 0.0197, 0.0320, 0.0215, 0.0317,\n",
      "         0.0179, 0.0189, 0.0299, 0.0171, 0.0581, 0.0063, 0.0377, 0.0505, 0.0194,\n",
      "         0.0197, 0.0103, 0.0211, 0.0351, 0.0200, 0.0306, 0.0136, 0.0420, 0.0056,\n",
      "         0.0527, 0.0195, 0.0352, 0.0175, 0.0234, 0.0304, 0.0482, 0.0465, 0.0538]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0166, 0.0318, 0.0218, 0.0197, 0.0320, 0.0215, 0.0317,\n",
      "         0.0179, 0.0189, 0.0298, 0.0171, 0.0579, 0.0063, 0.0376, 0.0526, 0.0193,\n",
      "         0.0196, 0.0103, 0.0211, 0.0351, 0.0199, 0.0306, 0.0136, 0.0419, 0.0056,\n",
      "         0.0525, 0.0195, 0.0352, 0.0175, 0.0234, 0.0303, 0.0480, 0.0464, 0.0537]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0166, 0.0318, 0.0218, 0.0197, 0.0320, 0.0215, 0.0316,\n",
      "         0.0179, 0.0189, 0.0298, 0.0171, 0.0579, 0.0063, 0.0376, 0.0526, 0.0193,\n",
      "         0.0196, 0.0103, 0.0215, 0.0350, 0.0199, 0.0305, 0.0136, 0.0419, 0.0056,\n",
      "         0.0525, 0.0195, 0.0351, 0.0175, 0.0234, 0.0303, 0.0480, 0.0464, 0.0536]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0168, 0.0318, 0.0218, 0.0197, 0.0320, 0.0215, 0.0316,\n",
      "         0.0179, 0.0189, 0.0298, 0.0171, 0.0578, 0.0063, 0.0376, 0.0526, 0.0193,\n",
      "         0.0196, 0.0103, 0.0215, 0.0350, 0.0199, 0.0305, 0.0136, 0.0418, 0.0056,\n",
      "         0.0524, 0.0195, 0.0351, 0.0175, 0.0234, 0.0303, 0.0480, 0.0464, 0.0536]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0168, 0.0318, 0.0218, 0.0196, 0.0319, 0.0215, 0.0316,\n",
      "         0.0179, 0.0188, 0.0298, 0.0171, 0.0577, 0.0063, 0.0376, 0.0525, 0.0193,\n",
      "         0.0196, 0.0103, 0.0215, 0.0350, 0.0199, 0.0305, 0.0136, 0.0418, 0.0056,\n",
      "         0.0524, 0.0195, 0.0351, 0.0175, 0.0234, 0.0311, 0.0479, 0.0463, 0.0535]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0168, 0.0318, 0.0218, 0.0196, 0.0319, 0.0214, 0.0316,\n",
      "         0.0179, 0.0188, 0.0298, 0.0171, 0.0576, 0.0063, 0.0375, 0.0524, 0.0193,\n",
      "         0.0196, 0.0102, 0.0215, 0.0361, 0.0199, 0.0305, 0.0136, 0.0418, 0.0056,\n",
      "         0.0523, 0.0195, 0.0351, 0.0175, 0.0233, 0.0311, 0.0478, 0.0462, 0.0534]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0127, 0.0168, 0.0318, 0.0218, 0.0196, 0.0319, 0.0214, 0.0316,\n",
      "         0.0179, 0.0188, 0.0298, 0.0173, 0.0576, 0.0063, 0.0375, 0.0524, 0.0193,\n",
      "         0.0196, 0.0102, 0.0215, 0.0360, 0.0199, 0.0305, 0.0136, 0.0417, 0.0056,\n",
      "         0.0522, 0.0195, 0.0351, 0.0175, 0.0233, 0.0311, 0.0478, 0.0462, 0.0534]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0127, 0.0168, 0.0317, 0.0218, 0.0196, 0.0318, 0.0214, 0.0315,\n",
      "         0.0178, 0.0188, 0.0297, 0.0173, 0.0575, 0.0063, 0.0374, 0.0523, 0.0193,\n",
      "         0.0196, 0.0102, 0.0214, 0.0360, 0.0199, 0.0304, 0.0136, 0.0432, 0.0056,\n",
      "         0.0521, 0.0195, 0.0350, 0.0175, 0.0233, 0.0310, 0.0477, 0.0461, 0.0533]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0127, 0.0168, 0.0317, 0.0218, 0.0196, 0.0318, 0.0214, 0.0315,\n",
      "         0.0178, 0.0188, 0.0297, 0.0173, 0.0574, 0.0063, 0.0374, 0.0523, 0.0193,\n",
      "         0.0196, 0.0103, 0.0214, 0.0360, 0.0199, 0.0304, 0.0136, 0.0432, 0.0056,\n",
      "         0.0521, 0.0195, 0.0350, 0.0175, 0.0233, 0.0310, 0.0477, 0.0461, 0.0533]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0127, 0.0168, 0.0316, 0.0217, 0.0196, 0.0318, 0.0214, 0.0315,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0572, 0.0063, 0.0373, 0.0521, 0.0193,\n",
      "         0.0196, 0.0103, 0.0214, 0.0359, 0.0199, 0.0304, 0.0136, 0.0431, 0.0056,\n",
      "         0.0544, 0.0194, 0.0349, 0.0175, 0.0233, 0.0310, 0.0476, 0.0460, 0.0531]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0127, 0.0168, 0.0316, 0.0217, 0.0196, 0.0317, 0.0214, 0.0314,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0571, 0.0063, 0.0373, 0.0520, 0.0192,\n",
      "         0.0196, 0.0103, 0.0214, 0.0359, 0.0199, 0.0303, 0.0136, 0.0430, 0.0056,\n",
      "         0.0543, 0.0194, 0.0349, 0.0175, 0.0233, 0.0309, 0.0475, 0.0459, 0.0530]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0127, 0.0168, 0.0316, 0.0217, 0.0196, 0.0326, 0.0214, 0.0314,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0571, 0.0063, 0.0373, 0.0520, 0.0192,\n",
      "         0.0195, 0.0103, 0.0214, 0.0358, 0.0199, 0.0303, 0.0136, 0.0430, 0.0056,\n",
      "         0.0542, 0.0194, 0.0348, 0.0174, 0.0232, 0.0309, 0.0474, 0.0459, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0127, 0.0168, 0.0316, 0.0217, 0.0196, 0.0326, 0.0214, 0.0314,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0570, 0.0063, 0.0373, 0.0519, 0.0192,\n",
      "         0.0195, 0.0103, 0.0214, 0.0358, 0.0199, 0.0303, 0.0136, 0.0430, 0.0056,\n",
      "         0.0542, 0.0194, 0.0348, 0.0177, 0.0232, 0.0309, 0.0474, 0.0458, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0127, 0.0167, 0.0315, 0.0217, 0.0196, 0.0326, 0.0213, 0.0314,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0569, 0.0063, 0.0372, 0.0518, 0.0192,\n",
      "         0.0195, 0.0103, 0.0214, 0.0369, 0.0198, 0.0303, 0.0136, 0.0429, 0.0056,\n",
      "         0.0541, 0.0194, 0.0348, 0.0177, 0.0232, 0.0309, 0.0473, 0.0458, 0.0528]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0127, 0.0167, 0.0315, 0.0221, 0.0195, 0.0326, 0.0213, 0.0314,\n",
      "         0.0178, 0.0188, 0.0296, 0.0173, 0.0569, 0.0063, 0.0372, 0.0518, 0.0192,\n",
      "         0.0195, 0.0103, 0.0214, 0.0369, 0.0198, 0.0303, 0.0136, 0.0429, 0.0056,\n",
      "         0.0540, 0.0194, 0.0348, 0.0177, 0.0232, 0.0309, 0.0473, 0.0457, 0.0528]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0315, 0.0221, 0.0195, 0.0325, 0.0213, 0.0313,\n",
      "         0.0178, 0.0187, 0.0295, 0.0173, 0.0567, 0.0063, 0.0371, 0.0517, 0.0192,\n",
      "         0.0195, 0.0103, 0.0213, 0.0368, 0.0198, 0.0302, 0.0136, 0.0428, 0.0056,\n",
      "         0.0539, 0.0194, 0.0347, 0.0177, 0.0232, 0.0308, 0.0472, 0.0475, 0.0526]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0315, 0.0221, 0.0195, 0.0325, 0.0213, 0.0313,\n",
      "         0.0178, 0.0187, 0.0295, 0.0173, 0.0567, 0.0063, 0.0371, 0.0516, 0.0192,\n",
      "         0.0195, 0.0103, 0.0213, 0.0368, 0.0198, 0.0302, 0.0136, 0.0428, 0.0056,\n",
      "         0.0539, 0.0197, 0.0347, 0.0177, 0.0232, 0.0308, 0.0472, 0.0475, 0.0526]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0315, 0.0221, 0.0195, 0.0325, 0.0213, 0.0313,\n",
      "         0.0178, 0.0187, 0.0295, 0.0173, 0.0566, 0.0063, 0.0371, 0.0516, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0368, 0.0198, 0.0302, 0.0136, 0.0427, 0.0056,\n",
      "         0.0538, 0.0197, 0.0347, 0.0177, 0.0232, 0.0308, 0.0472, 0.0475, 0.0526]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0315, 0.0221, 0.0195, 0.0325, 0.0213, 0.0313,\n",
      "         0.0180, 0.0187, 0.0295, 0.0173, 0.0566, 0.0063, 0.0371, 0.0516, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0368, 0.0198, 0.0302, 0.0136, 0.0427, 0.0056,\n",
      "         0.0538, 0.0197, 0.0347, 0.0177, 0.0232, 0.0308, 0.0471, 0.0474, 0.0525]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0323, 0.0221, 0.0195, 0.0324, 0.0213, 0.0313,\n",
      "         0.0180, 0.0187, 0.0295, 0.0172, 0.0565, 0.0063, 0.0371, 0.0515, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0368, 0.0198, 0.0302, 0.0136, 0.0427, 0.0056,\n",
      "         0.0537, 0.0197, 0.0347, 0.0177, 0.0232, 0.0308, 0.0471, 0.0474, 0.0525]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0323, 0.0221, 0.0195, 0.0324, 0.0217, 0.0312,\n",
      "         0.0180, 0.0187, 0.0295, 0.0172, 0.0565, 0.0063, 0.0370, 0.0515, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0198, 0.0302, 0.0136, 0.0427, 0.0056,\n",
      "         0.0537, 0.0197, 0.0346, 0.0177, 0.0232, 0.0308, 0.0470, 0.0473, 0.0524]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0127, 0.0167, 0.0323, 0.0221, 0.0195, 0.0324, 0.0217, 0.0312,\n",
      "         0.0180, 0.0187, 0.0295, 0.0175, 0.0564, 0.0063, 0.0370, 0.0514, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0198, 0.0302, 0.0136, 0.0426, 0.0056,\n",
      "         0.0536, 0.0197, 0.0346, 0.0177, 0.0232, 0.0307, 0.0470, 0.0473, 0.0524]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0127, 0.0167, 0.0322, 0.0220, 0.0195, 0.0324, 0.0217, 0.0312,\n",
      "         0.0180, 0.0187, 0.0294, 0.0175, 0.0563, 0.0063, 0.0369, 0.0513, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0198, 0.0301, 0.0135, 0.0425, 0.0056,\n",
      "         0.0535, 0.0197, 0.0346, 0.0177, 0.0231, 0.0307, 0.0469, 0.0492, 0.0522]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0127, 0.0167, 0.0322, 0.0220, 0.0195, 0.0324, 0.0217, 0.0312,\n",
      "         0.0180, 0.0187, 0.0294, 0.0178, 0.0562, 0.0063, 0.0369, 0.0513, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0366, 0.0198, 0.0301, 0.0135, 0.0425, 0.0056,\n",
      "         0.0535, 0.0197, 0.0346, 0.0177, 0.0231, 0.0307, 0.0469, 0.0492, 0.0522]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0127, 0.0167, 0.0322, 0.0220, 0.0195, 0.0323, 0.0217, 0.0312,\n",
      "         0.0180, 0.0187, 0.0294, 0.0178, 0.0562, 0.0063, 0.0369, 0.0512, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0366, 0.0198, 0.0301, 0.0135, 0.0425, 0.0056,\n",
      "         0.0534, 0.0197, 0.0345, 0.0179, 0.0231, 0.0307, 0.0469, 0.0491, 0.0522]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0127, 0.0167, 0.0322, 0.0220, 0.0195, 0.0323, 0.0221, 0.0312,\n",
      "         0.0180, 0.0187, 0.0294, 0.0178, 0.0561, 0.0063, 0.0369, 0.0512, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0366, 0.0198, 0.0301, 0.0135, 0.0425, 0.0056,\n",
      "         0.0534, 0.0197, 0.0345, 0.0179, 0.0231, 0.0307, 0.0468, 0.0491, 0.0521]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0127, 0.0167, 0.0322, 0.0220, 0.0195, 0.0323, 0.0221, 0.0311,\n",
      "         0.0180, 0.0190, 0.0294, 0.0178, 0.0561, 0.0063, 0.0369, 0.0512, 0.0192,\n",
      "         0.0198, 0.0103, 0.0213, 0.0366, 0.0198, 0.0301, 0.0135, 0.0425, 0.0056,\n",
      "         0.0533, 0.0197, 0.0345, 0.0179, 0.0231, 0.0307, 0.0468, 0.0491, 0.0521]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0127, 0.0167, 0.0321, 0.0220, 0.0194, 0.0323, 0.0220, 0.0311,\n",
      "         0.0180, 0.0190, 0.0293, 0.0177, 0.0559, 0.0063, 0.0368, 0.0510, 0.0191,\n",
      "         0.0198, 0.0103, 0.0212, 0.0365, 0.0197, 0.0300, 0.0135, 0.0424, 0.0056,\n",
      "         0.0532, 0.0196, 0.0344, 0.0179, 0.0231, 0.0306, 0.0467, 0.0511, 0.0520]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0127, 0.0167, 0.0321, 0.0220, 0.0194, 0.0332, 0.0220, 0.0311,\n",
      "         0.0180, 0.0190, 0.0293, 0.0177, 0.0558, 0.0063, 0.0368, 0.0509, 0.0191,\n",
      "         0.0198, 0.0103, 0.0212, 0.0365, 0.0197, 0.0300, 0.0135, 0.0423, 0.0056,\n",
      "         0.0531, 0.0196, 0.0344, 0.0179, 0.0231, 0.0306, 0.0466, 0.0510, 0.0519]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0126, 0.0166, 0.0320, 0.0219, 0.0194, 0.0331, 0.0220, 0.0310,\n",
      "         0.0179, 0.0189, 0.0292, 0.0177, 0.0557, 0.0062, 0.0367, 0.0531, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0364, 0.0197, 0.0299, 0.0135, 0.0422, 0.0056,\n",
      "         0.0529, 0.0196, 0.0343, 0.0179, 0.0230, 0.0305, 0.0465, 0.0509, 0.0517]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0126, 0.0166, 0.0320, 0.0219, 0.0194, 0.0330, 0.0220, 0.0310,\n",
      "         0.0179, 0.0189, 0.0292, 0.0177, 0.0555, 0.0062, 0.0366, 0.0530, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0375, 0.0197, 0.0299, 0.0135, 0.0421, 0.0056,\n",
      "         0.0528, 0.0196, 0.0343, 0.0178, 0.0230, 0.0305, 0.0464, 0.0508, 0.0516]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0126, 0.0166, 0.0320, 0.0219, 0.0194, 0.0330, 0.0220, 0.0310,\n",
      "         0.0179, 0.0189, 0.0292, 0.0177, 0.0555, 0.0062, 0.0366, 0.0530, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0375, 0.0197, 0.0299, 0.0135, 0.0421, 0.0056,\n",
      "         0.0528, 0.0199, 0.0343, 0.0178, 0.0230, 0.0305, 0.0464, 0.0507, 0.0516]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0320, 0.0219, 0.0194, 0.0330, 0.0220, 0.0309,\n",
      "         0.0179, 0.0189, 0.0292, 0.0177, 0.0554, 0.0062, 0.0366, 0.0529, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0375, 0.0197, 0.0299, 0.0135, 0.0421, 0.0056,\n",
      "         0.0527, 0.0199, 0.0343, 0.0178, 0.0230, 0.0313, 0.0463, 0.0507, 0.0515]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0320, 0.0219, 0.0194, 0.0330, 0.0219, 0.0309,\n",
      "         0.0179, 0.0189, 0.0292, 0.0179, 0.0554, 0.0062, 0.0366, 0.0529, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0375, 0.0197, 0.0299, 0.0135, 0.0421, 0.0056,\n",
      "         0.0527, 0.0199, 0.0342, 0.0178, 0.0230, 0.0313, 0.0463, 0.0507, 0.0515]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0330, 0.0219, 0.0309,\n",
      "         0.0179, 0.0189, 0.0292, 0.0179, 0.0554, 0.0062, 0.0366, 0.0528, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0375, 0.0197, 0.0299, 0.0135, 0.0420, 0.0056,\n",
      "         0.0527, 0.0199, 0.0342, 0.0181, 0.0230, 0.0313, 0.0463, 0.0506, 0.0515]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0330, 0.0224, 0.0309,\n",
      "         0.0179, 0.0189, 0.0292, 0.0179, 0.0553, 0.0062, 0.0366, 0.0528, 0.0191,\n",
      "         0.0197, 0.0103, 0.0212, 0.0374, 0.0197, 0.0299, 0.0135, 0.0420, 0.0056,\n",
      "         0.0526, 0.0199, 0.0342, 0.0181, 0.0230, 0.0312, 0.0463, 0.0506, 0.0514]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0330, 0.0224, 0.0309,\n",
      "         0.0179, 0.0189, 0.0292, 0.0179, 0.0553, 0.0062, 0.0365, 0.0528, 0.0191,\n",
      "         0.0200, 0.0103, 0.0212, 0.0374, 0.0197, 0.0299, 0.0135, 0.0420, 0.0056,\n",
      "         0.0526, 0.0199, 0.0342, 0.0181, 0.0230, 0.0312, 0.0462, 0.0506, 0.0514]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0330, 0.0224, 0.0309,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0552, 0.0062, 0.0365, 0.0527, 0.0191,\n",
      "         0.0200, 0.0103, 0.0212, 0.0374, 0.0197, 0.0298, 0.0135, 0.0420, 0.0056,\n",
      "         0.0526, 0.0199, 0.0342, 0.0181, 0.0230, 0.0312, 0.0462, 0.0505, 0.0514]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0329, 0.0224, 0.0317,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0552, 0.0062, 0.0365, 0.0527, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0374, 0.0196, 0.0298, 0.0135, 0.0419, 0.0056,\n",
      "         0.0525, 0.0199, 0.0342, 0.0181, 0.0230, 0.0312, 0.0461, 0.0505, 0.0513]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0329, 0.0223, 0.0317,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0551, 0.0062, 0.0365, 0.0526, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0373, 0.0196, 0.0306, 0.0135, 0.0419, 0.0056,\n",
      "         0.0524, 0.0199, 0.0341, 0.0181, 0.0229, 0.0312, 0.0461, 0.0504, 0.0512]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0329, 0.0223, 0.0317,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0550, 0.0062, 0.0365, 0.0526, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0373, 0.0196, 0.0306, 0.0135, 0.0419, 0.0056,\n",
      "         0.0524, 0.0202, 0.0341, 0.0181, 0.0229, 0.0312, 0.0461, 0.0504, 0.0512]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0126, 0.0166, 0.0319, 0.0219, 0.0194, 0.0329, 0.0223, 0.0317,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0550, 0.0063, 0.0364, 0.0525, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0373, 0.0196, 0.0306, 0.0135, 0.0419, 0.0056,\n",
      "         0.0524, 0.0202, 0.0341, 0.0184, 0.0229, 0.0312, 0.0460, 0.0503, 0.0512]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0126, 0.0166, 0.0318, 0.0219, 0.0194, 0.0338, 0.0223, 0.0316,\n",
      "         0.0179, 0.0189, 0.0291, 0.0182, 0.0549, 0.0062, 0.0364, 0.0524, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0373, 0.0196, 0.0306, 0.0135, 0.0418, 0.0056,\n",
      "         0.0523, 0.0202, 0.0341, 0.0184, 0.0229, 0.0311, 0.0460, 0.0503, 0.0511]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0126, 0.0166, 0.0318, 0.0219, 0.0193, 0.0338, 0.0223, 0.0316,\n",
      "         0.0179, 0.0192, 0.0291, 0.0182, 0.0549, 0.0063, 0.0364, 0.0524, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0373, 0.0196, 0.0305, 0.0135, 0.0418, 0.0056,\n",
      "         0.0523, 0.0202, 0.0341, 0.0184, 0.0229, 0.0311, 0.0460, 0.0502, 0.0511]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0126, 0.0166, 0.0318, 0.0219, 0.0193, 0.0338, 0.0223, 0.0316,\n",
      "         0.0179, 0.0192, 0.0290, 0.0182, 0.0548, 0.0063, 0.0364, 0.0523, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0372, 0.0196, 0.0305, 0.0135, 0.0417, 0.0056,\n",
      "         0.0522, 0.0202, 0.0341, 0.0184, 0.0229, 0.0320, 0.0459, 0.0502, 0.0510]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0126, 0.0166, 0.0318, 0.0218, 0.0193, 0.0337, 0.0223, 0.0316,\n",
      "         0.0179, 0.0192, 0.0290, 0.0182, 0.0547, 0.0062, 0.0363, 0.0523, 0.0190,\n",
      "         0.0200, 0.0103, 0.0211, 0.0372, 0.0196, 0.0305, 0.0135, 0.0417, 0.0056,\n",
      "         0.0521, 0.0202, 0.0350, 0.0184, 0.0229, 0.0319, 0.0458, 0.0501, 0.0509]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0126, 0.0166, 0.0317, 0.0218, 0.0193, 0.0337, 0.0223, 0.0315,\n",
      "         0.0178, 0.0191, 0.0290, 0.0182, 0.0545, 0.0062, 0.0362, 0.0521, 0.0190,\n",
      "         0.0199, 0.0103, 0.0211, 0.0371, 0.0196, 0.0304, 0.0135, 0.0416, 0.0056,\n",
      "         0.0519, 0.0202, 0.0350, 0.0183, 0.0229, 0.0319, 0.0457, 0.0499, 0.0531]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0222, 0.0315,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0544, 0.0062, 0.0362, 0.0520, 0.0190,\n",
      "         0.0199, 0.0102, 0.0210, 0.0370, 0.0195, 0.0304, 0.0134, 0.0415, 0.0056,\n",
      "         0.0518, 0.0201, 0.0349, 0.0183, 0.0228, 0.0318, 0.0475, 0.0498, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0222, 0.0315,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0544, 0.0062, 0.0362, 0.0519, 0.0190,\n",
      "         0.0199, 0.0103, 0.0210, 0.0370, 0.0196, 0.0304, 0.0134, 0.0415, 0.0056,\n",
      "         0.0518, 0.0201, 0.0349, 0.0183, 0.0228, 0.0318, 0.0475, 0.0498, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0227, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0543, 0.0062, 0.0361, 0.0519, 0.0190,\n",
      "         0.0199, 0.0103, 0.0210, 0.0370, 0.0195, 0.0304, 0.0134, 0.0415, 0.0056,\n",
      "         0.0517, 0.0201, 0.0349, 0.0183, 0.0228, 0.0318, 0.0474, 0.0498, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0227, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0543, 0.0062, 0.0361, 0.0519, 0.0190,\n",
      "         0.0199, 0.0103, 0.0210, 0.0370, 0.0195, 0.0304, 0.0134, 0.0415, 0.0056,\n",
      "         0.0517, 0.0201, 0.0349, 0.0183, 0.0228, 0.0318, 0.0474, 0.0498, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0227, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0543, 0.0062, 0.0361, 0.0519, 0.0190,\n",
      "         0.0199, 0.0103, 0.0210, 0.0370, 0.0196, 0.0304, 0.0134, 0.0415, 0.0056,\n",
      "         0.0517, 0.0201, 0.0349, 0.0183, 0.0228, 0.0318, 0.0474, 0.0498, 0.0529]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0227, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0543, 0.0062, 0.0361, 0.0519, 0.0190,\n",
      "         0.0199, 0.0103, 0.0210, 0.0370, 0.0195, 0.0304, 0.0134, 0.0414, 0.0056,\n",
      "         0.0517, 0.0205, 0.0349, 0.0183, 0.0228, 0.0318, 0.0474, 0.0497, 0.0528]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0218, 0.0193, 0.0336, 0.0227, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0542, 0.0062, 0.0361, 0.0518, 0.0190,\n",
      "         0.0199, 0.0103, 0.0214, 0.0370, 0.0195, 0.0303, 0.0134, 0.0414, 0.0056,\n",
      "         0.0517, 0.0205, 0.0349, 0.0183, 0.0228, 0.0318, 0.0474, 0.0497, 0.0528]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0217, 0.0193, 0.0335, 0.0226, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0541, 0.0062, 0.0361, 0.0517, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0369, 0.0195, 0.0303, 0.0134, 0.0414, 0.0056,\n",
      "         0.0516, 0.0205, 0.0348, 0.0183, 0.0228, 0.0326, 0.0473, 0.0496, 0.0527]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0316, 0.0217, 0.0193, 0.0335, 0.0226, 0.0314,\n",
      "         0.0178, 0.0191, 0.0289, 0.0181, 0.0541, 0.0062, 0.0361, 0.0517, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0369, 0.0195, 0.0303, 0.0134, 0.0414, 0.0056,\n",
      "         0.0516, 0.0205, 0.0348, 0.0186, 0.0228, 0.0326, 0.0473, 0.0496, 0.0527]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0315, 0.0217, 0.0193, 0.0335, 0.0226, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0181, 0.0540, 0.0062, 0.0360, 0.0516, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0369, 0.0195, 0.0303, 0.0134, 0.0413, 0.0056,\n",
      "         0.0515, 0.0205, 0.0348, 0.0186, 0.0228, 0.0326, 0.0472, 0.0495, 0.0526]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0305, 0.0126, 0.0165, 0.0315, 0.0217, 0.0193, 0.0335, 0.0226, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0184, 0.0540, 0.0062, 0.0360, 0.0516, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0369, 0.0195, 0.0303, 0.0134, 0.0413, 0.0056,\n",
      "         0.0515, 0.0205, 0.0348, 0.0186, 0.0228, 0.0326, 0.0472, 0.0495, 0.0526]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0304, 0.0126, 0.0165, 0.0315, 0.0217, 0.0192, 0.0335, 0.0226, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0184, 0.0539, 0.0062, 0.0360, 0.0515, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0368, 0.0195, 0.0303, 0.0134, 0.0412, 0.0056,\n",
      "         0.0514, 0.0205, 0.0347, 0.0186, 0.0228, 0.0335, 0.0471, 0.0494, 0.0525]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0304, 0.0126, 0.0165, 0.0324, 0.0217, 0.0192, 0.0334, 0.0226, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0184, 0.0538, 0.0062, 0.0359, 0.0515, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0368, 0.0195, 0.0302, 0.0134, 0.0412, 0.0056,\n",
      "         0.0513, 0.0205, 0.0347, 0.0186, 0.0228, 0.0335, 0.0471, 0.0494, 0.0524]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0304, 0.0126, 0.0165, 0.0323, 0.0217, 0.0192, 0.0334, 0.0230, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0184, 0.0538, 0.0062, 0.0359, 0.0514, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0368, 0.0195, 0.0302, 0.0134, 0.0412, 0.0056,\n",
      "         0.0513, 0.0204, 0.0347, 0.0186, 0.0227, 0.0335, 0.0470, 0.0493, 0.0524]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0304, 0.0126, 0.0165, 0.0323, 0.0217, 0.0192, 0.0334, 0.0230, 0.0322,\n",
      "         0.0178, 0.0191, 0.0288, 0.0187, 0.0538, 0.0062, 0.0359, 0.0514, 0.0189,\n",
      "         0.0199, 0.0103, 0.0214, 0.0368, 0.0195, 0.0302, 0.0134, 0.0412, 0.0056,\n",
      "         0.0512, 0.0204, 0.0347, 0.0186, 0.0227, 0.0335, 0.0470, 0.0493, 0.0524]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0303, 0.0126, 0.0165, 0.0323, 0.0217, 0.0192, 0.0333, 0.0230, 0.0321,\n",
      "         0.0178, 0.0190, 0.0287, 0.0187, 0.0536, 0.0062, 0.0358, 0.0512, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0195, 0.0302, 0.0134, 0.0411, 0.0056,\n",
      "         0.0511, 0.0204, 0.0346, 0.0185, 0.0227, 0.0334, 0.0469, 0.0513, 0.0522]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0303, 0.0126, 0.0165, 0.0323, 0.0217, 0.0192, 0.0333, 0.0230, 0.0321,\n",
      "         0.0178, 0.0190, 0.0287, 0.0187, 0.0536, 0.0062, 0.0358, 0.0512, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0195, 0.0302, 0.0134, 0.0410, 0.0056,\n",
      "         0.0511, 0.0208, 0.0346, 0.0185, 0.0227, 0.0334, 0.0469, 0.0513, 0.0522]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0303, 0.0126, 0.0167, 0.0323, 0.0217, 0.0192, 0.0333, 0.0230, 0.0321,\n",
      "         0.0178, 0.0190, 0.0287, 0.0187, 0.0535, 0.0062, 0.0358, 0.0512, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0367, 0.0195, 0.0301, 0.0134, 0.0410, 0.0056,\n",
      "         0.0510, 0.0208, 0.0346, 0.0185, 0.0227, 0.0334, 0.0468, 0.0513, 0.0521]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0303, 0.0126, 0.0167, 0.0322, 0.0217, 0.0192, 0.0333, 0.0230, 0.0320,\n",
      "         0.0178, 0.0190, 0.0287, 0.0186, 0.0534, 0.0062, 0.0358, 0.0511, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0366, 0.0195, 0.0301, 0.0134, 0.0410, 0.0056,\n",
      "         0.0510, 0.0208, 0.0345, 0.0185, 0.0227, 0.0343, 0.0468, 0.0512, 0.0521]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0303, 0.0126, 0.0167, 0.0322, 0.0216, 0.0192, 0.0332, 0.0230, 0.0320,\n",
      "         0.0177, 0.0190, 0.0287, 0.0186, 0.0533, 0.0062, 0.0357, 0.0510, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0378, 0.0194, 0.0301, 0.0134, 0.0409, 0.0056,\n",
      "         0.0509, 0.0208, 0.0345, 0.0185, 0.0227, 0.0343, 0.0467, 0.0511, 0.0520]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0302, 0.0126, 0.0167, 0.0322, 0.0216, 0.0192, 0.0332, 0.0230, 0.0320,\n",
      "         0.0177, 0.0190, 0.0286, 0.0189, 0.0533, 0.0062, 0.0357, 0.0510, 0.0189,\n",
      "         0.0198, 0.0103, 0.0213, 0.0377, 0.0194, 0.0301, 0.0134, 0.0409, 0.0056,\n",
      "         0.0508, 0.0208, 0.0345, 0.0185, 0.0227, 0.0343, 0.0467, 0.0511, 0.0519]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0302, 0.0125, 0.0167, 0.0321, 0.0216, 0.0192, 0.0332, 0.0229, 0.0320,\n",
      "         0.0177, 0.0190, 0.0286, 0.0189, 0.0532, 0.0062, 0.0357, 0.0509, 0.0188,\n",
      "         0.0198, 0.0103, 0.0213, 0.0377, 0.0194, 0.0300, 0.0134, 0.0423, 0.0056,\n",
      "         0.0507, 0.0207, 0.0344, 0.0185, 0.0226, 0.0342, 0.0466, 0.0510, 0.0518]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0302, 0.0125, 0.0167, 0.0321, 0.0216, 0.0192, 0.0332, 0.0229, 0.0319,\n",
      "         0.0177, 0.0190, 0.0286, 0.0192, 0.0532, 0.0062, 0.0356, 0.0508, 0.0188,\n",
      "         0.0198, 0.0103, 0.0213, 0.0377, 0.0194, 0.0300, 0.0134, 0.0423, 0.0056,\n",
      "         0.0507, 0.0207, 0.0344, 0.0185, 0.0226, 0.0342, 0.0466, 0.0509, 0.0518]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0302, 0.0125, 0.0167, 0.0321, 0.0216, 0.0191, 0.0331, 0.0229, 0.0319,\n",
      "         0.0177, 0.0190, 0.0286, 0.0192, 0.0531, 0.0062, 0.0356, 0.0508, 0.0188,\n",
      "         0.0198, 0.0103, 0.0213, 0.0376, 0.0194, 0.0300, 0.0134, 0.0422, 0.0056,\n",
      "         0.0506, 0.0207, 0.0344, 0.0185, 0.0226, 0.0352, 0.0465, 0.0509, 0.0517]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0302, 0.0125, 0.0167, 0.0321, 0.0216, 0.0191, 0.0331, 0.0229, 0.0319,\n",
      "         0.0177, 0.0190, 0.0286, 0.0192, 0.0531, 0.0062, 0.0356, 0.0507, 0.0188,\n",
      "         0.0198, 0.0104, 0.0213, 0.0376, 0.0194, 0.0300, 0.0134, 0.0422, 0.0056,\n",
      "         0.0506, 0.0207, 0.0344, 0.0185, 0.0226, 0.0352, 0.0465, 0.0508, 0.0517]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0301, 0.0125, 0.0167, 0.0320, 0.0216, 0.0191, 0.0331, 0.0229, 0.0318,\n",
      "         0.0177, 0.0190, 0.0285, 0.0192, 0.0529, 0.0062, 0.0355, 0.0506, 0.0188,\n",
      "         0.0197, 0.0104, 0.0212, 0.0375, 0.0194, 0.0299, 0.0134, 0.0421, 0.0056,\n",
      "         0.0527, 0.0207, 0.0343, 0.0185, 0.0226, 0.0351, 0.0463, 0.0507, 0.0515]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0125, 0.0167, 0.0320, 0.0215, 0.0191, 0.0330, 0.0229, 0.0318,\n",
      "         0.0177, 0.0189, 0.0285, 0.0192, 0.0528, 0.0062, 0.0355, 0.0505, 0.0188,\n",
      "         0.0197, 0.0104, 0.0212, 0.0375, 0.0194, 0.0299, 0.0134, 0.0421, 0.0056,\n",
      "         0.0527, 0.0207, 0.0343, 0.0185, 0.0226, 0.0351, 0.0463, 0.0506, 0.0515]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0309, 0.0125, 0.0167, 0.0320, 0.0215, 0.0191, 0.0340, 0.0229, 0.0318,\n",
      "         0.0177, 0.0189, 0.0285, 0.0192, 0.0527, 0.0062, 0.0355, 0.0505, 0.0188,\n",
      "         0.0197, 0.0104, 0.0212, 0.0375, 0.0194, 0.0299, 0.0134, 0.0420, 0.0056,\n",
      "         0.0526, 0.0207, 0.0342, 0.0184, 0.0226, 0.0351, 0.0462, 0.0506, 0.0514]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0125, 0.0166, 0.0319, 0.0215, 0.0191, 0.0350, 0.0228, 0.0318,\n",
      "         0.0177, 0.0189, 0.0285, 0.0192, 0.0527, 0.0062, 0.0354, 0.0504, 0.0188,\n",
      "         0.0197, 0.0104, 0.0212, 0.0374, 0.0194, 0.0299, 0.0134, 0.0420, 0.0056,\n",
      "         0.0525, 0.0206, 0.0342, 0.0184, 0.0225, 0.0350, 0.0462, 0.0505, 0.0513]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0308, 0.0125, 0.0166, 0.0319, 0.0215, 0.0191, 0.0349, 0.0228, 0.0317,\n",
      "         0.0177, 0.0189, 0.0284, 0.0192, 0.0526, 0.0062, 0.0354, 0.0503, 0.0188,\n",
      "         0.0197, 0.0104, 0.0212, 0.0374, 0.0193, 0.0298, 0.0134, 0.0419, 0.0056,\n",
      "         0.0524, 0.0206, 0.0352, 0.0184, 0.0225, 0.0350, 0.0461, 0.0504, 0.0512]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0125, 0.0166, 0.0318, 0.0215, 0.0190, 0.0348, 0.0228, 0.0317,\n",
      "         0.0176, 0.0189, 0.0284, 0.0191, 0.0524, 0.0062, 0.0353, 0.0501, 0.0187,\n",
      "         0.0197, 0.0104, 0.0211, 0.0373, 0.0193, 0.0298, 0.0133, 0.0418, 0.0056,\n",
      "         0.0547, 0.0206, 0.0351, 0.0184, 0.0225, 0.0349, 0.0460, 0.0502, 0.0511]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0307, 0.0125, 0.0166, 0.0318, 0.0214, 0.0190, 0.0348, 0.0227, 0.0316,\n",
      "         0.0176, 0.0189, 0.0283, 0.0191, 0.0522, 0.0062, 0.0352, 0.0500, 0.0187,\n",
      "         0.0196, 0.0104, 0.0211, 0.0372, 0.0193, 0.0297, 0.0133, 0.0417, 0.0056,\n",
      "         0.0545, 0.0206, 0.0351, 0.0184, 0.0224, 0.0348, 0.0458, 0.0523, 0.0509]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0306, 0.0125, 0.0166, 0.0317, 0.0214, 0.0190, 0.0347, 0.0227, 0.0316,\n",
      "         0.0176, 0.0188, 0.0283, 0.0191, 0.0521, 0.0062, 0.0352, 0.0499, 0.0187,\n",
      "         0.0196, 0.0104, 0.0211, 0.0371, 0.0193, 0.0297, 0.0133, 0.0416, 0.0056,\n",
      "         0.0544, 0.0206, 0.0361, 0.0184, 0.0224, 0.0348, 0.0458, 0.0523, 0.0508]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0317, 0.0214, 0.0190, 0.0347, 0.0227, 0.0315,\n",
      "         0.0176, 0.0188, 0.0283, 0.0191, 0.0521, 0.0062, 0.0351, 0.0498, 0.0187,\n",
      "         0.0196, 0.0104, 0.0211, 0.0371, 0.0193, 0.0297, 0.0133, 0.0416, 0.0056,\n",
      "         0.0544, 0.0205, 0.0361, 0.0183, 0.0224, 0.0348, 0.0457, 0.0522, 0.0508]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0317, 0.0214, 0.0190, 0.0347, 0.0227, 0.0315,\n",
      "         0.0176, 0.0188, 0.0283, 0.0194, 0.0520, 0.0062, 0.0351, 0.0498, 0.0187,\n",
      "         0.0196, 0.0104, 0.0211, 0.0371, 0.0193, 0.0297, 0.0133, 0.0416, 0.0056,\n",
      "         0.0543, 0.0205, 0.0361, 0.0183, 0.0224, 0.0348, 0.0457, 0.0521, 0.0507]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0317, 0.0214, 0.0190, 0.0346, 0.0227, 0.0315,\n",
      "         0.0176, 0.0188, 0.0282, 0.0194, 0.0520, 0.0062, 0.0351, 0.0497, 0.0187,\n",
      "         0.0196, 0.0103, 0.0211, 0.0371, 0.0192, 0.0296, 0.0133, 0.0415, 0.0056,\n",
      "         0.0542, 0.0205, 0.0360, 0.0183, 0.0224, 0.0358, 0.0456, 0.0521, 0.0506]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0317, 0.0214, 0.0190, 0.0346, 0.0231, 0.0315,\n",
      "         0.0176, 0.0188, 0.0282, 0.0194, 0.0519, 0.0062, 0.0351, 0.0497, 0.0187,\n",
      "         0.0196, 0.0103, 0.0210, 0.0370, 0.0192, 0.0296, 0.0133, 0.0415, 0.0056,\n",
      "         0.0542, 0.0205, 0.0360, 0.0183, 0.0224, 0.0358, 0.0456, 0.0520, 0.0506]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0316, 0.0214, 0.0190, 0.0346, 0.0231, 0.0315,\n",
      "         0.0176, 0.0188, 0.0282, 0.0194, 0.0519, 0.0062, 0.0351, 0.0497, 0.0187,\n",
      "         0.0196, 0.0103, 0.0210, 0.0370, 0.0192, 0.0296, 0.0133, 0.0415, 0.0056,\n",
      "         0.0541, 0.0205, 0.0360, 0.0183, 0.0228, 0.0358, 0.0456, 0.0520, 0.0506]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0314, 0.0125, 0.0166, 0.0316, 0.0214, 0.0190, 0.0346, 0.0231, 0.0315,\n",
      "         0.0176, 0.0188, 0.0282, 0.0197, 0.0518, 0.0062, 0.0350, 0.0496, 0.0187,\n",
      "         0.0196, 0.0103, 0.0210, 0.0370, 0.0192, 0.0296, 0.0133, 0.0415, 0.0056,\n",
      "         0.0541, 0.0205, 0.0360, 0.0183, 0.0228, 0.0357, 0.0455, 0.0519, 0.0505]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0125, 0.0166, 0.0316, 0.0214, 0.0190, 0.0346, 0.0231, 0.0323,\n",
      "         0.0176, 0.0188, 0.0282, 0.0197, 0.0518, 0.0062, 0.0350, 0.0496, 0.0187,\n",
      "         0.0196, 0.0103, 0.0210, 0.0370, 0.0192, 0.0296, 0.0133, 0.0414, 0.0056,\n",
      "         0.0540, 0.0205, 0.0359, 0.0183, 0.0228, 0.0357, 0.0455, 0.0519, 0.0505]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0345, 0.0231, 0.0322,\n",
      "         0.0175, 0.0188, 0.0281, 0.0197, 0.0516, 0.0062, 0.0349, 0.0516, 0.0186,\n",
      "         0.0196, 0.0103, 0.0210, 0.0369, 0.0192, 0.0295, 0.0133, 0.0413, 0.0056,\n",
      "         0.0539, 0.0205, 0.0359, 0.0183, 0.0228, 0.0356, 0.0454, 0.0517, 0.0503]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0345, 0.0231, 0.0322,\n",
      "         0.0175, 0.0188, 0.0281, 0.0197, 0.0516, 0.0062, 0.0349, 0.0516, 0.0186,\n",
      "         0.0196, 0.0103, 0.0210, 0.0369, 0.0192, 0.0295, 0.0133, 0.0413, 0.0056,\n",
      "         0.0538, 0.0208, 0.0358, 0.0183, 0.0228, 0.0356, 0.0453, 0.0517, 0.0503]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0313, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0345, 0.0231, 0.0322,\n",
      "         0.0175, 0.0188, 0.0281, 0.0200, 0.0515, 0.0062, 0.0349, 0.0515, 0.0186,\n",
      "         0.0196, 0.0103, 0.0210, 0.0369, 0.0192, 0.0295, 0.0133, 0.0413, 0.0056,\n",
      "         0.0538, 0.0208, 0.0358, 0.0183, 0.0228, 0.0356, 0.0453, 0.0516, 0.0503]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0344, 0.0231, 0.0322,\n",
      "         0.0175, 0.0188, 0.0281, 0.0200, 0.0515, 0.0062, 0.0349, 0.0515, 0.0186,\n",
      "         0.0195, 0.0103, 0.0210, 0.0368, 0.0192, 0.0295, 0.0133, 0.0412, 0.0056,\n",
      "         0.0537, 0.0208, 0.0358, 0.0183, 0.0228, 0.0367, 0.0452, 0.0516, 0.0502]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0344, 0.0230, 0.0331,\n",
      "         0.0175, 0.0188, 0.0281, 0.0200, 0.0514, 0.0062, 0.0348, 0.0514, 0.0186,\n",
      "         0.0195, 0.0103, 0.0210, 0.0368, 0.0192, 0.0295, 0.0133, 0.0412, 0.0056,\n",
      "         0.0536, 0.0208, 0.0358, 0.0183, 0.0227, 0.0367, 0.0452, 0.0515, 0.0501]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0124, 0.0165, 0.0315, 0.0213, 0.0189, 0.0344, 0.0230, 0.0331,\n",
      "         0.0175, 0.0188, 0.0281, 0.0200, 0.0513, 0.0062, 0.0348, 0.0513, 0.0186,\n",
      "         0.0195, 0.0103, 0.0210, 0.0368, 0.0192, 0.0294, 0.0133, 0.0411, 0.0056,\n",
      "         0.0536, 0.0208, 0.0357, 0.0183, 0.0232, 0.0366, 0.0452, 0.0514, 0.0501]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0124, 0.0165, 0.0314, 0.0213, 0.0189, 0.0344, 0.0230, 0.0331,\n",
      "         0.0175, 0.0188, 0.0281, 0.0200, 0.0513, 0.0062, 0.0348, 0.0513, 0.0186,\n",
      "         0.0195, 0.0103, 0.0210, 0.0367, 0.0192, 0.0294, 0.0133, 0.0411, 0.0056,\n",
      "         0.0535, 0.0212, 0.0357, 0.0183, 0.0232, 0.0366, 0.0451, 0.0514, 0.0500]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0312, 0.0124, 0.0165, 0.0314, 0.0213, 0.0189, 0.0344, 0.0230, 0.0330,\n",
      "         0.0178, 0.0188, 0.0281, 0.0200, 0.0513, 0.0062, 0.0348, 0.0513, 0.0186,\n",
      "         0.0195, 0.0103, 0.0210, 0.0367, 0.0192, 0.0294, 0.0133, 0.0411, 0.0056,\n",
      "         0.0535, 0.0212, 0.0357, 0.0183, 0.0232, 0.0366, 0.0451, 0.0514, 0.0500]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0124, 0.0165, 0.0314, 0.0213, 0.0189, 0.0343, 0.0230, 0.0330,\n",
      "         0.0178, 0.0187, 0.0280, 0.0200, 0.0512, 0.0062, 0.0348, 0.0512, 0.0186,\n",
      "         0.0195, 0.0103, 0.0209, 0.0367, 0.0192, 0.0294, 0.0133, 0.0410, 0.0056,\n",
      "         0.0534, 0.0212, 0.0357, 0.0183, 0.0232, 0.0378, 0.0450, 0.0513, 0.0499]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0311, 0.0124, 0.0165, 0.0314, 0.0213, 0.0189, 0.0343, 0.0230, 0.0330,\n",
      "         0.0178, 0.0187, 0.0280, 0.0199, 0.0511, 0.0062, 0.0347, 0.0511, 0.0186,\n",
      "         0.0195, 0.0103, 0.0209, 0.0366, 0.0191, 0.0294, 0.0133, 0.0410, 0.0056,\n",
      "         0.0533, 0.0212, 0.0356, 0.0182, 0.0232, 0.0390, 0.0450, 0.0512, 0.0498]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0124, 0.0165, 0.0313, 0.0212, 0.0188, 0.0342, 0.0229, 0.0329,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0509, 0.0062, 0.0346, 0.0509, 0.0185,\n",
      "         0.0195, 0.0103, 0.0209, 0.0365, 0.0191, 0.0293, 0.0132, 0.0409, 0.0056,\n",
      "         0.0556, 0.0211, 0.0355, 0.0182, 0.0231, 0.0389, 0.0448, 0.0510, 0.0497]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0124, 0.0165, 0.0313, 0.0212, 0.0188, 0.0342, 0.0234, 0.0329,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0509, 0.0062, 0.0346, 0.0509, 0.0185,\n",
      "         0.0195, 0.0103, 0.0209, 0.0365, 0.0191, 0.0293, 0.0132, 0.0408, 0.0056,\n",
      "         0.0556, 0.0211, 0.0355, 0.0182, 0.0231, 0.0388, 0.0448, 0.0510, 0.0496]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0124, 0.0165, 0.0313, 0.0212, 0.0188, 0.0342, 0.0234, 0.0329,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0509, 0.0062, 0.0346, 0.0509, 0.0185,\n",
      "         0.0195, 0.0104, 0.0209, 0.0365, 0.0191, 0.0293, 0.0132, 0.0408, 0.0056,\n",
      "         0.0556, 0.0211, 0.0355, 0.0182, 0.0231, 0.0388, 0.0448, 0.0510, 0.0496]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0124, 0.0165, 0.0313, 0.0212, 0.0188, 0.0342, 0.0234, 0.0329,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0508, 0.0062, 0.0346, 0.0508, 0.0185,\n",
      "         0.0195, 0.0104, 0.0209, 0.0365, 0.0191, 0.0293, 0.0132, 0.0408, 0.0056,\n",
      "         0.0555, 0.0215, 0.0355, 0.0182, 0.0231, 0.0388, 0.0448, 0.0509, 0.0496]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0310, 0.0124, 0.0165, 0.0312, 0.0212, 0.0188, 0.0341, 0.0239, 0.0328,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0508, 0.0062, 0.0346, 0.0508, 0.0185,\n",
      "         0.0195, 0.0104, 0.0209, 0.0365, 0.0191, 0.0293, 0.0132, 0.0408, 0.0056,\n",
      "         0.0555, 0.0215, 0.0355, 0.0182, 0.0231, 0.0388, 0.0447, 0.0509, 0.0495]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0318, 0.0124, 0.0165, 0.0312, 0.0212, 0.0188, 0.0341, 0.0239, 0.0328,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0507, 0.0062, 0.0345, 0.0507, 0.0185,\n",
      "         0.0194, 0.0104, 0.0209, 0.0364, 0.0191, 0.0292, 0.0132, 0.0407, 0.0056,\n",
      "         0.0554, 0.0215, 0.0354, 0.0182, 0.0231, 0.0388, 0.0447, 0.0508, 0.0495]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0318, 0.0124, 0.0165, 0.0312, 0.0212, 0.0188, 0.0341, 0.0239, 0.0328,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0507, 0.0062, 0.0345, 0.0507, 0.0185,\n",
      "         0.0194, 0.0104, 0.0209, 0.0364, 0.0191, 0.0292, 0.0132, 0.0407, 0.0056,\n",
      "         0.0553, 0.0219, 0.0354, 0.0182, 0.0231, 0.0387, 0.0446, 0.0508, 0.0494]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0318, 0.0124, 0.0165, 0.0312, 0.0216, 0.0188, 0.0341, 0.0239, 0.0328,\n",
      "         0.0177, 0.0187, 0.0279, 0.0199, 0.0506, 0.0062, 0.0345, 0.0506, 0.0185,\n",
      "         0.0194, 0.0104, 0.0209, 0.0364, 0.0191, 0.0292, 0.0132, 0.0407, 0.0056,\n",
      "         0.0553, 0.0219, 0.0354, 0.0182, 0.0231, 0.0387, 0.0446, 0.0507, 0.0494]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0318, 0.0124, 0.0164, 0.0312, 0.0216, 0.0188, 0.0340, 0.0238, 0.0327,\n",
      "         0.0177, 0.0187, 0.0278, 0.0199, 0.0505, 0.0062, 0.0345, 0.0506, 0.0185,\n",
      "         0.0194, 0.0104, 0.0208, 0.0364, 0.0191, 0.0292, 0.0132, 0.0406, 0.0056,\n",
      "         0.0552, 0.0219, 0.0354, 0.0182, 0.0230, 0.0400, 0.0445, 0.0507, 0.0493]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0318, 0.0124, 0.0164, 0.0312, 0.0216, 0.0188, 0.0340, 0.0238, 0.0327,\n",
      "         0.0177, 0.0187, 0.0278, 0.0199, 0.0505, 0.0062, 0.0345, 0.0505, 0.0185,\n",
      "         0.0194, 0.0104, 0.0212, 0.0363, 0.0191, 0.0292, 0.0132, 0.0406, 0.0056,\n",
      "         0.0551, 0.0219, 0.0353, 0.0182, 0.0230, 0.0400, 0.0445, 0.0506, 0.0493]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0317, 0.0124, 0.0164, 0.0311, 0.0216, 0.0188, 0.0340, 0.0238, 0.0327,\n",
      "         0.0177, 0.0187, 0.0278, 0.0199, 0.0505, 0.0062, 0.0344, 0.0505, 0.0185,\n",
      "         0.0194, 0.0104, 0.0212, 0.0363, 0.0191, 0.0292, 0.0132, 0.0406, 0.0056,\n",
      "         0.0551, 0.0223, 0.0353, 0.0182, 0.0230, 0.0400, 0.0445, 0.0506, 0.0492]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0317, 0.0124, 0.0164, 0.0311, 0.0215, 0.0188, 0.0340, 0.0238, 0.0336,\n",
      "         0.0177, 0.0186, 0.0278, 0.0199, 0.0504, 0.0062, 0.0344, 0.0504, 0.0185,\n",
      "         0.0194, 0.0104, 0.0212, 0.0363, 0.0191, 0.0292, 0.0132, 0.0405, 0.0056,\n",
      "         0.0550, 0.0223, 0.0353, 0.0182, 0.0230, 0.0399, 0.0444, 0.0505, 0.0492]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0326, 0.0124, 0.0164, 0.0311, 0.0215, 0.0188, 0.0339, 0.0238, 0.0336,\n",
      "         0.0177, 0.0186, 0.0278, 0.0198, 0.0503, 0.0062, 0.0344, 0.0503, 0.0185,\n",
      "         0.0194, 0.0104, 0.0212, 0.0363, 0.0190, 0.0291, 0.0132, 0.0405, 0.0056,\n",
      "         0.0549, 0.0223, 0.0353, 0.0182, 0.0230, 0.0399, 0.0444, 0.0504, 0.0491]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0325, 0.0124, 0.0164, 0.0310, 0.0215, 0.0188, 0.0339, 0.0237, 0.0335,\n",
      "         0.0177, 0.0186, 0.0277, 0.0198, 0.0502, 0.0062, 0.0343, 0.0502, 0.0185,\n",
      "         0.0194, 0.0104, 0.0212, 0.0362, 0.0190, 0.0291, 0.0132, 0.0404, 0.0056,\n",
      "         0.0547, 0.0222, 0.0352, 0.0181, 0.0230, 0.0398, 0.0443, 0.0526, 0.0490]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0325, 0.0124, 0.0164, 0.0310, 0.0215, 0.0188, 0.0339, 0.0238, 0.0335,\n",
      "         0.0177, 0.0186, 0.0277, 0.0198, 0.0502, 0.0062, 0.0343, 0.0502, 0.0185,\n",
      "         0.0194, 0.0105, 0.0212, 0.0362, 0.0190, 0.0291, 0.0132, 0.0404, 0.0056,\n",
      "         0.0547, 0.0222, 0.0352, 0.0181, 0.0230, 0.0398, 0.0443, 0.0525, 0.0489]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0334, 0.0124, 0.0164, 0.0310, 0.0215, 0.0187, 0.0338, 0.0237, 0.0335,\n",
      "         0.0176, 0.0186, 0.0277, 0.0198, 0.0501, 0.0062, 0.0343, 0.0501, 0.0184,\n",
      "         0.0194, 0.0105, 0.0212, 0.0361, 0.0190, 0.0290, 0.0132, 0.0403, 0.0056,\n",
      "         0.0546, 0.0222, 0.0351, 0.0181, 0.0230, 0.0397, 0.0442, 0.0525, 0.0489]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0334, 0.0124, 0.0164, 0.0310, 0.0215, 0.0187, 0.0338, 0.0237, 0.0335,\n",
      "         0.0176, 0.0186, 0.0277, 0.0198, 0.0501, 0.0062, 0.0343, 0.0501, 0.0184,\n",
      "         0.0194, 0.0106, 0.0212, 0.0361, 0.0190, 0.0290, 0.0132, 0.0403, 0.0056,\n",
      "         0.0546, 0.0222, 0.0351, 0.0181, 0.0230, 0.0397, 0.0442, 0.0524, 0.0489]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0334, 0.0124, 0.0164, 0.0310, 0.0215, 0.0187, 0.0338, 0.0237, 0.0335,\n",
      "         0.0179, 0.0186, 0.0277, 0.0198, 0.0501, 0.0062, 0.0343, 0.0501, 0.0184,\n",
      "         0.0194, 0.0106, 0.0212, 0.0361, 0.0190, 0.0290, 0.0132, 0.0403, 0.0056,\n",
      "         0.0546, 0.0222, 0.0351, 0.0181, 0.0230, 0.0397, 0.0442, 0.0524, 0.0488]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0334, 0.0124, 0.0164, 0.0310, 0.0215, 0.0187, 0.0338, 0.0237, 0.0335,\n",
      "         0.0179, 0.0186, 0.0277, 0.0198, 0.0500, 0.0062, 0.0342, 0.0500, 0.0184,\n",
      "         0.0194, 0.0106, 0.0211, 0.0372, 0.0190, 0.0290, 0.0132, 0.0403, 0.0056,\n",
      "         0.0545, 0.0222, 0.0351, 0.0181, 0.0229, 0.0396, 0.0441, 0.0523, 0.0488]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0333, 0.0124, 0.0164, 0.0309, 0.0215, 0.0187, 0.0338, 0.0237, 0.0334,\n",
      "         0.0179, 0.0186, 0.0277, 0.0198, 0.0499, 0.0062, 0.0342, 0.0499, 0.0184,\n",
      "         0.0193, 0.0106, 0.0211, 0.0372, 0.0190, 0.0290, 0.0132, 0.0402, 0.0056,\n",
      "         0.0544, 0.0226, 0.0351, 0.0181, 0.0229, 0.0396, 0.0441, 0.0523, 0.0487]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0333, 0.0124, 0.0164, 0.0309, 0.0214, 0.0187, 0.0337, 0.0237, 0.0334,\n",
      "         0.0179, 0.0186, 0.0276, 0.0198, 0.0498, 0.0062, 0.0341, 0.0498, 0.0184,\n",
      "         0.0193, 0.0106, 0.0211, 0.0372, 0.0190, 0.0290, 0.0132, 0.0402, 0.0056,\n",
      "         0.0543, 0.0226, 0.0350, 0.0181, 0.0229, 0.0410, 0.0440, 0.0522, 0.0486]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0333, 0.0124, 0.0164, 0.0309, 0.0214, 0.0187, 0.0337, 0.0237, 0.0334,\n",
      "         0.0179, 0.0186, 0.0276, 0.0198, 0.0498, 0.0062, 0.0341, 0.0498, 0.0184,\n",
      "         0.0193, 0.0107, 0.0211, 0.0371, 0.0190, 0.0290, 0.0132, 0.0402, 0.0056,\n",
      "         0.0543, 0.0226, 0.0350, 0.0181, 0.0229, 0.0409, 0.0440, 0.0522, 0.0486]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0333, 0.0124, 0.0164, 0.0309, 0.0214, 0.0187, 0.0337, 0.0237, 0.0334,\n",
      "         0.0179, 0.0186, 0.0276, 0.0201, 0.0498, 0.0062, 0.0341, 0.0498, 0.0184,\n",
      "         0.0193, 0.0107, 0.0211, 0.0371, 0.0190, 0.0290, 0.0132, 0.0402, 0.0056,\n",
      "         0.0543, 0.0226, 0.0350, 0.0181, 0.0229, 0.0409, 0.0440, 0.0521, 0.0486]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0332, 0.0124, 0.0164, 0.0309, 0.0214, 0.0187, 0.0337, 0.0237, 0.0333,\n",
      "         0.0179, 0.0185, 0.0276, 0.0201, 0.0497, 0.0062, 0.0341, 0.0497, 0.0184,\n",
      "         0.0193, 0.0107, 0.0211, 0.0371, 0.0190, 0.0289, 0.0132, 0.0401, 0.0056,\n",
      "         0.0542, 0.0226, 0.0349, 0.0181, 0.0229, 0.0424, 0.0439, 0.0520, 0.0485]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0332, 0.0124, 0.0164, 0.0308, 0.0214, 0.0187, 0.0336, 0.0236, 0.0333,\n",
      "         0.0179, 0.0185, 0.0276, 0.0201, 0.0497, 0.0062, 0.0341, 0.0497, 0.0184,\n",
      "         0.0193, 0.0107, 0.0215, 0.0371, 0.0190, 0.0289, 0.0132, 0.0401, 0.0056,\n",
      "         0.0541, 0.0226, 0.0349, 0.0181, 0.0229, 0.0423, 0.0439, 0.0520, 0.0485]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0332, 0.0124, 0.0164, 0.0308, 0.0214, 0.0187, 0.0336, 0.0236, 0.0333,\n",
      "         0.0179, 0.0185, 0.0276, 0.0201, 0.0496, 0.0062, 0.0341, 0.0496, 0.0184,\n",
      "         0.0193, 0.0107, 0.0215, 0.0370, 0.0190, 0.0289, 0.0132, 0.0400, 0.0056,\n",
      "         0.0541, 0.0230, 0.0349, 0.0181, 0.0229, 0.0423, 0.0438, 0.0519, 0.0484]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0332, 0.0124, 0.0163, 0.0308, 0.0214, 0.0187, 0.0336, 0.0236, 0.0333,\n",
      "         0.0179, 0.0185, 0.0276, 0.0201, 0.0496, 0.0062, 0.0340, 0.0496, 0.0184,\n",
      "         0.0193, 0.0107, 0.0215, 0.0370, 0.0189, 0.0296, 0.0132, 0.0400, 0.0056,\n",
      "         0.0540, 0.0230, 0.0349, 0.0181, 0.0229, 0.0423, 0.0438, 0.0519, 0.0484]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0331, 0.0123, 0.0163, 0.0307, 0.0214, 0.0187, 0.0335, 0.0236, 0.0332,\n",
      "         0.0178, 0.0185, 0.0275, 0.0200, 0.0494, 0.0062, 0.0339, 0.0494, 0.0184,\n",
      "         0.0193, 0.0106, 0.0214, 0.0369, 0.0189, 0.0296, 0.0132, 0.0399, 0.0056,\n",
      "         0.0564, 0.0230, 0.0348, 0.0180, 0.0228, 0.0421, 0.0436, 0.0517, 0.0482]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0214, 0.0186, 0.0335, 0.0236, 0.0332,\n",
      "         0.0178, 0.0185, 0.0275, 0.0200, 0.0493, 0.0062, 0.0339, 0.0493, 0.0183,\n",
      "         0.0193, 0.0106, 0.0214, 0.0369, 0.0189, 0.0295, 0.0131, 0.0399, 0.0056,\n",
      "         0.0563, 0.0229, 0.0348, 0.0180, 0.0228, 0.0421, 0.0436, 0.0516, 0.0481]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0214, 0.0186, 0.0335, 0.0236, 0.0332,\n",
      "         0.0178, 0.0185, 0.0275, 0.0204, 0.0493, 0.0062, 0.0339, 0.0493, 0.0183,\n",
      "         0.0193, 0.0106, 0.0214, 0.0369, 0.0189, 0.0295, 0.0131, 0.0398, 0.0056,\n",
      "         0.0563, 0.0229, 0.0348, 0.0180, 0.0228, 0.0421, 0.0436, 0.0516, 0.0481]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0213, 0.0186, 0.0335, 0.0236, 0.0331,\n",
      "         0.0178, 0.0185, 0.0275, 0.0204, 0.0493, 0.0062, 0.0339, 0.0493, 0.0183,\n",
      "         0.0193, 0.0106, 0.0214, 0.0368, 0.0189, 0.0295, 0.0131, 0.0398, 0.0056,\n",
      "         0.0562, 0.0229, 0.0347, 0.0183, 0.0228, 0.0420, 0.0436, 0.0515, 0.0481]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0213, 0.0186, 0.0335, 0.0236, 0.0331,\n",
      "         0.0178, 0.0185, 0.0275, 0.0204, 0.0493, 0.0062, 0.0339, 0.0493, 0.0183,\n",
      "         0.0193, 0.0106, 0.0214, 0.0368, 0.0189, 0.0295, 0.0131, 0.0398, 0.0056,\n",
      "         0.0562, 0.0229, 0.0347, 0.0183, 0.0228, 0.0420, 0.0435, 0.0515, 0.0481]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0213, 0.0186, 0.0334, 0.0235, 0.0331,\n",
      "         0.0178, 0.0185, 0.0275, 0.0204, 0.0492, 0.0062, 0.0339, 0.0492, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0368, 0.0189, 0.0303, 0.0131, 0.0398, 0.0056,\n",
      "         0.0562, 0.0229, 0.0347, 0.0183, 0.0228, 0.0420, 0.0435, 0.0515, 0.0480]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0213, 0.0186, 0.0334, 0.0240, 0.0331,\n",
      "         0.0178, 0.0185, 0.0274, 0.0204, 0.0492, 0.0062, 0.0338, 0.0492, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0368, 0.0189, 0.0303, 0.0131, 0.0398, 0.0056,\n",
      "         0.0561, 0.0229, 0.0347, 0.0183, 0.0228, 0.0420, 0.0435, 0.0514, 0.0480]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0340, 0.0123, 0.0163, 0.0307, 0.0213, 0.0186, 0.0334, 0.0240, 0.0331,\n",
      "         0.0178, 0.0185, 0.0274, 0.0207, 0.0491, 0.0062, 0.0338, 0.0491, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0368, 0.0189, 0.0303, 0.0131, 0.0397, 0.0056,\n",
      "         0.0561, 0.0229, 0.0347, 0.0183, 0.0228, 0.0420, 0.0434, 0.0514, 0.0480]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0339, 0.0123, 0.0163, 0.0306, 0.0213, 0.0186, 0.0334, 0.0240, 0.0330,\n",
      "         0.0178, 0.0185, 0.0274, 0.0207, 0.0490, 0.0062, 0.0338, 0.0490, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0367, 0.0189, 0.0302, 0.0131, 0.0397, 0.0056,\n",
      "         0.0559, 0.0229, 0.0346, 0.0183, 0.0227, 0.0434, 0.0434, 0.0513, 0.0479]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0339, 0.0123, 0.0163, 0.0306, 0.0213, 0.0186, 0.0333, 0.0240, 0.0340,\n",
      "         0.0178, 0.0185, 0.0274, 0.0207, 0.0490, 0.0062, 0.0337, 0.0490, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0367, 0.0189, 0.0302, 0.0131, 0.0396, 0.0056,\n",
      "         0.0558, 0.0229, 0.0346, 0.0183, 0.0227, 0.0434, 0.0433, 0.0512, 0.0478]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0339, 0.0123, 0.0163, 0.0306, 0.0213, 0.0186, 0.0333, 0.0240, 0.0340,\n",
      "         0.0178, 0.0185, 0.0274, 0.0211, 0.0489, 0.0062, 0.0337, 0.0489, 0.0183,\n",
      "         0.0192, 0.0106, 0.0214, 0.0367, 0.0189, 0.0302, 0.0131, 0.0396, 0.0056,\n",
      "         0.0558, 0.0229, 0.0346, 0.0183, 0.0227, 0.0434, 0.0433, 0.0512, 0.0478]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0349, 0.0123, 0.0163, 0.0305, 0.0213, 0.0186, 0.0333, 0.0240, 0.0339,\n",
      "         0.0178, 0.0184, 0.0274, 0.0211, 0.0489, 0.0062, 0.0337, 0.0489, 0.0183,\n",
      "         0.0192, 0.0106, 0.0213, 0.0366, 0.0188, 0.0301, 0.0131, 0.0396, 0.0056,\n",
      "         0.0557, 0.0229, 0.0345, 0.0183, 0.0227, 0.0433, 0.0432, 0.0511, 0.0477]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n",
      "tensor([[0.0348, 0.0123, 0.0162, 0.0305, 0.0212, 0.0186, 0.0332, 0.0239, 0.0339,\n",
      "         0.0177, 0.0184, 0.0273, 0.0210, 0.0487, 0.0062, 0.0336, 0.0487, 0.0183,\n",
      "         0.0192, 0.0106, 0.0213, 0.0365, 0.0188, 0.0301, 0.0131, 0.0395, 0.0056,\n",
      "         0.0555, 0.0228, 0.0345, 0.0182, 0.0227, 0.0432, 0.0431, 0.0533, 0.0476]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([1, 100])\n",
      "tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([1, 36])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m context, target \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcbow_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 22\u001b[0m, in \u001b[0;36mCBOW.forward\u001b[1;34m(self, context)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(probabilities\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(probabilities\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(probabilities)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    429\u001b[0m     )\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor_str.py:183\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m nonzero_finite_vals:\n\u001b[1;32m--> 183\u001b[0m                 value_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m{{\u001b[39;49;00m\u001b[38;5;124;43m:.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPRINT_OPTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;130;43;01m}}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PRINT_OPTS\u001b[38;5;241m.\u001b[39msci_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:933\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m--> 933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the CBOW model\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# The Adam optimizer is an extension to stochastic gradient descent\n",
    "optimizer = optim.SGD(cbow_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(context_window, len(train_sequence) - context_window):\n",
    "        # get context window, and get 1-hot encoding for each character in the window\n",
    "        context = torch.tensor(train_sequence[i-context_window:i] + train_sequence[i+1:i+1+context_window])\n",
    "        # create 1-hot encoding for each position in the context array\n",
    "        context = F.one_hot(context, num_classes=vocab_size)\n",
    "        # get target character\n",
    "        target = torch.tensor([train_sequence[i]])\n",
    "        # create 1-hot encoding for target character\n",
    "        target = F.one_hot(target, num_classes=vocab_size).float()\n",
    "        \n",
    "        # Move tensors to GPU if available\n",
    "        context, target = context.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = cbow_model(context)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 20)\n",
      "ى: [-0.02491802  0.03899876 -0.0858681  -0.05633762 -0.01706139 -0.00362067\n",
      " -0.00908654 -0.04218103  0.01387355 -0.01394024  0.0263774   0.00491693\n",
      " -0.0042674   0.01571666  0.07048664  0.02466692  0.01340346  0.01285902\n",
      "  0.06158666  0.0092001 ]\n",
      "ل: [-0.530507    0.4280205   0.62792784  2.230431    0.39901805  0.90821904\n",
      "  0.5206144   1.1459837   0.42858866  1.4255207  -0.7981823  -0.65918475\n",
      "  0.56598693 -0.12815654  0.12077828 -0.69428    -1.1426365  -1.6433033\n",
      " -0.21235164 -0.4322641 ]\n",
      "ط: [-1.3274553   0.9719781  -1.3855953  -0.02773895 -0.27838656 -1.1500709\n",
      "  1.051754    0.53278327 -1.4847202   0.6330003  -0.37871987  0.32195097\n",
      "  0.20924708 -0.49564987 -2.1044495  -1.3350732  -0.37433508  1.0329229\n",
      " -0.67105204 -0.25660402]\n",
      "ه: [ 1.5211954  -1.4997439   0.64794385  0.2514645  -0.7202958   0.8731724\n",
      "  0.47653553  1.475459    0.42314875  0.90437627  0.57568526 -0.2645905\n",
      "  0.2805538  -0.14809914 -0.38314816 -1.5234482  -0.8347636  -0.10202003\n",
      "  0.7203185   0.04670541]\n",
      "ث: [-0.5884517   0.9144036  -0.9941744  -0.75279397  0.17645212  0.32793924\n",
      "  0.5845402   0.66803855  0.53756326  0.60653937  2.004862    1.4527321\n",
      "  0.576557    0.06514768 -0.8980901   0.02319272  1.9647824  -1.5026889\n",
      " -0.5355513   0.18188101]\n",
      "س: [-0.18285103 -0.08582148 -0.29478166  1.4660999   2.1223516   0.08269177\n",
      "  0.08721611  0.08790605  2.6113706   0.52153057 -1.5812328  -0.46107\n",
      "  0.28744447 -1.6532035  -1.8420388  -0.12302239  2.127262   -0.8213263\n",
      "  0.31381634 -1.7244538 ]\n",
      "ف: [ 1.4311182  -0.9786896   1.460334    0.4295704  -0.73810244  0.8357171\n",
      "  0.40148386 -1.9004631  -0.03731754 -0.5378758   0.5088984   0.2796663\n",
      "  0.23467076 -0.6022391   0.02053991 -0.7449528  -0.8031995   0.28811\n",
      "  1.8604679  -0.1820042 ]\n",
      "ظ: [ 1.0615455  -0.848957   -0.80964917  1.0029274   1.1422989   0.17594868\n",
      "  0.7310592  -1.1675165  -0.6750878  -0.7409957   1.121703    0.8655165\n",
      "  1.1264247  -0.6533809  -2.1736598  -0.7341088  -0.6379571  -0.4106153\n",
      "  0.6132259   0.33260635]\n",
      "غ: [-1.1265279   0.8884243   1.7222013   0.16379912 -0.11834965  0.37726766\n",
      "  2.0414736   0.91966987 -0.25808945 -2.269263   -2.9202754   0.27777258\n",
      " -0.46223396  0.44489667 -0.44589487 -0.60612804  0.19586316 -0.99770606\n",
      " -0.71333027  0.30701223]\n",
      "ح: [ 0.09958977  1.3125302   0.16474484 -0.74022    -0.15051672 -0.7838214\n",
      "  0.5384362  -1.5014347   0.7977347  -0.21532716 -0.6727707   2.454144\n",
      " -0.4276143   0.05977108 -0.6299645   0.8060288   0.5937304   0.60431504\n",
      " -0.2022441   1.0274734 ]\n",
      "ي: [-0.66496694  1.0230402  -0.51440537 -1.1531123   0.02581535  1.3134739\n",
      " -1.4467378   0.7985477  -0.06962252  0.5312092   1.0418189  -0.53711295\n",
      " -0.57190984  0.6513591  -2.053138   -0.28183246 -0.2399646   0.2628529\n",
      "  0.3142394   0.21815848]\n",
      "ص: [-2.9224870e-01 -9.4630986e-01  2.3077287e-01  1.1750538e+00\n",
      " -2.5421554e-01 -1.2990806e+00 -2.8883478e-01 -2.1060027e-01\n",
      " -1.3666067e+00 -6.7464125e-01 -4.2317227e-01 -2.0278364e-03\n",
      "  8.9787459e-01 -8.5152298e-01 -1.0859125e+00 -6.7268538e-01\n",
      "  6.1584103e-01  1.8120942e+00 -1.4138147e+00 -2.1147354e+00]\n",
      "إ: [-1.3156347  -0.5532026  -0.4171754   1.4158592   2.1743574   0.7112373\n",
      " -0.17256156  0.8696095   0.09460492  3.2816432  -0.04084814 -1.1238118\n",
      " -1.5001774  -0.88064563 -0.28227952 -0.7572609  -0.42546546 -0.423296\n",
      "  0.13845101  1.1622804 ]\n",
      "ت: [ 0.3994302  -1.4393858  -0.32676873  0.9564201  -1.9134573  -1.0779209\n",
      "  0.9953936  -1.4582272  -0.4574555  -1.0146587  -1.2756792   2.104737\n",
      "  0.04768682  0.44391355 -2.4018834   0.29809552  0.7272299   0.4939671\n",
      "  0.4959876   0.7670768 ]\n",
      "ج: [-0.38038376 -0.86378163 -1.3243799  -0.38814938  0.6921884   0.1538235\n",
      " -0.08685709 -0.3367451  -0.5607375   0.12912053  0.7537703  -0.5799976\n",
      "  0.61983824  0.90819234 -0.47257504 -0.9175141  -0.48511183  1.257933\n",
      " -0.8362495   2.0941484 ]\n",
      "ب: [-0.82578844  0.0445065  -1.0837362   1.5298442   1.5000616  -0.53982645\n",
      "  0.17328154  1.4560934  -0.9266572  -0.8175301  -0.5843818  -0.44704893\n",
      " -1.5405171   0.00537883 -0.09986006  0.10406119 -0.1876078   0.80892485\n",
      " -0.35464823 -1.9953597 ]\n",
      "ئ: [-0.28476346  1.2277232   0.28425506  1.5276155   2.431151   -1.1679051\n",
      " -0.6874137   1.0955521   1.6083012   0.47213262 -0.02184482  1.3048418\n",
      "  0.1427015  -0.48278895  0.15932652  1.213028    0.7313864   1.2185476\n",
      " -0.36031008 -0.62747854]\n",
      "ا: [-0.501994   -0.5400418   0.42129233 -1.5220126  -0.7129474  -1.5015049\n",
      " -2.1801715   0.2951713  -0.54549193  1.6487129   1.2780659  -0.22531798\n",
      " -0.7302016   2.006325   -0.6687967  -1.0127196  -1.4114321  -0.17635727\n",
      " -1.5017723   0.09518766]\n",
      "د: [ 0.9744637  -2.260021   -0.13982563  1.4998494  -0.54645205 -1.3534662\n",
      "  1.3567578  -1.2394592  -0.28594136  1.4837394  -0.34074876 -1.7501355\n",
      " -2.5039628  -0.74660754  0.46483564 -0.521262    3.26614    -1.8671923\n",
      "  0.36427015 -0.5883449 ]\n",
      "و: [-0.9852135  -0.59582067 -2.073349    0.12068009  0.0097671   0.06030437\n",
      "  0.5706057  -0.8407909  -0.5693434  -0.4013235   0.46145365  0.40579012\n",
      " -0.8583963   0.83421844  0.8777865   0.80994475 -0.7829282   0.40594798\n",
      " -0.70453936  1.6917189 ]\n",
      "ء: [-0.97593015 -1.3530436  -1.0265561   0.4704537  -1.4356767   2.2194178\n",
      "  0.8085142  -0.2899938  -1.764196   -0.7116725  -0.42857137  0.29972675\n",
      "  0.77774656 -0.6859968   0.2100819  -0.6516252  -0.8499133   0.5438745\n",
      "  2.035436    0.6537657 ]\n",
      "أ: [ 1.1459705  -1.3113843  -2.1304874   0.8058519   2.3519678   0.9061781\n",
      "  0.4538042   1.681012    0.14083181 -1.0339086   0.47953343  0.52946\n",
      "  0.08327677 -0.75658554  0.8768628  -0.488514   -0.20124052 -0.99661946\n",
      "  1.334096   -0.04991787]\n",
      "ز: [ 1.3598586  -0.45653194 -0.41330078 -1.1681544  -0.48114485  0.4226967\n",
      "  0.54863495 -1.6750605  -0.05018903  0.72993946  0.03541064  0.9007834\n",
      "  0.04078123 -0.02933133 -0.71146965 -0.08598683 -0.17774753 -0.2550305\n",
      " -0.6446048   1.4764241 ]\n",
      "ؤ: [-1.939835    1.4975197   0.24277253  0.5043818  -0.58133596 -0.4852781\n",
      "  0.58074087  1.2900844   1.0421749   0.6801562   0.11947732  0.42493454\n",
      " -0.04179359  2.5315294   1.0209434  -0.65950114 -1.3603656   0.717332\n",
      " -0.8177514   1.198185  ]\n",
      "ذ: [ 0.5792007   1.3600742  -0.48827693 -0.45353264  1.2222542  -1.1796553\n",
      " -1.4730638  -0.8323476  -0.58504     0.38434216  0.16336325 -0.4008281\n",
      "  1.210406    2.1568425   0.27094007  1.1005771  -1.0569385  -0.3094458\n",
      "  1.436538    0.07361337]\n",
      "ك: [-0.4877926  -0.27631634  0.25907162 -0.14624852 -1.4167986  -0.9295455\n",
      "  0.07622926 -0.8830794  -0.1336896   0.3532669   0.5653217   0.4125884\n",
      " -0.5589232  -0.68656206  0.4083765   1.1597091  -0.28859118 -0.60998905\n",
      " -1.2465338   0.79637724]\n",
      "ة: [ 0.9264135   2.0777643  -0.9299633   3.0240862   1.09259     2.2539818\n",
      " -0.583986   -1.7292465  -1.0796525  -0.50966185 -0.80513227 -1.9030209\n",
      " -0.47626793  0.54687905  0.20822407  0.41804817  0.02806692  0.36448774\n",
      "  0.46969107 -0.58340794]\n",
      "ن: [-0.94338125 -0.1127754  -0.00449528  1.2639779   1.2718642   1.1055831\n",
      "  0.997217    0.81731856 -1.4001906   0.7897858   1.0931407   0.5984391\n",
      "  0.3280607  -0.30630922  0.58551186 -0.50669664  0.38601747 -0.5787797\n",
      "  0.13576128  1.8804224 ]\n",
      "ق: [ 0.5678023  -0.09995629 -0.13170268 -0.21648733  0.1366303   0.8983836\n",
      " -0.27757403 -0.09396125 -0.95944285 -1.4655592  -0.32415774  0.03706026\n",
      "  0.66456866 -0.53545976  0.26240662 -0.5814559   1.0043406  -0.2787616\n",
      " -1.0675654  -0.14444743]\n",
      "ر: [ 0.24160938  2.1387873   0.05336482 -0.0671714  -0.03222551  1.4329519\n",
      " -0.32816938 -1.5886159  -0.83728886 -0.70432484  0.2592438  -1.2703096\n",
      " -1.1856219  -1.1632588  -0.8009939  -0.08350214 -0.9591349  -0.6072733\n",
      " -0.5552153  -1.8651255 ]\n",
      "آ: [-0.7310049   1.7578431  -0.79592085 -0.6742526  -0.5099132   0.2609314\n",
      "  1.2060614  -0.7720326   0.76558745  2.5788271  -0.31503654  0.18293028\n",
      "  1.5875274   1.2764888  -1.5632311   1.0265051  -0.19878311  0.10054414\n",
      "  0.6232345   1.0372422 ]\n",
      "خ: [-0.5356095   1.287146   -0.78147364  1.2684156  -0.59524375 -1.9861598\n",
      " -0.7845337   0.00585918 -0.9012099  -0.9079951  -0.16233069 -1.5356752\n",
      " -0.1143513   1.1888905   0.46719813  0.14733918  2.078655    0.44791403\n",
      " -1.6630013   0.5504395 ]\n",
      "ع: [ 8.69869411e-01  7.13039100e-01 -4.14076418e-01  7.29632616e-01\n",
      "  1.68712914e+00  1.90526628e+00  1.05164659e+00  5.04680991e-01\n",
      "  7.53068924e-01 -6.74782612e-04 -4.82181042e-01 -1.18047798e+00\n",
      "  1.01560795e+00  3.14031810e-01  6.78516999e-02 -7.02427551e-02\n",
      "  9.80446339e-01  1.11879736e-01  2.92835653e-01 -1.94821608e+00]\n",
      "ش: [ 0.67714584 -1.1263671   0.4535201   0.8026707   0.11013842 -0.8075421\n",
      "  0.4907048   0.6383291   0.12930535 -0.25872144  0.9767754   1.7422438\n",
      "  0.75682753  2.259246   -0.57142234  0.41838357 -0.63299775 -1.2736408\n",
      "  1.2800246   0.3523401 ]\n",
      "م: [-2.3865802   1.3654909  -0.2086912  -0.41265982 -1.2857214  -1.203329\n",
      " -0.7336501   0.48817897 -0.3391885   0.21115695  0.339717    0.30019736\n",
      " -0.4633064  -0.2714937   0.41051966  0.25363725 -0.13432425  0.7033017\n",
      " -0.4762524   0.8115516 ]\n",
      "ض: [ 0.7747471   0.52797437 -0.33064258  1.1941265  -0.64378613 -0.5199803\n",
      "  0.21608834 -1.7735046  -1.4557463  -0.01495739 -1.0254965  -0.89123154\n",
      "  0.02689638 -1.0148044  -0.09700958  1.0177908   0.1641328  -0.04313956\n",
      " -0.5405619   1.8502918 ]\n"
     ]
    }
   ],
   "source": [
    "# Get character embeddings\n",
    "char_embeddings = cbow_model.embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "print(char_embeddings.shape)\n",
    "\n",
    "# Print character embeddings\n",
    "for idx, char in index_to_char.items():\n",
    "    print(f'{char}: {char_embeddings[idx]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
