{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from preprocessing.preprocess import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8351479\n",
      "421099\n",
      "15637321\n",
      "788621\n",
      "{'د': 1, 'خ': 2, 'ذ': 3, 'ة': 4, 'ج': 5, '~': 6, 'ء': 7, 'ب': 8, 'ا': 9, 'ن': 10, 'ف': 11, 'ع': 12, 'س': 13, 'إ': 14, 'ر': 15, 'ئ': 16, 'ل': 17, 'ي': 18, 'ش': 19, 'ه': 20, 'أ': 21, 'ض': 22, 'ق': 23, 'ح': 24, 'ص': 25, 'و': 26, 'ت': 27, 'ث': 28, 'ك': 29, 'ز': 30, 'ط': 31, 'غ': 32, 'ى': 33, 'ؤ': 34, 'آ': 35, 'ظ': 36, 'م': 37}\n",
      "{1: 'د', 2: 'خ', 3: 'ذ', 4: 'ة', 5: 'ج', 6: '~', 7: 'ء', 8: 'ب', 9: 'ا', 10: 'ن', 11: 'ف', 12: 'ع', 13: 'س', 14: 'إ', 15: 'ر', 16: 'ئ', 17: 'ل', 18: 'ي', 19: 'ش', 20: 'ه', 21: 'أ', 22: 'ض', 23: 'ق', 24: 'ح', 25: 'ص', 26: 'و', 27: 'ت', 28: 'ث', 29: 'ك', 30: 'ز', 31: 'ط', 32: 'غ', 33: 'ى', 34: 'ؤ', 35: 'آ', 36: 'ظ', 37: 'م'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = '../../dataset'\n",
    "\n",
    "# preprocess and save the data\n",
    "preprocess_data(data_type='train', dataset_path=dataset_path)\n",
    "preprocess_data(data_type='val', dataset_path=dataset_path)\n",
    "\n",
    "# load data\n",
    "with open(f'{dataset_path}/cleaned_train_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    # read all lines into a single string\n",
    "    training_data = re.compile(r'[\\n\\r\\t\\s]').sub('', file.read())\n",
    "with open(f'{dataset_path}/cleaned_val_data_without_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    # read all lines into a single string\n",
    "    validation_data = re.compile(r'[\\n\\r\\t\\s]').sub('', file.read())\n",
    "    \n",
    "with open(f'{dataset_path}/cleaned_train_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    # read all lines into a single string\n",
    "    training_data_with_diacritics = re.compile(r'[\\n\\r\\t\\s]').sub('', file.read())\n",
    "    \n",
    "with open(f'{dataset_path}/cleaned_val_data_with_diacritics.txt', 'r', encoding='utf-8') as file:\n",
    "    # read all lines into a single string\n",
    "    validation_data_with_diacritics = re.compile(r'[\\n\\r\\t\\s]').sub('', file.read())\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(validation_data))\n",
    "print(len(training_data_with_diacritics))\n",
    "print(len(validation_data_with_diacritics))\n",
    "# Tokenize the text into sequences at the character level\n",
    "vocab = set(''.join(training_data + validation_data))\n",
    "\n",
    "char_to_index = {char: idx + 1 for idx, char in enumerate(vocab)}\n",
    "index_to_char = {idx + 1: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "print(char_to_index)\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1614: 1, 1615: 2, 1616: 3, 1617: 4, 1618: 5, 1611: 6, 1612: 7, 1613: 8, (1617, 1614): 9, (1617, 1615): 10, (1617, 1616): 11, (1617, 1611): 12, (1617, 1612): 13, (1617, 1613): 14}\n",
      "{0: 0, 1: 1614, 2: 1615, 3: 1616, 4: 1617, 5: 1618, 6: 1611, 7: 1612, 8: 1613, 9: (1617, 1614), 10: (1617, 1615), 11: (1617, 1616), 12: (1617, 1611), 13: (1617, 1612), 14: (1617, 1613)}\n"
     ]
    }
   ],
   "source": [
    "# define the diacritics unicode and their corresponding labels classes indices\n",
    "# note that index 0 is reserved for no diacritic\n",
    "labels = {\n",
    "    # no diacritic\n",
    "    0: 0,\n",
    "    # fath\n",
    "    1614: 1,\n",
    "    # damm\n",
    "    1615: 2,\n",
    "    # kasr\n",
    "    1616: 3,\n",
    "    # shadd\n",
    "    1617: 4,\n",
    "    # sukun\n",
    "    1618: 5,\n",
    "    # tanween bel fath\n",
    "    1611: 6,\n",
    "    # tanween bel damm\n",
    "    1612: 7,\n",
    "    # tanween bel kasr\n",
    "    1613: 8,\n",
    "    # shadd and fath\n",
    "    (1617, 1614): 9,\n",
    "    # shadd and damm\n",
    "    (1617, 1615): 10,\n",
    "    # shadd and kasr\n",
    "    (1617, 1616): 11,\n",
    "    # shadd and tanween bel fath\n",
    "    (1617, 1611): 12,\n",
    "    # shadd and tanween bel damm\n",
    "    (1617, 1612): 13,\n",
    "    # shadd and tanween bel kasr\n",
    "    (1617, 1613): 14\n",
    "}\n",
    "\n",
    "indicies_to_labels = {\n",
    "    # no diacritic\n",
    "    0: 0,\n",
    "    # fath\n",
    "    1: 1614,\n",
    "    # damm\n",
    "    2: 1615,\n",
    "    # kasr\n",
    "    3: 1616,\n",
    "    # shadd\n",
    "    4: 1617,\n",
    "    # sukun\n",
    "    5: 1618,\n",
    "    # tanween bel fath\n",
    "    6: 1611,\n",
    "    # tanween bel damm\n",
    "    7: 1612,\n",
    "    # tanween bel kasr\n",
    "    8: 1613,\n",
    "    # shadd and fath\n",
    "    9: (1617, 1614),\n",
    "    # shadd and damm\n",
    "    10: (1617, 1615),\n",
    "    # shadd and kasr\n",
    "    11: (1617, 1616),\n",
    "    # shadd and tanween bel fath\n",
    "    12: (1617, 1611),\n",
    "    # shadd and tanween bel damm\n",
    "    13: (1617, 1612),\n",
    "    # shadd and tanween bel kasr\n",
    "    14: (1617, 1613)\n",
    "}\n",
    "\n",
    "print(labels)\n",
    "print(indicies_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 26, 17, 20, 21, 26, 23, 31, 12, 9]\n",
      "8351479\n",
      "[23, 26, 17, 20, 26, 17, 9, 27, 29, 15]\n",
      "421099\n"
     ]
    }
   ],
   "source": [
    "# build one array that holds all sequences of training data\n",
    "training_data_sequences = [char_to_index[char] for char in training_data]\n",
    "print(training_data_sequences[:10])\n",
    "print(len(training_data_sequences))\n",
    "\n",
    "# build one array that holds all sequences of validation data\n",
    "validation_data_sequences = [char_to_index[char] for char in validation_data]\n",
    "print(validation_data_sequences[:10])\n",
    "print(len(validation_data_sequences))\n",
    "\n",
    "fixed_sequence_length = 50\n",
    "\n",
    "# Create fixed-length sequences\n",
    "fixed_sequences = [training_data_sequences[i:i+fixed_sequence_length] for i in range(0, len(training_data_sequences), fixed_sequence_length)]\n",
    "\n",
    "# Pad 0 to last sequence if it is less than fixed_sequence_length\n",
    "if len(fixed_sequences[-1]) < fixed_sequence_length:\n",
    "    fixed_sequences[-1] += [0] * (fixed_sequence_length - len(fixed_sequences[-1]))\n",
    "\n",
    "training_data_sequences = torch.tensor(fixed_sequences)\n",
    "\n",
    "fixed_sequence_length = 50\n",
    "\n",
    "# Create fixed-length sequences\n",
    "fixed_sequences = [validation_data_sequences[i:i+fixed_sequence_length] for i in range(0, len(validation_data_sequences), fixed_sequence_length)]\n",
    "\n",
    "# Pad 0 to last sequence if it is less than fixed_sequence_length\n",
    "if len(fixed_sequences[-1]) < fixed_sequence_length:\n",
    "    fixed_sequences[-1] += [0] * (fixed_sequence_length - len(fixed_sequences[-1]))\n",
    "\n",
    "validation_data_sequences = torch.tensor(fixed_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8351479\n",
      "[1, 5, 2, 2, 1, 5, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "training_data_labels = []\n",
    "training_size = len(training_data_with_diacritics)\n",
    "index = 0\n",
    "while index < training_size:\n",
    "    if ord(training_data_with_diacritics[index]) not in labels:\n",
    "        # char is not a diacritic\n",
    "        if (index + 1) < training_size and ord(training_data_with_diacritics[index + 1]) in labels:\n",
    "            # char has a diacritic\n",
    "            if ord(training_data_with_diacritics[index + 1]) == 1617:\n",
    "                # char has a shadd diacritic\n",
    "                if (index + 2) < training_size and ord(training_data_with_diacritics[index + 2]) in labels:\n",
    "                    # char has a shadd and another diacritic\n",
    "                    training_data_labels.append(labels[(1617, ord(training_data_with_diacritics[index + 2]))])\n",
    "                    # skip next 2 diacritics chars\n",
    "                    index += 3  # increment by 3 to skip two diacritic chars\n",
    "                    continue\n",
    "                else:\n",
    "                    # char has a shadd and no other diacritic\n",
    "                    training_data_labels.append(labels[1617])\n",
    "                    # skip next diacritic char\n",
    "                    index += 2\n",
    "                    continue\n",
    "            # char has a diacritic other than shadd\n",
    "            training_data_labels.append(labels[ord(training_data_with_diacritics[index + 1])])\n",
    "            # skip next diacritic char\n",
    "            index += 2  # increment by 2 to skip one diacritic char\n",
    "            continue\n",
    "        else:\n",
    "            # char has no diacritic\n",
    "            training_data_labels.append(0)\n",
    "    index += 1  # increment by 1 for normal iteration\n",
    "\n",
    "print(len(training_data_labels))\n",
    "print(training_data_labels[:10])\n",
    "\n",
    "# Create fixed-length sequences\n",
    "fixed_labels = [training_data_labels[i:i+fixed_sequence_length] for i in range(0, len(training_data_labels), fixed_sequence_length)]\n",
    "\n",
    "# Pad 0 to last sequence if it is less than fixed_sequence_length\n",
    "if len(fixed_labels[-1]) < fixed_sequence_length:\n",
    "    fixed_labels[-1] += [0] * (fixed_sequence_length - len(fixed_labels[-1]))\n",
    "\n",
    "training_data_labels = torch.tensor(fixed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421099\n",
      "[1, 5, 2, 2, 1, 1, 0, 2, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "validation_data_labels = []\n",
    "validation_size = len(validation_data_with_diacritics)\n",
    "index = 0\n",
    "while index < validation_size:\n",
    "    if ord(validation_data_with_diacritics[index]) not in labels:\n",
    "        # char is not a diacritic\n",
    "        if (index + 1) < validation_size and ord(validation_data_with_diacritics[index + 1]) in labels:\n",
    "            # char has a diacritic\n",
    "            if ord(validation_data_with_diacritics[index + 1]) == 1617:\n",
    "                # char has a shadd diacritic\n",
    "                if (index + 2) < validation_size and ord(validation_data_with_diacritics[index + 2]) in labels:\n",
    "                    # char has a shadd and another diacritic\n",
    "                    validation_data_labels.append(labels[(1617, ord(validation_data_with_diacritics[index + 2]))])\n",
    "                    # skip next 2 diacritics chars\n",
    "                    index += 3  # increment by 3 to skip two diacritic chars\n",
    "                    continue\n",
    "                else:\n",
    "                    # char has a shadd and no other diacritic\n",
    "                    validation_data_labels.append(labels[1617])\n",
    "                    # skip next diacritic char\n",
    "                    index += 2\n",
    "                    continue\n",
    "            # char has a diacritic other than shadd\n",
    "            validation_data_labels.append(labels[ord(validation_data_with_diacritics[index + 1])])\n",
    "            # skip next diacritic char\n",
    "            index += 2  # increment by 2 to skip one diacritic char\n",
    "            continue\n",
    "        else:\n",
    "            # char has no diacritic\n",
    "            validation_data_labels.append(0)\n",
    "    index += 1  # increment by 1 for normal iteration\n",
    "\n",
    "print(len(validation_data_labels))\n",
    "print(validation_data_labels[:10])\n",
    "\n",
    "# Create fixed-length sequences\n",
    "fixed_labels = [validation_data_labels[i:i+fixed_sequence_length] for i in range(0, len(validation_data_labels), fixed_sequence_length)]\n",
    "\n",
    "# Pad 0 to last sequence if it is less than fixed_sequence_length\n",
    "if len(fixed_labels[-1]) < fixed_sequence_length:\n",
    "    fixed_labels[-1] += [0] * (fixed_sequence_length - len(fixed_labels[-1]))\n",
    "\n",
    "validation_data_labels = torch.tensor(fixed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = TensorDataset(training_data_sequences, training_data_labels)\n",
    "\n",
    "batch_size = 32\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size)\n",
    "\n",
    "validation_dataset = TensorDataset(validation_data_sequences, validation_data_labels)\n",
    "\n",
    "batch_size = 32\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (embedding): Embedding(38, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (output): Linear(in_features=256, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, drop_prob=0.5, num_layers=1):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        # chars embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        # LSTM layers\n",
    "        # batch_first: it means that the input tensor has its first dimension representing the batch size\n",
    "        # TODO: BLSTM\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Drop out layer, how likely would it drop some neurons (assign zeros to them)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # output layer\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x) # batch_size * seq_length * embedding_size\n",
    "        lstm_out, _ = self.lstm(embedded) # batch_size * seq_length * hidden_size\n",
    "        after_dropout = self.dropout(lstm_out) # batch_size * seq_length *  hidden_size\n",
    "        output = self.output(after_dropout)  # batch_size * seq_length * output_size\n",
    "        output_softmax = F.softmax(output, dim=1)  # Apply softmax to the output\n",
    "        return output_softmax\n",
    "    \n",
    "num_layers = 2\n",
    "vocab_size = len(char_to_index) + 1 # +1 for the 0 padding\n",
    "embedding_size = 200\n",
    "output_size = len(labels)\n",
    "hidden_size = 256\n",
    "drop_prob = 0.5\n",
    "lr=0.001\n",
    "\n",
    "model = CharLSTM(vocab_size, embedding_size,  hidden_size, output_size, drop_prob, num_layers)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_sequences, batch_labels \u001b[38;5;129;01min\u001b[39;00m training_dataloader:\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_sequences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;66;03m# batch_size * seq_length * output_size\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# convert batch_labels to one hot encoding\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     batch_labels_one_hot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(batch_labels, num_classes\u001b[38;5;241m=\u001b[39moutput_size)\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;66;03m# batch_size * seq_length * output_size\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m, in \u001b[0;36mCharLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     19\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;66;03m# batch_size * seq_length * embedding_size\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# batch_size * seq_length * hidden_size\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     after_dropout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(lstm_out) \u001b[38;5;66;03m# batch_size * seq_length *  hidden_size\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(after_dropout)  \u001b[38;5;66;03m# batch_size * seq_length * output_size\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for batch_sequences, batch_labels in training_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_sequences).float() # batch_size * seq_length * output_size\n",
    "        # convert batch_labels to one hot encoding\n",
    "        batch_labels_one_hot = F.one_hot(batch_labels, num_classes=output_size).float() # batch_size * seq_length * output_size\n",
    "        \n",
    "        loss = criterion(outputs, batch_labels_one_hot)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    for validation_batch_sequences, validation_batch_labels in validation_dataloader:\n",
    "        outputs = model(validation_batch_sequences).float() # batch_size * seq_length * output_size\n",
    "        # Calculate accuracy\n",
    "        predicted_labels = outputs.argmax(dim=2)  # Get the index with the maximum probability\n",
    "        correct_predictions += (predicted_labels == validation_batch_labels).sum().item()\n",
    "        total_predictions += validation_batch_labels.numel()\n",
    "        \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}, Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(model, sentence):\n",
    "    model.eval() # evaluation mode\n",
    "    sentence = [char_to_index[char] for char in sentence]\n",
    "    \n",
    "    # Create fixed-length sequences\n",
    "    fixed_sequences = [sentence[i:i+fixed_sequence_length] for i in range(0, len(sentence), fixed_sequence_length)]\n",
    "\n",
    "    # Pad 0 to last sequence if it is less than fixed_sequence_length\n",
    "    if len(fixed_sequences[-1]) < fixed_sequence_length:\n",
    "        fixed_sequences[-1] += [0] * (fixed_sequence_length - len(fixed_sequences[-1]))\n",
    "\n",
    "    sentence_sequences = torch.tensor(fixed_sequences).view(1, -1)  # Assuming batch size 1\n",
    "\n",
    "    print(sentence_sequences.shape)\n",
    "    outputs = model(sentence_sequences)\n",
    "    print(outputs.shape)\n",
    "    outputs = outputs.argmax(dim=2)\n",
    "    print(outputs.shape)\n",
    "    outputs = outputs.tolist()\n",
    "    print(outputs)\n",
    "    diacritics = []\n",
    "    for output in outputs:\n",
    "        for index in output:\n",
    "            predicted_class = indicies_to_labels[index]\n",
    "            if type(predicted_class) is tuple:\n",
    "                diacritics.append(chr(predicted_class[0]) + chr(predicted_class[1]))\n",
    "            elif predicted_class == 0:\n",
    "                diacritics.append('')\n",
    "            else:\n",
    "                diacritics.append(chr(predicted_class))\n",
    "    return diacritics[:len(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50])\n",
      "torch.Size([1, 50, 15])\n",
      "torch.Size([1, 50])\n",
      "[[1, 5, 3, 2, 1, 5, 1, 3, 3, 0, 5, 1, 9, 3, 3, 3, 2, 3, 1, 1, 1, 0, 3, 0, 5, 9, 4, 3, 3, 10, 3, 1, 12, 7, 13, 12, 7, 1, 14, 8, 1, 14, 6, 1, 14, 6, 1, 13, 6, 1]]\n",
      "قَوْلِهُأَوْقَطِعِالْأَوَّلِيِدِهُإِلَخَقَالِالْزَّرّكِشِيُّ\n"
     ]
    }
   ],
   "source": [
    "test_sentence = 'قوله أو قطع الأول يده إلخ قال الزركشي'\n",
    "test_sentence = re.compile(r'[\\n+\\r+\\t+\\s+]').sub('', test_sentence)\n",
    "predicted_diacritics = lstm_predict(model, test_sentence)\n",
    "\n",
    "diacritized_sentence = ''\n",
    "for i in range(len(test_sentence)):\n",
    "    diacritized_sentence += test_sentence[i] + predicted_diacritics[i]\n",
    "\n",
    "print(diacritized_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
